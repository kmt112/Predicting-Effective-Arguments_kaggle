{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip installs\n",
    "# !pip install pyspellchecker\n",
    "# !pip install seaborn==0.11.2\n",
    "# !pip install -U textblob\n",
    "# !pip install nltk\n",
    "# nltk.download('punkt')\n",
    "# !pip install multimodal-transformers --user\n",
    "## always restart kernel after installation\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tan_k\\anaconda3\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import (AutoTokenizer, AutoConfig, Trainer, EvalPrediction, set_seed)\n",
    "from textblob import TextBlob\n",
    "from transformers.training_args import TrainingArguments\n",
    "from multimodal_transformers.data import load_data_from_folder\n",
    "from multimodal_transformers.model import TabularConfig\n",
    "from multimodal_transformers.model import AutoModelWithTabular\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tan_k\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "sent = \"asfdnsdf\"\n",
    "blob = TextBlob(sent)\n",
    "for sent in blob.sentences:\n",
    "    print(sent.sentiment.polarity)\n",
    "    print(sent.sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\tan_k\\Predicting Effective Arguments_kaggle\\data_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples train-val\n",
      "33088 3677\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df= np.split(df.sample(frac=1), [int(.9*len(df))])\n",
    "print('Num examples train-val')\n",
    "# print(len(train_df), len(val_df), len(test_df))\n",
    "print(len(train_df), len(val_df))\n",
    "train_df.to_csv('train.csv')\n",
    "val_df.to_csv('val.csv')\n",
    "# test_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>source</th>\n",
       "      <th>spelling</th>\n",
       "      <th>count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20670</th>\n",
       "      <td>This world is turning into a darker place. The...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32237</th>\n",
       "      <td>I find that would be much easier. people would...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>The author does not strongly support the idea ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.002083</td>\n",
       "      <td>0.610417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31482</th>\n",
       "      <td>Another benefit to online education is the stu...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17219</th>\n",
       "      <td>I understand that \"the winning candidate's sha...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.654167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          discourse_text discourse_type  \\\n",
       "20670  This world is turning into a darker place. The...           Lead   \n",
       "32237  I find that would be much easier. people would...       Evidence   \n",
       "2007   The author does not strongly support the idea ...       Position   \n",
       "31482  Another benefit to online education is the stu...          Claim   \n",
       "17219  I understand that \"the winning candidate's sha...   Counterclaim   \n",
       "\n",
       "       discourse_effectiveness  source  spelling  count  polarity  \\\n",
       "20670                        1       0         0     61  0.000000   \n",
       "32237                        2       0         0     25  0.350000   \n",
       "2007                         1       0         1     35 -0.002083   \n",
       "31482                        1       0         0     13  0.000000   \n",
       "17219                        1       0         0     34  0.383333   \n",
       "\n",
       "       subjectivity  \n",
       "20670      0.000000  \n",
       "32237      0.512500  \n",
       "2007       0.610417  \n",
       "31482      0.000000  \n",
       "17219      0.654167  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>source</th>\n",
       "      <th>spelling</th>\n",
       "      <th>count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10691</th>\n",
       "      <td>First of all i am against using this technolog...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.456667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18809</th>\n",
       "      <td>Another positive to driverless cars are the en...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24083</th>\n",
       "      <td>I do not like the Electoral College. The Elect...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0.130357</td>\n",
       "      <td>0.558929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24817</th>\n",
       "      <td>Joe and I have different belifes, although I a...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13861</th>\n",
       "      <td>The possiblities of a ball of rock, a planet, ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.351000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          discourse_text discourse_type  \\\n",
       "10691  First of all i am against using this technolog...          Claim   \n",
       "18809  Another positive to driverless cars are the en...          Claim   \n",
       "24083  I do not like the Electoral College. The Elect...           Lead   \n",
       "24817  Joe and I have different belifes, although I a...       Evidence   \n",
       "13861  The possiblities of a ball of rock, a planet, ...          Claim   \n",
       "\n",
       "       discourse_effectiveness  source  spelling  count  polarity  \\\n",
       "10691                        2       0         1     41  0.120000   \n",
       "18809                        1       0         1     22  0.250000   \n",
       "24083                        0       0         1     63  0.130357   \n",
       "24817                        2       0         5     75  0.000000   \n",
       "13861                        0       0         1     21  0.104000   \n",
       "\n",
       "       subjectivity  \n",
       "10691      0.456667  \n",
       "18809      0.612500  \n",
       "24083      0.558929  \n",
       "24817      0.000000  \n",
       "13861      0.351000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "  \"\"\"\n",
    "  Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "  \"\"\"\n",
    "\n",
    "  model_name_or_path: str = field(\n",
    "      metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "  )\n",
    "  config_name: Optional[str] = field(\n",
    "      default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "  )\n",
    "  tokenizer_name: Optional[str] = field(\n",
    "      default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "  )\n",
    "  cache_dir: Optional[str] = field(\n",
    "      default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "  )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MultimodalDataTrainingArguments:\n",
    "  \"\"\"\n",
    "  Arguments pertaining to how we combine tabular features\n",
    "  Using `HfArgumentParser` we can turn this class\n",
    "  into argparse arguments to be able to specify them on\n",
    "  the command line.\n",
    "  \"\"\"\n",
    "\n",
    "  data_path: str = field(metadata={\n",
    "                            'help': 'the path to the csv file containing the dataset'\n",
    "                        })\n",
    "  column_info_path: str = field(\n",
    "      default=None,\n",
    "      metadata={\n",
    "          'help': 'the path to the json file detailing which columns are text, categorical, numerical, and the label'\n",
    "  })\n",
    "\n",
    "  column_info: dict = field(\n",
    "      default=None,\n",
    "      metadata={\n",
    "          'help': 'a dict referencing the text, categorical, numerical, and label columns'\n",
    "                  'its keys are text_cols, num_cols, cat_cols, and label_col'\n",
    "  })\n",
    "\n",
    "  categorical_encode_type: str = field(default='ohe',\n",
    "                                        metadata={\n",
    "                                            'help': 'sklearn encoder to use for categorical data',\n",
    "                                            'choices': ['ohe', 'binary', 'label', 'none']\n",
    "                                        })\n",
    "  numerical_transformer_method: str = field(default='yeo_johnson',\n",
    "                                            metadata={\n",
    "                                                'help': 'sklearn numerical transformer to preprocess numerical data',\n",
    "                                                'choices': ['yeo_johnson', 'box_cox', 'quantile_normal', 'none']\n",
    "                                            })\n",
    "  task: str = field(default=\"classification\",\n",
    "                    metadata={\n",
    "                        \"help\": \"The downstream training task\",\n",
    "                        \"choices\": [\"classification\", \"regression\"]\n",
    "                    })\n",
    "\n",
    "  mlp_division: int = field(default=4,\n",
    "                            metadata={\n",
    "                                'help': 'the ratio of the number of '\n",
    "                                        'hidden dims in a current layer to the next MLP layer'\n",
    "                            })\n",
    "  combine_feat_method: str = field(default='individual_mlps_on_cat_and_numerical_feats_then_concat',\n",
    "                                    metadata={\n",
    "                                        'help': 'method to combine categorical and numerical features, '\n",
    "                                                'see README for all the method'\n",
    "                                    })\n",
    "  mlp_dropout: float = field(default=0.1,\n",
    "                              metadata={\n",
    "                                'help': 'dropout ratio used for MLP layers'\n",
    "                              })\n",
    "  numerical_bn: bool = field(default=True,\n",
    "                              metadata={\n",
    "                                  'help': 'whether to use batchnorm on numerical features'\n",
    "                              })\n",
    "  use_simple_classifier: str = field(default=True,\n",
    "                                      metadata={\n",
    "                                          'help': 'whether to use single layer or MLP as final classifier'\n",
    "                                      })\n",
    "  mlp_act: str = field(default='relu',\n",
    "                        metadata={\n",
    "                            'help': 'the activation function to use for finetuning layers',\n",
    "                            'choices': ['relu', 'prelu', 'sigmoid', 'tanh', 'linear']\n",
    "                        })\n",
    "  gating_beta: float = field(default=0.2,\n",
    "                              metadata={\n",
    "                                  'help': \"the beta hyperparameters used for gating tabular data \"\n",
    "                                          \"see https://www.aclweb.org/anthology/2020.acl-main.214.pdf\"\n",
    "                              })\n",
    "\n",
    "  def __post_init__(self):\n",
    "      assert self.column_info != self.column_info_path\n",
    "      if self.column_info is None and self.column_info_path:\n",
    "          with open(self.column_info_path, 'r') as f:\n",
    "              self.column_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['discourse_text', 'discourse_type']\n",
    "cat_cols = ['source', 'spelling']\n",
    "numerical_cols = ['count', 'polarity', 'subjectivity']\n",
    "\n",
    "column_info_dict = {\n",
    "    'text_cols': text_cols,\n",
    "    'num_cols': numerical_cols,\n",
    "    'cat_cols': cat_cols,\n",
    "    'label_col': 'discourse_effectiveness',\n",
    "    'label_list': ['Adequate', 'Effective', 'Ineffective']\n",
    "}\n",
    "\n",
    "\n",
    "model_args = ModelArguments(\n",
    "    model_name_or_path='bert-base-uncased'\n",
    ")\n",
    "\n",
    "data_args = MultimodalDataTrainingArguments(\n",
    "    data_path='.',\n",
    "    combine_feat_method='gating_on_cat_and_num_feats_then_sum',\n",
    "    column_info=column_info_dict,\n",
    "    task='classification'\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./logs/model_name\",\n",
    "    logging_dir=\"./logs/runs\",\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    evaluate_during_training=True,\n",
    "    logging_steps=25,\n",
    "    eval_steps=250\n",
    ")\n",
    "\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified tokenizer:  bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "tokenizer_path_or_name = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
    "print('Specified tokenizer: ', tokenizer_path_or_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_path_or_name,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tan_k\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\tan_k\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\tan_k\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\tan_k\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "# Get Datasets\n",
    "train_dataset, val_dataset, test_dataset = load_data_from_folder(\n",
    "    data_args.data_path,\n",
    "    data_args.column_info['text_cols'],\n",
    "    tokenizer,\n",
    "    label_col=data_args.column_info['label_col'],\n",
    "    label_list=data_args.column_info['label_list'],\n",
    "    categorical_cols=data_args.column_info['cat_cols'],\n",
    "    numerical_cols=data_args.column_info['num_cols'],\n",
    "    sep_text_token_str=tokenizer.sep_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(np.unique(train_dataset.labels))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "tabular_config = TabularConfig(num_labels=num_labels,\n",
    "                               cat_feat_dim=train_dataset.cat_feats.shape[1],\n",
    "                               numerical_feat_dim=train_dataset.numerical_feats.shape[1],\n",
    "                               **vars(data_args))\n",
    "config.tabular_config = tabular_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertWithTabular: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertWithTabular from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertWithTabular from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertWithTabular were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'tabular_combiner.h_bias', 'tabular_combiner.num_bn.weight', 'tabular_combiner.num_bn.bias', 'tabular_combiner.num_bn.running_mean', 'tabular_combiner.num_bn.running_var', 'tabular_combiner.g_cat_layer.weight', 'tabular_combiner.g_cat_layer.bias', 'tabular_combiner.h_cat_layer.weight', 'tabular_combiner.g_num_layer.weight', 'tabular_combiner.g_num_layer.bias', 'tabular_combiner.h_num_layer.weight', 'tabular_combiner.layer_norm.weight', 'tabular_combiner.layer_norm.bias', 'tabular_classifier.weight', 'tabular_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithTabular.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    ")\n",
    "\n",
    "def calc_classification_metrics(p: EvalPrediction):\n",
    "  pred_labels = np.argmax(p.predictions, axis=1)\n",
    "  pred_scores = softmax(p.predictions, axis=1)[:, 1]\n",
    "  labels = p.label_ids\n",
    "  if len(np.unique(labels)) == 2:  # binary classification\n",
    "      roc_auc_pred_score = roc_auc_score(labels, pred_scores)\n",
    "      precisions, recalls, thresholds = precision_recall_curve(labels,\n",
    "                                                                pred_scores)\n",
    "      fscore = (2 * precisions * recalls) / (precisions + recalls)\n",
    "      fscore[np.isnan(fscore)] = 0\n",
    "      ix = np.argmax(fscore)\n",
    "      threshold = thresholds[ix].item()\n",
    "      pr_auc = auc(recalls, precisions)\n",
    "      tn, fp, fn, tp = confusion_matrix(labels, pred_labels, labels=[0, 1]).ravel()\n",
    "      result = {'roc_auc': roc_auc_pred_score,\n",
    "                'threshold': threshold,\n",
    "                'pr_auc': pr_auc,\n",
    "                'recall': recalls[ix].item(),\n",
    "                'precision': precisions[ix].item(), 'f1': fscore[ix].item(),\n",
    "                'tn': tn.item(), 'fp': fp.item(), 'fn': fn.item(), 'tp': tp.item()\n",
    "                }\n",
    "  else:\n",
    "      acc = (pred_labels == labels).mean()\n",
    "      f1 = f1_score(y_true=labels, y_pred=pred_labels, average = 'macro')\n",
    "      result = {\n",
    "          \"acc\": acc,\n",
    "          \"f1\": f1,\n",
    "          \"acc_and_f1\": (acc + f1) / 2,\n",
    "          \"mcc\": matthews_corrcoef(labels, pred_labels)\n",
    "      }\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=calc_classification_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  433626 KB |  433626 KB |  433626 KB |       0 B  |\\n|       from large pool |  433001 KB |  433001 KB |  433001 KB |       0 B  |\\n|       from small pool |     625 KB |     625 KB |     625 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  433626 KB |  433626 KB |  433626 KB |       0 B  |\\n|       from large pool |  433001 KB |  433001 KB |  433001 KB |       0 B  |\\n|       from small pool |     625 KB |     625 KB |     625 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  483328 KB |  483328 KB |  483328 KB |       0 B  |\\n|       from large pool |  481280 KB |  481280 KB |  481280 KB |       0 B  |\\n|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   49701 KB |   54556 KB |  265210 KB |  215508 KB |\\n|       from large pool |   48279 KB |   52992 KB |  263168 KB |  214889 KB |\\n|       from small pool |    1422 KB |    2042 KB |    2042 KB |     619 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     218    |     218    |     218    |       0    |\\n|       from large pool |      77    |      77    |      77    |       0    |\\n|       from small pool |     141    |     141    |     141    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     218    |     218    |     218    |       0    |\\n|       from large pool |      77    |      77    |      77    |       0    |\\n|       from small pool |     141    |     141    |     141    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      21    |      21    |      21    |       0    |\\n|       from large pool |      20    |      20    |      20    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      19    |      19    |      20    |       1    |\\n|       from large pool |      18    |      18    |      19    |       1    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ba66b88f1f408fa05bf8750e53f061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=2.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b79a74fb1fa41669c38136626a10a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8272.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0062890625, 'learning_rate': 4.992444390715668e-05, 'epoch': 0.0030222437137330752, 'step': 25}\n",
      "{'loss': 1.0674319458007813, 'learning_rate': 4.984888781431335e-05, 'epoch': 0.0060444874274661504, 'step': 50}\n",
      "{'loss': 1.0166531372070313, 'learning_rate': 4.977333172147002e-05, 'epoch': 0.009066731141199226, 'step': 75}\n",
      "{'loss': 0.8382000732421875, 'learning_rate': 4.9697775628626697e-05, 'epoch': 0.012088974854932301, 'step': 100}\n",
      "{'loss': 0.9735873413085937, 'learning_rate': 4.9622219535783365e-05, 'epoch': 0.015111218568665378, 'step': 125}\n",
      "{'loss': 0.8514450073242188, 'learning_rate': 4.954666344294004e-05, 'epoch': 0.01813346228239845, 'step': 150}\n",
      "{'loss': 0.9443792724609374, 'learning_rate': 4.9471107350096715e-05, 'epoch': 0.02115570599613153, 'step': 175}\n",
      "{'loss': 1.028966064453125, 'learning_rate': 4.9395551257253384e-05, 'epoch': 0.024177949709864602, 'step': 200}\n",
      "{'loss': 0.9286456298828125, 'learning_rate': 4.931999516441006e-05, 'epoch': 0.02720019342359768, 'step': 225}\n",
      "{'loss': 0.9275335693359374, 'learning_rate': 4.9244439071566734e-05, 'epoch': 0.030222437137330756, 'step': 250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533c91b6cca245049198d9b0f1ff6557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8589335994808642, 'eval_acc': 0.6309491433233614, 'eval_f1': 0.43465591111123186, 'eval_acc_and_f1': 0.5328025272172966, 'eval_mcc': 0.3025153017906576, 'epoch': 0.030222437137330756, 'step': 250}\n",
      "{'loss': 0.809146728515625, 'learning_rate': 4.916888297872341e-05, 'epoch': 0.03324468085106383, 'step': 275}\n",
      "{'loss': 0.817662353515625, 'learning_rate': 4.909332688588008e-05, 'epoch': 0.0362669245647969, 'step': 300}\n",
      "{'loss': 0.85695556640625, 'learning_rate': 4.901777079303675e-05, 'epoch': 0.03928916827852998, 'step': 325}\n",
      "{'loss': 0.9280078125, 'learning_rate': 4.894221470019343e-05, 'epoch': 0.04231141199226306, 'step': 350}\n",
      "{'loss': 0.8129541015625, 'learning_rate': 4.88666586073501e-05, 'epoch': 0.04533365570599613, 'step': 375}\n",
      "{'loss': 0.8776171875, 'learning_rate': 4.879110251450677e-05, 'epoch': 0.048355899419729204, 'step': 400}\n",
      "{'loss': 0.8221240234375, 'learning_rate': 4.871554642166344e-05, 'epoch': 0.051378143133462284, 'step': 425}\n",
      "{'loss': 0.8697509765625, 'learning_rate': 4.8639990328820116e-05, 'epoch': 0.05440038684719536, 'step': 450}\n",
      "{'loss': 0.90614501953125, 'learning_rate': 4.856443423597679e-05, 'epoch': 0.05742263056092843, 'step': 475}\n",
      "{'loss': 0.703673095703125, 'learning_rate': 4.8488878143133466e-05, 'epoch': 0.06044487427466151, 'step': 500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2149874c43454ecca2d4dcb089972414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8907123185675981, 'eval_acc': 0.6382920859396247, 'eval_f1': 0.44384443220257364, 'eval_acc_and_f1': 0.5410682590710991, 'eval_mcc': 0.3173518077374346, 'epoch': 0.06044487427466151, 'step': 500}\n",
      "{'loss': 0.806356201171875, 'learning_rate': 4.841332205029014e-05, 'epoch': 0.06346711798839458, 'step': 525}\n",
      "{'loss': 0.962724609375, 'learning_rate': 4.833776595744681e-05, 'epoch': 0.06648936170212766, 'step': 550}\n",
      "{'loss': 0.960323486328125, 'learning_rate': 4.8262209864603485e-05, 'epoch': 0.06951160541586074, 'step': 575}\n",
      "{'loss': 0.8246923828125, 'learning_rate': 4.818665377176016e-05, 'epoch': 0.0725338491295938, 'step': 600}\n",
      "{'loss': 0.802724609375, 'learning_rate': 4.811109767891683e-05, 'epoch': 0.07555609284332689, 'step': 625}\n",
      "{'loss': 0.88124267578125, 'learning_rate': 4.8035541586073504e-05, 'epoch': 0.07857833655705997, 'step': 650}\n",
      "{'loss': 0.80088134765625, 'learning_rate': 4.795998549323017e-05, 'epoch': 0.08160058027079303, 'step': 675}\n",
      "{'loss': 0.80370849609375, 'learning_rate': 4.788442940038685e-05, 'epoch': 0.08462282398452611, 'step': 700}\n",
      "{'loss': 0.72694580078125, 'learning_rate': 4.780887330754352e-05, 'epoch': 0.0876450676982592, 'step': 725}\n",
      "{'loss': 0.90098388671875, 'learning_rate': 4.77333172147002e-05, 'epoch': 0.09066731141199226, 'step': 750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca74070f7b840ba9d9fcc8529d04033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8155692038018645, 'eval_acc': 0.6464509110688061, 'eval_f1': 0.47375192955727813, 'eval_acc_and_f1': 0.5601014203130421, 'eval_mcc': 0.337814827637422, 'epoch': 0.09066731141199226, 'step': 750}\n",
      "{'loss': 0.888974609375, 'learning_rate': 4.7657761121856867e-05, 'epoch': 0.09368955512572534, 'step': 775}\n",
      "{'loss': 0.91248291015625, 'learning_rate': 4.758220502901354e-05, 'epoch': 0.09671179883945841, 'step': 800}\n",
      "{'loss': 0.74496337890625, 'learning_rate': 4.750664893617022e-05, 'epoch': 0.09973404255319149, 'step': 825}\n",
      "{'loss': 0.8615087890625, 'learning_rate': 4.743109284332689e-05, 'epoch': 0.10275628626692457, 'step': 850}\n",
      "{'loss': 0.94611328125, 'learning_rate': 4.735553675048356e-05, 'epoch': 0.10577852998065763, 'step': 875}\n",
      "{'loss': 0.75705322265625, 'learning_rate': 4.7279980657640236e-05, 'epoch': 0.10880077369439071, 'step': 900}\n",
      "{'loss': 0.91038818359375, 'learning_rate': 4.7204424564796904e-05, 'epoch': 0.1118230174081238, 'step': 925}\n",
      "{'loss': 0.81388671875, 'learning_rate': 4.712886847195358e-05, 'epoch': 0.11484526112185686, 'step': 950}\n",
      "{'loss': 0.879140625, 'learning_rate': 4.7053312379110255e-05, 'epoch': 0.11786750483558994, 'step': 975}\n",
      "{'loss': 0.9672509765625, 'learning_rate': 4.697775628626693e-05, 'epoch': 0.12088974854932302, 'step': 1000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e1c43a29674e25a693ba3a90715766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8709524641680205, 'eval_acc': 0.5678542289910253, 'eval_f1': 0.5359042696547419, 'eval_acc_and_f1': 0.5518792493228837, 'eval_mcc': 0.2896871493421644, 'epoch': 0.12088974854932302, 'step': 1000}\n",
      "{'loss': 0.87268310546875, 'learning_rate': 4.69022001934236e-05, 'epoch': 0.12391199226305609, 'step': 1025}\n",
      "{'loss': 0.86135986328125, 'learning_rate': 4.6826644100580274e-05, 'epoch': 0.12693423597678916, 'step': 1050}\n",
      "{'loss': 0.7563916015625, 'learning_rate': 4.675108800773695e-05, 'epoch': 0.12995647969052224, 'step': 1075}\n",
      "{'loss': 0.74781982421875, 'learning_rate': 4.667553191489362e-05, 'epoch': 0.13297872340425532, 'step': 1100}\n",
      "{'loss': 0.95817138671875, 'learning_rate': 4.659997582205029e-05, 'epoch': 0.1360009671179884, 'step': 1125}\n",
      "{'loss': 0.85396728515625, 'learning_rate': 4.652441972920696e-05, 'epoch': 0.13902321083172148, 'step': 1150}\n",
      "{'loss': 0.74593505859375, 'learning_rate': 4.6448863636363636e-05, 'epoch': 0.14204545454545456, 'step': 1175}\n",
      "{'loss': 0.73847900390625, 'learning_rate': 4.637330754352031e-05, 'epoch': 0.1450676982591876, 'step': 1200}\n",
      "{'loss': 0.81705078125, 'learning_rate': 4.629775145067699e-05, 'epoch': 0.1480899419729207, 'step': 1225}\n",
      "{'loss': 0.8123681640625, 'learning_rate': 4.622219535783366e-05, 'epoch': 0.15111218568665377, 'step': 1250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520dfe45392c4a3795ab18d2103c9a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8004801660768033, 'eval_acc': 0.6562415012238237, 'eval_f1': 0.46331976211515835, 'eval_acc_and_f1': 0.5597806316694911, 'eval_mcc': 0.3587010632107857, 'epoch': 0.15111218568665377, 'step': 1250}\n",
      "{'loss': 0.8639013671875, 'learning_rate': 4.614663926499033e-05, 'epoch': 0.15413442940038685, 'step': 1275}\n",
      "{'loss': 0.81814453125, 'learning_rate': 4.6071083172147006e-05, 'epoch': 0.15715667311411993, 'step': 1300}\n",
      "{'loss': 0.75828125, 'learning_rate': 4.599552707930368e-05, 'epoch': 0.16017891682785299, 'step': 1325}\n",
      "{'loss': 0.8725537109375, 'learning_rate': 4.591997098646035e-05, 'epoch': 0.16320116054158607, 'step': 1350}\n",
      "{'loss': 0.899052734375, 'learning_rate': 4.5844414893617024e-05, 'epoch': 0.16622340425531915, 'step': 1375}\n",
      "{'loss': 0.8684423828125, 'learning_rate': 4.576885880077369e-05, 'epoch': 0.16924564796905223, 'step': 1400}\n",
      "{'loss': 0.86470703125, 'learning_rate': 4.569330270793037e-05, 'epoch': 0.1722678916827853, 'step': 1425}\n",
      "{'loss': 0.84654296875, 'learning_rate': 4.561774661508704e-05, 'epoch': 0.1752901353965184, 'step': 1450}\n",
      "{'loss': 0.858173828125, 'learning_rate': 4.554219052224372e-05, 'epoch': 0.17831237911025144, 'step': 1475}\n",
      "{'loss': 0.872294921875, 'learning_rate': 4.546663442940039e-05, 'epoch': 0.18133462282398452, 'step': 1500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7763dfa2d3fb4baa86339d274b9e987e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8172872044938331, 'eval_acc': 0.6363883600761491, 'eval_f1': 0.41807749236753405, 'eval_acc_and_f1': 0.5272329262218416, 'eval_mcc': 0.3144166821939467, 'epoch': 0.18133462282398452, 'step': 1500}\n",
      "{'loss': 0.7483544921875, 'learning_rate': 4.539107833655706e-05, 'epoch': 0.1843568665377176, 'step': 1525}\n",
      "{'loss': 0.8547265625, 'learning_rate': 4.531552224371374e-05, 'epoch': 0.18737911025145068, 'step': 1550}\n",
      "{'loss': 0.8635302734375, 'learning_rate': 4.523996615087041e-05, 'epoch': 0.19040135396518376, 'step': 1575}\n",
      "{'loss': 0.8126171875, 'learning_rate': 4.516441005802708e-05, 'epoch': 0.19342359767891681, 'step': 1600}\n",
      "{'loss': 1.0479248046875, 'learning_rate': 4.508885396518375e-05, 'epoch': 0.1964458413926499, 'step': 1625}\n",
      "{'loss': 0.768388671875, 'learning_rate': 4.5013297872340425e-05, 'epoch': 0.19946808510638298, 'step': 1650}\n",
      "{'loss': 0.8411962890625, 'learning_rate': 4.49377417794971e-05, 'epoch': 0.20249032882011606, 'step': 1675}\n",
      "{'loss': 0.8363720703125, 'learning_rate': 4.4862185686653775e-05, 'epoch': 0.20551257253384914, 'step': 1700}\n",
      "{'loss': 0.9142578125, 'learning_rate': 4.478662959381045e-05, 'epoch': 0.20853481624758222, 'step': 1725}\n",
      "{'loss': 0.764443359375, 'learning_rate': 4.471107350096712e-05, 'epoch': 0.21155705996131527, 'step': 1750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25803bbc05964b2b84a40e686069b900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.810052686584427, 'eval_acc': 0.6581452270872994, 'eval_f1': 0.46342383107088997, 'eval_acc_and_f1': 0.5607845290790947, 'eval_mcc': 0.36217645297591683, 'epoch': 0.21155705996131527, 'step': 1750}\n",
      "{'loss': 0.925146484375, 'learning_rate': 4.4635517408123794e-05, 'epoch': 0.21457930367504835, 'step': 1775}\n",
      "{'loss': 0.71400390625, 'learning_rate': 4.455996131528047e-05, 'epoch': 0.21760154738878143, 'step': 1800}\n",
      "{'loss': 0.766943359375, 'learning_rate': 4.4484405222437145e-05, 'epoch': 0.2206237911025145, 'step': 1825}\n",
      "{'loss': 0.7715380859375, 'learning_rate': 4.440884912959381e-05, 'epoch': 0.2236460348162476, 'step': 1850}\n",
      "{'loss': 0.8038037109375, 'learning_rate': 4.433329303675048e-05, 'epoch': 0.22666827852998067, 'step': 1875}\n",
      "{'loss': 0.82525390625, 'learning_rate': 4.425773694390716e-05, 'epoch': 0.22969052224371372, 'step': 1900}\n",
      "{'loss': 0.8021875, 'learning_rate': 4.418218085106383e-05, 'epoch': 0.2327127659574468, 'step': 1925}\n",
      "{'loss': 0.8443603515625, 'learning_rate': 4.410662475822051e-05, 'epoch': 0.23573500967117988, 'step': 1950}\n",
      "{'loss': 0.770068359375, 'learning_rate': 4.4031068665377176e-05, 'epoch': 0.23875725338491297, 'step': 1975}\n",
      "{'loss': 0.9677392578125, 'learning_rate': 4.395551257253385e-05, 'epoch': 0.24177949709864605, 'step': 2000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59dbc9659be24871a495760a650be389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8007318429205124, 'eval_acc': 0.6524340494968724, 'eval_f1': 0.46020712542881603, 'eval_acc_and_f1': 0.5563205874628443, 'eval_mcc': 0.353414753987153, 'epoch': 0.24177949709864605, 'step': 2000}\n",
      "{'loss': 0.91673828125, 'learning_rate': 4.3879956479690526e-05, 'epoch': 0.2448017408123791, 'step': 2025}\n",
      "{'loss': 0.97779296875, 'learning_rate': 4.38044003868472e-05, 'epoch': 0.24782398452611218, 'step': 2050}\n",
      "{'loss': 0.8172509765625, 'learning_rate': 4.372884429400387e-05, 'epoch': 0.25084622823984526, 'step': 2075}\n",
      "{'loss': 0.837626953125, 'learning_rate': 4.365328820116054e-05, 'epoch': 0.2538684719535783, 'step': 2100}\n",
      "{'loss': 0.8837890625, 'learning_rate': 4.357773210831721e-05, 'epoch': 0.2568907156673114, 'step': 2125}\n",
      "{'loss': 0.777646484375, 'learning_rate': 4.350217601547389e-05, 'epoch': 0.2599129593810445, 'step': 2150}\n",
      "{'loss': 0.73390625, 'learning_rate': 4.3426619922630564e-05, 'epoch': 0.2629352030947776, 'step': 2175}\n",
      "{'loss': 1.0022705078125, 'learning_rate': 4.335106382978724e-05, 'epoch': 0.26595744680851063, 'step': 2200}\n",
      "{'loss': 0.8308837890625, 'learning_rate': 4.327550773694391e-05, 'epoch': 0.2689796905222437, 'step': 2225}\n",
      "{'loss': 0.77126953125, 'learning_rate': 4.319995164410058e-05, 'epoch': 0.2720019342359768, 'step': 2250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493cd45410a94efeadf4ea990c20fca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8490167533634861, 'eval_acc': 0.6236062007070982, 'eval_f1': 0.49519852686756943, 'eval_acc_and_f1': 0.5594023637873338, 'eval_mcc': 0.28976876522842254, 'epoch': 0.2720019342359768, 'step': 2250}\n",
      "{'loss': 0.88861328125, 'learning_rate': 4.312439555125726e-05, 'epoch': 0.27502417794970985, 'step': 2275}\n",
      "{'loss': 0.810693359375, 'learning_rate': 4.304883945841393e-05, 'epoch': 0.27804642166344296, 'step': 2300}\n",
      "{'loss': 0.7898974609375, 'learning_rate': 4.29732833655706e-05, 'epoch': 0.281068665377176, 'step': 2325}\n",
      "{'loss': 0.908720703125, 'learning_rate': 4.289772727272727e-05, 'epoch': 0.2840909090909091, 'step': 2350}\n",
      "{'loss': 0.7748583984375, 'learning_rate': 4.2822171179883945e-05, 'epoch': 0.28711315280464217, 'step': 2375}\n",
      "{'loss': 0.8317626953125, 'learning_rate': 4.274661508704062e-05, 'epoch': 0.2901353965183752, 'step': 2400}\n",
      "{'loss': 0.84427734375, 'learning_rate': 4.2671058994197296e-05, 'epoch': 0.29315764023210833, 'step': 2425}\n",
      "{'loss': 0.709765625, 'learning_rate': 4.2595502901353964e-05, 'epoch': 0.2961798839458414, 'step': 2450}\n",
      "{'loss': 0.802353515625, 'learning_rate': 4.251994680851064e-05, 'epoch': 0.2992021276595745, 'step': 2475}\n",
      "{'loss': 0.855830078125, 'learning_rate': 4.2444390715667315e-05, 'epoch': 0.30222437137330754, 'step': 2500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cfeaea44e4444ca6cf43f0c7dd3717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8949163904778815, 'eval_acc': 0.6401958118031004, 'eval_f1': 0.48875364753877837, 'eval_acc_and_f1': 0.5644747296709394, 'eval_mcc': 0.33798989449490036, 'epoch': 0.30222437137330754, 'step': 2500}\n",
      "{'loss': 0.849912109375, 'learning_rate': 4.236883462282399e-05, 'epoch': 0.3052466150870406, 'step': 2525}\n",
      "{'loss': 0.793974609375, 'learning_rate': 4.2293278529980665e-05, 'epoch': 0.3082688588007737, 'step': 2550}\n",
      "{'loss': 0.849990234375, 'learning_rate': 4.2217722437137333e-05, 'epoch': 0.31129110251450676, 'step': 2575}\n",
      "{'loss': 0.755390625, 'learning_rate': 4.2142166344294e-05, 'epoch': 0.31431334622823986, 'step': 2600}\n",
      "{'loss': 0.875205078125, 'learning_rate': 4.206661025145068e-05, 'epoch': 0.3173355899419729, 'step': 2625}\n",
      "{'loss': 0.926337890625, 'learning_rate': 4.199105415860735e-05, 'epoch': 0.32035783365570597, 'step': 2650}\n",
      "{'loss': 0.888935546875, 'learning_rate': 4.191549806576403e-05, 'epoch': 0.3233800773694391, 'step': 2675}\n",
      "{'loss': 0.799091796875, 'learning_rate': 4.1839941972920696e-05, 'epoch': 0.32640232108317213, 'step': 2700}\n",
      "{'loss': 0.765390625, 'learning_rate': 4.176438588007737e-05, 'epoch': 0.32942456479690524, 'step': 2725}\n",
      "{'loss': 0.883623046875, 'learning_rate': 4.1688829787234047e-05, 'epoch': 0.3324468085106383, 'step': 2750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9fd7f0099847d4b885234f052d8538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8712656674483629, 'eval_acc': 0.6181669839543106, 'eval_f1': 0.4082600000361678, 'eval_acc_and_f1': 0.5132134919952391, 'eval_mcc': 0.27818419026493696, 'epoch': 0.3324468085106383, 'step': 2750}\n",
      "{'loss': 0.775390625, 'learning_rate': 4.161327369439072e-05, 'epoch': 0.3354690522243714, 'step': 2775}\n",
      "{'loss': 0.94138671875, 'learning_rate': 4.153771760154739e-05, 'epoch': 0.33849129593810445, 'step': 2800}\n",
      "{'loss': 0.75484375, 'learning_rate': 4.146216150870406e-05, 'epoch': 0.3415135396518375, 'step': 2825}\n",
      "{'loss': 0.742705078125, 'learning_rate': 4.1386605415860734e-05, 'epoch': 0.3445357833655706, 'step': 2850}\n",
      "{'loss': 0.949140625, 'learning_rate': 4.131104932301741e-05, 'epoch': 0.34755802707930367, 'step': 2875}\n",
      "{'loss': 0.859990234375, 'learning_rate': 4.1235493230174084e-05, 'epoch': 0.3505802707930368, 'step': 2900}\n",
      "{'loss': 0.8753125, 'learning_rate': 4.115993713733076e-05, 'epoch': 0.3536025145067698, 'step': 2925}\n",
      "{'loss': 0.820498046875, 'learning_rate': 4.108438104448743e-05, 'epoch': 0.3566247582205029, 'step': 2950}\n",
      "{'loss': 0.69763671875, 'learning_rate': 4.10088249516441e-05, 'epoch': 0.359647001934236, 'step': 2975}\n",
      "{'loss': 0.73748046875, 'learning_rate': 4.093326885880078e-05, 'epoch': 0.36266924564796904, 'step': 3000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407060bfb81842279e4d6554fd2b70cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8299565005146812, 'eval_acc': 0.6467228719064455, 'eval_f1': 0.4548709904767642, 'eval_acc_and_f1': 0.5507969311916049, 'eval_mcc': 0.3364887404994228, 'epoch': 0.36266924564796904, 'step': 3000}\n",
      "{'loss': 0.67546875, 'learning_rate': 4.0857712765957454e-05, 'epoch': 0.36569148936170215, 'step': 3025}\n",
      "{'loss': 0.8441796875, 'learning_rate': 4.078215667311412e-05, 'epoch': 0.3687137330754352, 'step': 3050}\n",
      "{'loss': 0.7323046875, 'learning_rate': 4.070660058027079e-05, 'epoch': 0.37173597678916825, 'step': 3075}\n",
      "{'loss': 0.7621875, 'learning_rate': 4.0631044487427466e-05, 'epoch': 0.37475822050290136, 'step': 3100}\n",
      "{'loss': 0.75556640625, 'learning_rate': 4.055548839458414e-05, 'epoch': 0.3777804642166344, 'step': 3125}\n",
      "{'loss': 0.777646484375, 'learning_rate': 4.0479932301740816e-05, 'epoch': 0.3808027079303675, 'step': 3150}\n",
      "{'loss': 0.78087890625, 'learning_rate': 4.0404376208897485e-05, 'epoch': 0.3838249516441006, 'step': 3175}\n",
      "{'loss': 0.77869140625, 'learning_rate': 4.032882011605416e-05, 'epoch': 0.38684719535783363, 'step': 3200}\n",
      "{'loss': 0.892431640625, 'learning_rate': 4.0253264023210835e-05, 'epoch': 0.38986943907156674, 'step': 3225}\n",
      "{'loss': 0.79212890625, 'learning_rate': 4.017770793036751e-05, 'epoch': 0.3928916827852998, 'step': 3250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fb73cd0a5447fcb4d7d8ab9a81b01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8248289526805691, 'eval_acc': 0.6276856132716889, 'eval_f1': 0.48542686624526943, 'eval_acc_and_f1': 0.5565562397584791, 'eval_mcc': 0.32128661405720665, 'epoch': 0.3928916827852998, 'step': 3250}\n",
      "{'loss': 0.779013671875, 'learning_rate': 4.0102151837524186e-05, 'epoch': 0.3959139264990329, 'step': 3275}\n",
      "{'loss': 0.82912109375, 'learning_rate': 4.002659574468085e-05, 'epoch': 0.39893617021276595, 'step': 3300}\n",
      "{'loss': 0.84736328125, 'learning_rate': 3.995103965183752e-05, 'epoch': 0.40195841392649906, 'step': 3325}\n",
      "{'loss': 0.818125, 'learning_rate': 3.98754835589942e-05, 'epoch': 0.4049806576402321, 'step': 3350}\n",
      "{'loss': 0.8258984375, 'learning_rate': 3.979992746615087e-05, 'epoch': 0.40800290135396516, 'step': 3375}\n",
      "{'loss': 0.70734375, 'learning_rate': 3.972437137330755e-05, 'epoch': 0.41102514506769827, 'step': 3400}\n",
      "{'loss': 0.635380859375, 'learning_rate': 3.9648815280464217e-05, 'epoch': 0.4140473887814313, 'step': 3425}\n",
      "{'loss': 0.77455078125, 'learning_rate': 3.957325918762089e-05, 'epoch': 0.41706963249516443, 'step': 3450}\n",
      "{'loss': 0.741630859375, 'learning_rate': 3.949770309477757e-05, 'epoch': 0.4200918762088975, 'step': 3475}\n",
      "{'loss': 0.82724609375, 'learning_rate': 3.942214700193424e-05, 'epoch': 0.42311411992263054, 'step': 3500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea21bb40d01a45ffa0face027143fb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8650547728805656, 'eval_acc': 0.6472667935817242, 'eval_f1': 0.5055201649918597, 'eval_acc_and_f1': 0.576393479286792, 'eval_mcc': 0.33935186467353795, 'epoch': 0.42311411992263054, 'step': 3500}\n",
      "{'loss': 0.770595703125, 'learning_rate': 3.934659090909091e-05, 'epoch': 0.42613636363636365, 'step': 3525}\n",
      "{'loss': 0.773427734375, 'learning_rate': 3.927103481624758e-05, 'epoch': 0.4291586073500967, 'step': 3550}\n",
      "{'loss': 0.732392578125, 'learning_rate': 3.9195478723404254e-05, 'epoch': 0.4321808510638298, 'step': 3575}\n",
      "{'loss': 0.856298828125, 'learning_rate': 3.911992263056093e-05, 'epoch': 0.43520309477756286, 'step': 3600}\n",
      "{'loss': 0.844931640625, 'learning_rate': 3.9044366537717605e-05, 'epoch': 0.4382253384912959, 'step': 3625}\n",
      "{'loss': 0.76310546875, 'learning_rate': 3.896881044487427e-05, 'epoch': 0.441247582205029, 'step': 3650}\n",
      "{'loss': 0.830546875, 'learning_rate': 3.889325435203095e-05, 'epoch': 0.4442698259187621, 'step': 3675}\n",
      "{'loss': 0.746787109375, 'learning_rate': 3.8817698259187624e-05, 'epoch': 0.4472920696324952, 'step': 3700}\n",
      "{'loss': 0.774736328125, 'learning_rate': 3.87421421663443e-05, 'epoch': 0.45031431334622823, 'step': 3725}\n",
      "{'loss': 0.7955859375, 'learning_rate': 3.8666586073500974e-05, 'epoch': 0.45333655705996134, 'step': 3750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35726d94de543b5ae450acc319f2917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8253591091599775, 'eval_acc': 0.6505303236333968, 'eval_f1': 0.4940231286608392, 'eval_acc_and_f1': 0.572276726147118, 'eval_mcc': 0.3562298259973765, 'epoch': 0.45333655705996134, 'step': 3750}\n",
      "{'loss': 0.81095703125, 'learning_rate': 3.859102998065764e-05, 'epoch': 0.4563588007736944, 'step': 3775}\n",
      "{'loss': 0.891865234375, 'learning_rate': 3.851547388781431e-05, 'epoch': 0.45938104448742745, 'step': 3800}\n",
      "{'loss': 0.942548828125, 'learning_rate': 3.8439917794970986e-05, 'epoch': 0.46240328820116056, 'step': 3825}\n",
      "{'loss': 0.782880859375, 'learning_rate': 3.836436170212766e-05, 'epoch': 0.4654255319148936, 'step': 3850}\n",
      "{'loss': 0.847314453125, 'learning_rate': 3.828880560928434e-05, 'epoch': 0.4684477756286267, 'step': 3875}\n",
      "{'loss': 0.83359375, 'learning_rate': 3.8213249516441005e-05, 'epoch': 0.47147001934235977, 'step': 3900}\n",
      "{'loss': 0.7035546875, 'learning_rate': 3.813769342359768e-05, 'epoch': 0.4744922630560928, 'step': 3925}\n",
      "{'loss': 0.85263671875, 'learning_rate': 3.8062137330754356e-05, 'epoch': 0.47751450676982593, 'step': 3950}\n",
      "{'loss': 0.842353515625, 'learning_rate': 3.798658123791103e-05, 'epoch': 0.480536750483559, 'step': 3975}\n",
      "{'loss': 0.7472265625, 'learning_rate': 3.79110251450677e-05, 'epoch': 0.4835589941972921, 'step': 4000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7526b66fa73c4e5eb95f882f06fc69fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8329633959032836, 'eval_acc': 0.6450911068806092, 'eval_f1': 0.44421116271147726, 'eval_acc_and_f1': 0.5446511347960432, 'eval_mcc': 0.33099082629556664, 'epoch': 0.4835589941972921, 'step': 4000}\n",
      "{'loss': 0.745263671875, 'learning_rate': 3.783546905222437e-05, 'epoch': 0.48658123791102514, 'step': 4025}\n",
      "{'loss': 0.740341796875, 'learning_rate': 3.775991295938104e-05, 'epoch': 0.4896034816247582, 'step': 4050}\n",
      "{'loss': 0.73833984375, 'learning_rate': 3.768435686653772e-05, 'epoch': 0.4926257253384913, 'step': 4075}\n",
      "{'loss': 0.718896484375, 'learning_rate': 3.760880077369439e-05, 'epoch': 0.49564796905222436, 'step': 4100}\n",
      "{'loss': 0.7251171875, 'learning_rate': 3.753324468085106e-05, 'epoch': 0.49867021276595747, 'step': 4125}\n",
      "{'loss': 0.9162890625, 'learning_rate': 3.745768858800774e-05, 'epoch': 0.5016924564796905, 'step': 4150}\n",
      "{'loss': 0.7572265625, 'learning_rate': 3.738213249516441e-05, 'epoch': 0.5047147001934236, 'step': 4175}\n",
      "{'loss': 0.823681640625, 'learning_rate': 3.730657640232109e-05, 'epoch': 0.5077369439071566, 'step': 4200}\n",
      "{'loss': 0.832255859375, 'learning_rate': 3.723102030947776e-05, 'epoch': 0.5107591876208898, 'step': 4225}\n",
      "{'loss': 0.8285546875, 'learning_rate': 3.715546421663443e-05, 'epoch': 0.5137814313346228, 'step': 4250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7033706dcab5472ea2ea5b7a15e45b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8872832599333327, 'eval_acc': 0.5730214849061736, 'eval_f1': 0.5507925718257244, 'eval_acc_and_f1': 0.561907028365949, 'eval_mcc': 0.34209170600674066, 'epoch': 0.5137814313346228, 'step': 4250}\n",
      "{'loss': 0.879921875, 'learning_rate': 3.70799081237911e-05, 'epoch': 0.5168036750483559, 'step': 4275}\n",
      "{'loss': 0.796728515625, 'learning_rate': 3.7004352030947775e-05, 'epoch': 0.519825918762089, 'step': 4300}\n",
      "{'loss': 0.84029296875, 'learning_rate': 3.692879593810445e-05, 'epoch': 0.522848162475822, 'step': 4325}\n",
      "{'loss': 0.80626953125, 'learning_rate': 3.6853239845261125e-05, 'epoch': 0.5258704061895552, 'step': 4350}\n",
      "{'loss': 0.94068359375, 'learning_rate': 3.6777683752417794e-05, 'epoch': 0.5288926499032882, 'step': 4375}\n",
      "{'loss': 0.76708984375, 'learning_rate': 3.670212765957447e-05, 'epoch': 0.5319148936170213, 'step': 4400}\n",
      "{'loss': 0.8387109375, 'learning_rate': 3.6626571566731144e-05, 'epoch': 0.5349371373307543, 'step': 4425}\n",
      "{'loss': 0.88291015625, 'learning_rate': 3.655101547388782e-05, 'epoch': 0.5379593810444874, 'step': 4450}\n",
      "{'loss': 0.832666015625, 'learning_rate': 3.647545938104449e-05, 'epoch': 0.5409816247582205, 'step': 4475}\n",
      "{'loss': 0.812158203125, 'learning_rate': 3.639990328820116e-05, 'epoch': 0.5440038684719536, 'step': 4500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d55d9b8ef34a078b711d1ab2ab3f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8256643047662153, 'eval_acc': 0.6508022844710362, 'eval_f1': 0.4884923851527047, 'eval_acc_and_f1': 0.5696473348118705, 'eval_mcc': 0.34542928593149724, 'epoch': 0.5440038684719536, 'step': 4500}\n",
      "{'loss': 0.766943359375, 'learning_rate': 3.632434719535783e-05, 'epoch': 0.5470261121856866, 'step': 4525}\n",
      "{'loss': 0.742216796875, 'learning_rate': 3.624879110251451e-05, 'epoch': 0.5500483558994197, 'step': 4550}\n",
      "{'loss': 0.77091796875, 'learning_rate': 3.617323500967118e-05, 'epoch': 0.5530705996131529, 'step': 4575}\n",
      "{'loss': 0.79619140625, 'learning_rate': 3.609767891682786e-05, 'epoch': 0.5560928433268859, 'step': 4600}\n",
      "{'loss': 0.940302734375, 'learning_rate': 3.6022122823984526e-05, 'epoch': 0.559115087040619, 'step': 4625}\n",
      "{'loss': 0.813515625, 'learning_rate': 3.59465667311412e-05, 'epoch': 0.562137330754352, 'step': 4650}\n",
      "{'loss': 0.823896484375, 'learning_rate': 3.5871010638297876e-05, 'epoch': 0.5651595744680851, 'step': 4675}\n",
      "{'loss': 0.757138671875, 'learning_rate': 3.579545454545455e-05, 'epoch': 0.5681818181818182, 'step': 4700}\n",
      "{'loss': 0.791533203125, 'learning_rate': 3.571989845261122e-05, 'epoch': 0.5712040618955513, 'step': 4725}\n",
      "{'loss': 0.7210546875, 'learning_rate': 3.5644342359767895e-05, 'epoch': 0.5742263056092843, 'step': 4750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaedd5f9f66f49d38850e279794540d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8210994683921353, 'eval_acc': 0.6274136524340495, 'eval_f1': 0.5786327032982265, 'eval_acc_and_f1': 0.6030231778661379, 'eval_mcc': 0.355200849149505, 'epoch': 0.5742263056092843, 'step': 4750}\n",
      "{'loss': 0.72171875, 'learning_rate': 3.556878626692456e-05, 'epoch': 0.5772485493230174, 'step': 4775}\n",
      "{'loss': 0.8684765625, 'learning_rate': 3.549323017408124e-05, 'epoch': 0.5802707930367504, 'step': 4800}\n",
      "{'loss': 0.8552734375, 'learning_rate': 3.5417674081237914e-05, 'epoch': 0.5832930367504836, 'step': 4825}\n",
      "{'loss': 0.821650390625, 'learning_rate': 3.534211798839458e-05, 'epoch': 0.5863152804642167, 'step': 4850}\n",
      "{'loss': 0.74529296875, 'learning_rate': 3.526656189555126e-05, 'epoch': 0.5893375241779497, 'step': 4875}\n",
      "{'loss': 0.883388671875, 'learning_rate': 3.519100580270793e-05, 'epoch': 0.5923597678916828, 'step': 4900}\n",
      "{'loss': 0.8293359375, 'learning_rate': 3.511544970986461e-05, 'epoch': 0.5953820116054158, 'step': 4925}\n",
      "{'loss': 0.836162109375, 'learning_rate': 3.503989361702128e-05, 'epoch': 0.598404255319149, 'step': 4950}\n",
      "{'loss': 0.83728515625, 'learning_rate': 3.496433752417795e-05, 'epoch': 0.601426499032882, 'step': 4975}\n",
      "{'loss': 0.67787109375, 'learning_rate': 3.488878143133462e-05, 'epoch': 0.6044487427466151, 'step': 5000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa60c8cb443f48d283802718ef3babcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8273859957264985, 'eval_acc': 0.6437313026924123, 'eval_f1': 0.4898274822273309, 'eval_acc_and_f1': 0.5667793924598716, 'eval_mcc': 0.32983192846213066, 'epoch': 0.6044487427466151, 'step': 5000}\n",
      "{'loss': 0.9690625, 'learning_rate': 3.4813225338491295e-05, 'epoch': 0.6074709864603481, 'step': 5025}\n",
      "{'loss': 0.93001953125, 'learning_rate': 3.473766924564797e-05, 'epoch': 0.6104932301740812, 'step': 5050}\n",
      "{'loss': 0.89078125, 'learning_rate': 3.4662113152804646e-05, 'epoch': 0.6135154738878144, 'step': 5075}\n",
      "{'loss': 0.8793359375, 'learning_rate': 3.4586557059961314e-05, 'epoch': 0.6165377176015474, 'step': 5100}\n",
      "{'loss': 0.79115234375, 'learning_rate': 3.451100096711799e-05, 'epoch': 0.6195599613152805, 'step': 5125}\n",
      "{'loss': 0.88923828125, 'learning_rate': 3.4435444874274665e-05, 'epoch': 0.6225822050290135, 'step': 5150}\n",
      "{'loss': 0.84986328125, 'learning_rate': 3.435988878143134e-05, 'epoch': 0.6256044487427466, 'step': 5175}\n",
      "{'loss': 0.775859375, 'learning_rate': 3.428433268858801e-05, 'epoch': 0.6286266924564797, 'step': 5200}\n",
      "{'loss': 0.8296484375, 'learning_rate': 3.4208776595744683e-05, 'epoch': 0.6316489361702128, 'step': 5225}\n",
      "{'loss': 0.85990234375, 'learning_rate': 3.413322050290135e-05, 'epoch': 0.6346711798839458, 'step': 5250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fea0a21768453bb38ca8af20a4d83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7798478068266674, 'eval_acc': 0.6502583627957574, 'eval_f1': 0.5595051620511516, 'eval_acc_and_f1': 0.6048817624234546, 'eval_mcc': 0.3697830049060294, 'epoch': 0.6346711798839458, 'step': 5250}\n",
      "{'loss': 0.7212890625, 'learning_rate': 3.405766441005803e-05, 'epoch': 0.6376934235976789, 'step': 5275}\n",
      "{'loss': 0.69181640625, 'learning_rate': 3.39821083172147e-05, 'epoch': 0.6407156673114119, 'step': 5300}\n",
      "{'loss': 0.90896484375, 'learning_rate': 3.390655222437137e-05, 'epoch': 0.6437379110251451, 'step': 5325}\n",
      "{'loss': 0.79349609375, 'learning_rate': 3.3830996131528046e-05, 'epoch': 0.6467601547388782, 'step': 5350}\n",
      "{'loss': 0.953984375, 'learning_rate': 3.375544003868472e-05, 'epoch': 0.6497823984526112, 'step': 5375}\n",
      "{'loss': 0.73291015625, 'learning_rate': 3.3679883945841397e-05, 'epoch': 0.6528046421663443, 'step': 5400}\n",
      "{'loss': 0.8076171875, 'learning_rate': 3.360432785299807e-05, 'epoch': 0.6558268858800773, 'step': 5425}\n",
      "{'loss': 0.85583984375, 'learning_rate': 3.352877176015474e-05, 'epoch': 0.6588491295938105, 'step': 5450}\n",
      "{'loss': 0.895703125, 'learning_rate': 3.3453215667311415e-05, 'epoch': 0.6618713733075435, 'step': 5475}\n",
      "{'loss': 0.7052734375, 'learning_rate': 3.3377659574468084e-05, 'epoch': 0.6648936170212766, 'step': 5500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a47810356c47509973974f829e9052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7676716292556096, 'eval_acc': 0.659233070437857, 'eval_f1': 0.5322223142094404, 'eval_acc_and_f1': 0.5957276923236487, 'eval_mcc': 0.36935782077807894, 'epoch': 0.6648936170212766, 'step': 5500}\n",
      "{'loss': 0.765625, 'learning_rate': 3.330210348162476e-05, 'epoch': 0.6679158607350096, 'step': 5525}\n",
      "{'loss': 0.7087890625, 'learning_rate': 3.3226547388781434e-05, 'epoch': 0.6709381044487428, 'step': 5550}\n",
      "{'loss': 0.6761328125, 'learning_rate': 3.31509912959381e-05, 'epoch': 0.6739603481624759, 'step': 5575}\n",
      "{'loss': 0.73228515625, 'learning_rate': 3.307543520309478e-05, 'epoch': 0.6769825918762089, 'step': 5600}\n",
      "{'loss': 0.87546875, 'learning_rate': 3.299987911025145e-05, 'epoch': 0.680004835589942, 'step': 5625}\n",
      "{'loss': 0.8378515625, 'learning_rate': 3.292432301740813e-05, 'epoch': 0.683027079303675, 'step': 5650}\n",
      "{'loss': 0.80076171875, 'learning_rate': 3.28487669245648e-05, 'epoch': 0.6860493230174082, 'step': 5675}\n",
      "{'loss': 0.84654296875, 'learning_rate': 3.277321083172147e-05, 'epoch': 0.6890715667311412, 'step': 5700}\n",
      "{'loss': 0.71318359375, 'learning_rate': 3.269765473887815e-05, 'epoch': 0.6920938104448743, 'step': 5725}\n",
      "{'loss': 0.6546875, 'learning_rate': 3.2622098646034816e-05, 'epoch': 0.6951160541586073, 'step': 5750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ac8d191ea34fa6a6c9dc505df25c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.818487498109873, 'eval_acc': 0.6690236605928747, 'eval_f1': 0.5201543271347607, 'eval_acc_and_f1': 0.5945889938638177, 'eval_mcc': 0.3893894021826645, 'epoch': 0.6951160541586073, 'step': 5750}\n",
      "{'loss': 0.7971875, 'learning_rate': 3.254654255319149e-05, 'epoch': 0.6981382978723404, 'step': 5775}\n",
      "{'loss': 0.7137109375, 'learning_rate': 3.2470986460348166e-05, 'epoch': 0.7011605415860735, 'step': 5800}\n",
      "{'loss': 0.95177734375, 'learning_rate': 3.2395430367504835e-05, 'epoch': 0.7041827852998066, 'step': 5825}\n",
      "{'loss': 0.973671875, 'learning_rate': 3.231987427466151e-05, 'epoch': 0.7072050290135397, 'step': 5850}\n",
      "{'loss': 0.76484375, 'learning_rate': 3.2244318181818185e-05, 'epoch': 0.7102272727272727, 'step': 5875}\n",
      "{'loss': 0.9959375, 'learning_rate': 3.216876208897486e-05, 'epoch': 0.7132495164410058, 'step': 5900}\n",
      "{'loss': 0.8641015625, 'learning_rate': 3.209320599613153e-05, 'epoch': 0.7162717601547389, 'step': 5925}\n",
      "{'loss': 0.756640625, 'learning_rate': 3.2017649903288204e-05, 'epoch': 0.719294003868472, 'step': 5950}\n",
      "{'loss': 0.71484375, 'learning_rate': 3.194209381044487e-05, 'epoch': 0.722316247582205, 'step': 5975}\n",
      "{'loss': 0.79373046875, 'learning_rate': 3.186653771760155e-05, 'epoch': 0.7253384912959381, 'step': 6000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aea23407ea34d519f643ed854a0f3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.813009844741842, 'eval_acc': 0.6573293445743813, 'eval_f1': 0.5941980966381223, 'eval_acc_and_f1': 0.6257637206062518, 'eval_mcc': 0.39559534828905335, 'epoch': 0.7253384912959381, 'step': 6000}\n",
      "{'loss': 0.91392578125, 'learning_rate': 3.179098162475822e-05, 'epoch': 0.7283607350096711, 'step': 6025}\n",
      "{'loss': 0.68119140625, 'learning_rate': 3.171542553191489e-05, 'epoch': 0.7313829787234043, 'step': 6050}\n",
      "{'loss': 0.80833984375, 'learning_rate': 3.1639869439071567e-05, 'epoch': 0.7344052224371374, 'step': 6075}\n",
      "{'loss': 0.71578125, 'learning_rate': 3.156431334622824e-05, 'epoch': 0.7374274661508704, 'step': 6100}\n",
      "{'loss': 0.9025390625, 'learning_rate': 3.148875725338492e-05, 'epoch': 0.7404497098646035, 'step': 6125}\n",
      "{'loss': 0.7801953125, 'learning_rate': 3.1413201160541585e-05, 'epoch': 0.7434719535783365, 'step': 6150}\n",
      "{'loss': 0.74091796875, 'learning_rate': 3.133764506769826e-05, 'epoch': 0.7464941972920697, 'step': 6175}\n",
      "{'loss': 0.59501953125, 'learning_rate': 3.1262088974854936e-05, 'epoch': 0.7495164410058027, 'step': 6200}\n",
      "{'loss': 0.77251953125, 'learning_rate': 3.1186532882011604e-05, 'epoch': 0.7525386847195358, 'step': 6225}\n",
      "{'loss': 0.960078125, 'learning_rate': 3.111097678916828e-05, 'epoch': 0.7555609284332688, 'step': 6250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18b1ef335d842ec893720a8633d82f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7804990551832872, 'eval_acc': 0.6605928746260539, 'eval_f1': 0.5576883611246329, 'eval_acc_and_f1': 0.6091406178753433, 'eval_mcc': 0.3755602679783682, 'epoch': 0.7555609284332688, 'step': 6250}\n",
      "{'loss': 0.6714453125, 'learning_rate': 3.1035420696324955e-05, 'epoch': 0.7585831721470019, 'step': 6275}\n",
      "{'loss': 0.7573046875, 'learning_rate': 3.095986460348162e-05, 'epoch': 0.761605415860735, 'step': 6300}\n",
      "{'loss': 0.660078125, 'learning_rate': 3.08843085106383e-05, 'epoch': 0.7646276595744681, 'step': 6325}\n",
      "{'loss': 0.75072265625, 'learning_rate': 3.0808752417794974e-05, 'epoch': 0.7676499032882012, 'step': 6350}\n",
      "{'loss': 0.8034375, 'learning_rate': 3.073319632495165e-05, 'epoch': 0.7706721470019342, 'step': 6375}\n",
      "{'loss': 0.89130859375, 'learning_rate': 3.065764023210832e-05, 'epoch': 0.7736943907156673, 'step': 6400}\n",
      "{'loss': 0.78455078125, 'learning_rate': 3.058208413926499e-05, 'epoch': 0.7767166344294004, 'step': 6425}\n",
      "{'loss': 0.74251953125, 'learning_rate': 3.0506528046421668e-05, 'epoch': 0.7797388781431335, 'step': 6450}\n",
      "{'loss': 0.808984375, 'learning_rate': 3.0430971953578336e-05, 'epoch': 0.7827611218568665, 'step': 6475}\n",
      "{'loss': 0.69798828125, 'learning_rate': 3.0355415860735008e-05, 'epoch': 0.7857833655705996, 'step': 6500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dc4cee910845f19a63d784e9cc696a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7668820303647713, 'eval_acc': 0.6725591514821866, 'eval_f1': 0.518139785313766, 'eval_acc_and_f1': 0.5953494683979763, 'eval_mcc': 0.3947261716395034, 'epoch': 0.7857833655705996, 'step': 6500}\n",
      "{'loss': 0.81013671875, 'learning_rate': 3.0279859767891683e-05, 'epoch': 0.7888056092843327, 'step': 6525}\n",
      "{'loss': 0.78458984375, 'learning_rate': 3.0204303675048355e-05, 'epoch': 0.7918278529980658, 'step': 6550}\n",
      "{'loss': 0.75083984375, 'learning_rate': 3.012874758220503e-05, 'epoch': 0.7948500967117988, 'step': 6575}\n",
      "{'loss': 0.69830078125, 'learning_rate': 3.0053191489361706e-05, 'epoch': 0.7978723404255319, 'step': 6600}\n",
      "{'loss': 0.7022265625, 'learning_rate': 2.9977635396518377e-05, 'epoch': 0.800894584139265, 'step': 6625}\n",
      "{'loss': 0.8051953125, 'learning_rate': 2.9902079303675053e-05, 'epoch': 0.8039168278529981, 'step': 6650}\n",
      "{'loss': 0.68287109375, 'learning_rate': 2.9826523210831724e-05, 'epoch': 0.8069390715667312, 'step': 6675}\n",
      "{'loss': 0.7076171875, 'learning_rate': 2.97509671179884e-05, 'epoch': 0.8099613152804642, 'step': 6700}\n",
      "{'loss': 0.85033203125, 'learning_rate': 2.9675411025145068e-05, 'epoch': 0.8129835589941973, 'step': 6725}\n",
      "{'loss': 0.92080078125, 'learning_rate': 2.959985493230174e-05, 'epoch': 0.8160058027079303, 'step': 6750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a663554a11934b6ebf63c33d873f3746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7907936598964771, 'eval_acc': 0.6494424802828392, 'eval_f1': 0.4670960647242331, 'eval_acc_and_f1': 0.5582692725035362, 'eval_mcc': 0.34542172276750266, 'epoch': 0.8160058027079303, 'step': 6750}\n",
      "{'loss': 0.71767578125, 'learning_rate': 2.9524298839458415e-05, 'epoch': 0.8190280464216635, 'step': 6775}\n",
      "{'loss': 0.8345703125, 'learning_rate': 2.9448742746615087e-05, 'epoch': 0.8220502901353965, 'step': 6800}\n",
      "{'loss': 0.720390625, 'learning_rate': 2.9373186653771762e-05, 'epoch': 0.8250725338491296, 'step': 6825}\n",
      "{'loss': 0.71865234375, 'learning_rate': 2.9297630560928434e-05, 'epoch': 0.8280947775628626, 'step': 6850}\n",
      "{'loss': 0.9043359375, 'learning_rate': 2.922207446808511e-05, 'epoch': 0.8311170212765957, 'step': 6875}\n",
      "{'loss': 0.78650390625, 'learning_rate': 2.914651837524178e-05, 'epoch': 0.8341392649903289, 'step': 6900}\n",
      "{'loss': 0.85755859375, 'learning_rate': 2.9070962282398456e-05, 'epoch': 0.8371615087040619, 'step': 6925}\n",
      "{'loss': 0.72220703125, 'learning_rate': 2.899540618955513e-05, 'epoch': 0.840183752417795, 'step': 6950}\n",
      "{'loss': 0.67486328125, 'learning_rate': 2.8919850096711797e-05, 'epoch': 0.843205996131528, 'step': 6975}\n",
      "{'loss': 0.72904296875, 'learning_rate': 2.8844294003868472e-05, 'epoch': 0.8462282398452611, 'step': 7000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63a52b956984d6688d5075d9cd55bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8250462003528407, 'eval_acc': 0.6581452270872994, 'eval_f1': 0.5054179461547071, 'eval_acc_and_f1': 0.5817815866210032, 'eval_mcc': 0.37936266330704704, 'epoch': 0.8462282398452611, 'step': 7000}\n",
      "{'loss': 0.89673828125, 'learning_rate': 2.8768737911025144e-05, 'epoch': 0.8492504835589942, 'step': 7025}\n",
      "{'loss': 0.87529296875, 'learning_rate': 2.869318181818182e-05, 'epoch': 0.8522727272727273, 'step': 7050}\n",
      "{'loss': 0.69099609375, 'learning_rate': 2.8617625725338494e-05, 'epoch': 0.8552949709864603, 'step': 7075}\n",
      "{'loss': 0.82767578125, 'learning_rate': 2.8542069632495166e-05, 'epoch': 0.8583172147001934, 'step': 7100}\n",
      "{'loss': 0.7812109375, 'learning_rate': 2.846651353965184e-05, 'epoch': 0.8613394584139265, 'step': 7125}\n",
      "{'loss': 0.79240234375, 'learning_rate': 2.8390957446808513e-05, 'epoch': 0.8643617021276596, 'step': 7150}\n",
      "{'loss': 0.8013671875, 'learning_rate': 2.8315401353965188e-05, 'epoch': 0.8673839458413927, 'step': 7175}\n",
      "{'loss': 0.78427734375, 'learning_rate': 2.8239845261121857e-05, 'epoch': 0.8704061895551257, 'step': 7200}\n",
      "{'loss': 0.8223828125, 'learning_rate': 2.816428916827853e-05, 'epoch': 0.8734284332688588, 'step': 7225}\n",
      "{'loss': 0.78681640625, 'learning_rate': 2.8088733075435204e-05, 'epoch': 0.8764506769825918, 'step': 7250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cee4c91cc8346839a9e44e45a85be4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7652217718872131, 'eval_acc': 0.6709273864563503, 'eval_f1': 0.5132717689888873, 'eval_acc_and_f1': 0.5920995777226188, 'eval_mcc': 0.39116525813474423, 'epoch': 0.8764506769825918, 'step': 7250}\n",
      "{'loss': 0.6322265625, 'learning_rate': 2.8013176982591876e-05, 'epoch': 0.879472920696325, 'step': 7275}\n",
      "{'loss': 0.9691796875, 'learning_rate': 2.793762088974855e-05, 'epoch': 0.882495164410058, 'step': 7300}\n",
      "{'loss': 0.80189453125, 'learning_rate': 2.7862064796905223e-05, 'epoch': 0.8855174081237911, 'step': 7325}\n",
      "{'loss': 0.8230859375, 'learning_rate': 2.7786508704061898e-05, 'epoch': 0.8885396518375241, 'step': 7350}\n",
      "{'loss': 0.7889453125, 'learning_rate': 2.771095261121857e-05, 'epoch': 0.8915618955512572, 'step': 7375}\n",
      "{'loss': 0.73623046875, 'learning_rate': 2.7635396518375245e-05, 'epoch': 0.8945841392649904, 'step': 7400}\n",
      "{'loss': 0.86580078125, 'learning_rate': 2.755984042553192e-05, 'epoch': 0.8976063829787234, 'step': 7425}\n",
      "{'loss': 0.8550390625, 'learning_rate': 2.7484284332688585e-05, 'epoch': 0.9006286266924565, 'step': 7450}\n",
      "{'loss': 0.7407421875, 'learning_rate': 2.740872823984526e-05, 'epoch': 0.9036508704061895, 'step': 7475}\n",
      "{'loss': 0.64779296875, 'learning_rate': 2.7333172147001936e-05, 'epoch': 0.9066731141199227, 'step': 7500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f9660ea8354f758f7cf7ee76ac8cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8017111894615584, 'eval_acc': 0.6374762034267065, 'eval_f1': 0.5662769005071063, 'eval_acc_and_f1': 0.6018765519669065, 'eval_mcc': 0.34369779385007465, 'epoch': 0.9066731141199227, 'step': 7500}\n",
      "{'loss': 0.78740234375, 'learning_rate': 2.7257616054158607e-05, 'epoch': 0.9096953578336557, 'step': 7525}\n",
      "{'loss': 0.748046875, 'learning_rate': 2.7182059961315283e-05, 'epoch': 0.9127176015473888, 'step': 7550}\n",
      "{'loss': 0.5878515625, 'learning_rate': 2.7106503868471955e-05, 'epoch': 0.9157398452611218, 'step': 7575}\n",
      "{'loss': 0.8198828125, 'learning_rate': 2.703094777562863e-05, 'epoch': 0.9187620889748549, 'step': 7600}\n",
      "{'loss': 0.95908203125, 'learning_rate': 2.69553916827853e-05, 'epoch': 0.9217843326885881, 'step': 7625}\n",
      "{'loss': 0.79435546875, 'learning_rate': 2.6879835589941977e-05, 'epoch': 0.9248065764023211, 'step': 7650}\n",
      "{'loss': 0.66748046875, 'learning_rate': 2.680427949709865e-05, 'epoch': 0.9278288201160542, 'step': 7675}\n",
      "{'loss': 0.80365234375, 'learning_rate': 2.6728723404255317e-05, 'epoch': 0.9308510638297872, 'step': 7700}\n",
      "{'loss': 0.83373046875, 'learning_rate': 2.6653167311411992e-05, 'epoch': 0.9338733075435203, 'step': 7725}\n",
      "{'loss': 0.77505859375, 'learning_rate': 2.6577611218568664e-05, 'epoch': 0.9368955512572534, 'step': 7750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfdac43a14b4b5c889e26a190ae977e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7864757029946031, 'eval_acc': 0.6513462061463149, 'eval_f1': 0.6003844651445384, 'eval_acc_and_f1': 0.6258653356454267, 'eval_mcc': 0.3885131029636677, 'epoch': 0.9368955512572534, 'step': 7750}\n",
      "{'loss': 0.884296875, 'learning_rate': 2.650205512572534e-05, 'epoch': 0.9399177949709865, 'step': 7775}\n",
      "{'loss': 0.65724609375, 'learning_rate': 2.642649903288201e-05, 'epoch': 0.9429400386847195, 'step': 7800}\n",
      "{'loss': 0.687421875, 'learning_rate': 2.6350942940038686e-05, 'epoch': 0.9459622823984526, 'step': 7825}\n",
      "{'loss': 0.90322265625, 'learning_rate': 2.627538684719536e-05, 'epoch': 0.9489845261121856, 'step': 7850}\n",
      "{'loss': 0.80703125, 'learning_rate': 2.6199830754352033e-05, 'epoch': 0.9520067698259188, 'step': 7875}\n",
      "{'loss': 0.77134765625, 'learning_rate': 2.612427466150871e-05, 'epoch': 0.9550290135396519, 'step': 7900}\n",
      "{'loss': 0.68791015625, 'learning_rate': 2.604871856866538e-05, 'epoch': 0.9580512572533849, 'step': 7925}\n",
      "{'loss': 0.7834375, 'learning_rate': 2.597316247582205e-05, 'epoch': 0.961073500967118, 'step': 7950}\n",
      "{'loss': 0.72083984375, 'learning_rate': 2.5897606382978724e-05, 'epoch': 0.964095744680851, 'step': 7975}\n",
      "{'loss': 0.72521484375, 'learning_rate': 2.5822050290135396e-05, 'epoch': 0.9671179883945842, 'step': 8000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8a1377aa0d481ba34b55dda2bd3029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7627521261982143, 'eval_acc': 0.6652162088659233, 'eval_f1': 0.5535543499100398, 'eval_acc_and_f1': 0.6093852793879815, 'eval_mcc': 0.39346531410393704, 'epoch': 0.9671179883945842, 'step': 8000}\n",
      "{'loss': 0.78041015625, 'learning_rate': 2.574649419729207e-05, 'epoch': 0.9701402321083172, 'step': 8025}\n",
      "{'loss': 0.75439453125, 'learning_rate': 2.5670938104448743e-05, 'epoch': 0.9731624758220503, 'step': 8050}\n",
      "{'loss': 0.7410546875, 'learning_rate': 2.559538201160542e-05, 'epoch': 0.9761847195357833, 'step': 8075}\n",
      "{'loss': 0.76861328125, 'learning_rate': 2.551982591876209e-05, 'epoch': 0.9792069632495164, 'step': 8100}\n",
      "{'loss': 0.6858203125, 'learning_rate': 2.5444269825918765e-05, 'epoch': 0.9822292069632496, 'step': 8125}\n",
      "{'loss': 0.70962890625, 'learning_rate': 2.5368713733075437e-05, 'epoch': 0.9852514506769826, 'step': 8150}\n",
      "{'loss': 0.7173046875, 'learning_rate': 2.5293157640232106e-05, 'epoch': 0.9882736943907157, 'step': 8175}\n",
      "{'loss': 0.68361328125, 'learning_rate': 2.521760154738878e-05, 'epoch': 0.9912959381044487, 'step': 8200}\n",
      "{'loss': 0.778203125, 'learning_rate': 2.5142045454545453e-05, 'epoch': 0.9943181818181818, 'step': 8225}\n",
      "{'loss': 0.65044921875, 'learning_rate': 2.5066489361702128e-05, 'epoch': 0.9973404255319149, 'step': 8250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd4d7e7fb984b548277ada7118cf3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8171522526239162, 'eval_acc': 0.6608648354636932, 'eval_f1': 0.5013025905748192, 'eval_acc_and_f1': 0.5810837130192562, 'eval_mcc': 0.3758757772314667, 'epoch': 0.9973404255319149, 'step': 8250}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1f7b4312d5424980bb5848b7db4fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8272.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.510234375, 'learning_rate': 2.4990933268858803e-05, 'epoch': 1.000362669245648, 'step': 8275}\n",
      "{'loss': 0.694453125, 'learning_rate': 2.4915377176015475e-05, 'epoch': 1.003384912959381, 'step': 8300}\n",
      "{'loss': 0.7840234375, 'learning_rate': 2.483982108317215e-05, 'epoch': 1.006407156673114, 'step': 8325}\n",
      "{'loss': 0.69017578125, 'learning_rate': 2.4764264990328822e-05, 'epoch': 1.0094294003868471, 'step': 8350}\n",
      "{'loss': 0.68970703125, 'learning_rate': 2.4688708897485494e-05, 'epoch': 1.0124516441005802, 'step': 8375}\n",
      "{'loss': 0.68865234375, 'learning_rate': 2.4613152804642166e-05, 'epoch': 1.0154738878143132, 'step': 8400}\n",
      "{'loss': 0.60453125, 'learning_rate': 2.453759671179884e-05, 'epoch': 1.0184961315280465, 'step': 8425}\n",
      "{'loss': 0.61958984375, 'learning_rate': 2.4462040618955516e-05, 'epoch': 1.0215183752417796, 'step': 8450}\n",
      "{'loss': 0.7388671875, 'learning_rate': 2.4386484526112185e-05, 'epoch': 1.0245406189555126, 'step': 8475}\n",
      "{'loss': 0.6983984375, 'learning_rate': 2.431092843326886e-05, 'epoch': 1.0275628626692457, 'step': 8500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf121ea4f2bf4ed6b80f7b6657a75011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8289782955395583, 'eval_acc': 0.6703834647810716, 'eval_f1': 0.5974711830434941, 'eval_acc_and_f1': 0.6339273239122829, 'eval_mcc': 0.4110954057895114, 'epoch': 1.0275628626692457, 'step': 8500}\n",
      "{'loss': 0.59208984375, 'learning_rate': 2.423537234042553e-05, 'epoch': 1.0305851063829787, 'step': 8525}\n",
      "{'loss': 0.972578125, 'learning_rate': 2.4159816247582207e-05, 'epoch': 1.0336073500967118, 'step': 8550}\n",
      "{'loss': 0.65064453125, 'learning_rate': 2.408426015473888e-05, 'epoch': 1.0366295938104448, 'step': 8575}\n",
      "{'loss': 0.49544921875, 'learning_rate': 2.400870406189555e-05, 'epoch': 1.039651837524178, 'step': 8600}\n",
      "{'loss': 0.83080078125, 'learning_rate': 2.3933147969052226e-05, 'epoch': 1.042674081237911, 'step': 8625}\n",
      "{'loss': 0.66728515625, 'learning_rate': 2.3857591876208898e-05, 'epoch': 1.045696324951644, 'step': 8650}\n",
      "{'loss': 0.77310546875, 'learning_rate': 2.3782035783365573e-05, 'epoch': 1.0487185686653773, 'step': 8675}\n",
      "{'loss': 0.69455078125, 'learning_rate': 2.3706479690522245e-05, 'epoch': 1.0517408123791103, 'step': 8700}\n",
      "{'loss': 0.6266796875, 'learning_rate': 2.3630923597678917e-05, 'epoch': 1.0547630560928434, 'step': 8725}\n",
      "{'loss': 0.74009765625, 'learning_rate': 2.3555367504835592e-05, 'epoch': 1.0577852998065764, 'step': 8750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd40a89bef0547d4ac8b0218d281484c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8427287195407731, 'eval_acc': 0.644275224367691, 'eval_f1': 0.5544741127681476, 'eval_acc_and_f1': 0.5993746685679193, 'eval_mcc': 0.38145109384275533, 'epoch': 1.0577852998065764, 'step': 8750}\n",
      "{'loss': 0.64294921875, 'learning_rate': 2.3479811411992264e-05, 'epoch': 1.0608075435203095, 'step': 8775}\n",
      "{'loss': 0.62490234375, 'learning_rate': 2.340425531914894e-05, 'epoch': 1.0638297872340425, 'step': 8800}\n",
      "{'loss': 0.72107421875, 'learning_rate': 2.332869922630561e-05, 'epoch': 1.0668520309477756, 'step': 8825}\n",
      "{'loss': 0.75279296875, 'learning_rate': 2.3253143133462282e-05, 'epoch': 1.0698742746615086, 'step': 8850}\n",
      "{'loss': 0.7040234375, 'learning_rate': 2.3177587040618958e-05, 'epoch': 1.0728965183752417, 'step': 8875}\n",
      "{'loss': 0.5926953125, 'learning_rate': 2.310203094777563e-05, 'epoch': 1.0759187620889747, 'step': 8900}\n",
      "{'loss': 0.59466796875, 'learning_rate': 2.3026474854932305e-05, 'epoch': 1.078941005802708, 'step': 8925}\n",
      "{'loss': 0.79669921875, 'learning_rate': 2.2950918762088977e-05, 'epoch': 1.081963249516441, 'step': 8950}\n",
      "{'loss': 0.68734375, 'learning_rate': 2.287536266924565e-05, 'epoch': 1.0849854932301741, 'step': 8975}\n",
      "{'loss': 0.58880859375, 'learning_rate': 2.279980657640232e-05, 'epoch': 1.0880077369439072, 'step': 9000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0458ffb7cc40d88ec24087aa27524e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8086434582798968, 'eval_acc': 0.6706554256187109, 'eval_f1': 0.5597277324824278, 'eval_acc_and_f1': 0.6151915790505693, 'eval_mcc': 0.4010899454161666, 'epoch': 1.0880077369439072, 'step': 9000}\n",
      "{'loss': 0.8181640625, 'learning_rate': 2.2724250483558995e-05, 'epoch': 1.0910299806576402, 'step': 9025}\n",
      "{'loss': 0.62955078125, 'learning_rate': 2.2648694390715667e-05, 'epoch': 1.0940522243713733, 'step': 9050}\n",
      "{'loss': 0.55234375, 'learning_rate': 2.2573138297872343e-05, 'epoch': 1.0970744680851063, 'step': 9075}\n",
      "{'loss': 0.8781640625, 'learning_rate': 2.2497582205029014e-05, 'epoch': 1.1000967117988394, 'step': 9100}\n",
      "{'loss': 0.64900390625, 'learning_rate': 2.2422026112185686e-05, 'epoch': 1.1031189555125724, 'step': 9125}\n",
      "{'loss': 0.70494140625, 'learning_rate': 2.234647001934236e-05, 'epoch': 1.1061411992263057, 'step': 9150}\n",
      "{'loss': 0.6803125, 'learning_rate': 2.2270913926499033e-05, 'epoch': 1.1091634429400388, 'step': 9175}\n",
      "{'loss': 0.57111328125, 'learning_rate': 2.219535783365571e-05, 'epoch': 1.1121856866537718, 'step': 9200}\n",
      "{'loss': 0.584921875, 'learning_rate': 2.211980174081238e-05, 'epoch': 1.1152079303675049, 'step': 9225}\n",
      "{'loss': 0.5680078125, 'learning_rate': 2.2044245647969052e-05, 'epoch': 1.118230174081238, 'step': 9250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bd3058241d4131bb4dc43e215a516d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8412174453935061, 'eval_acc': 0.6709273864563503, 'eval_f1': 0.5434877845492228, 'eval_acc_and_f1': 0.6072075855027865, 'eval_mcc': 0.39624926212050515, 'epoch': 1.118230174081238, 'step': 9250}\n",
      "{'loss': 0.67865234375, 'learning_rate': 2.1968689555125727e-05, 'epoch': 1.121252417794971, 'step': 9275}\n",
      "{'loss': 0.57123046875, 'learning_rate': 2.18931334622824e-05, 'epoch': 1.124274661508704, 'step': 9300}\n",
      "{'loss': 0.66203125, 'learning_rate': 2.1817577369439074e-05, 'epoch': 1.127296905222437, 'step': 9325}\n",
      "{'loss': 0.841171875, 'learning_rate': 2.1742021276595746e-05, 'epoch': 1.1303191489361701, 'step': 9350}\n",
      "{'loss': 0.804765625, 'learning_rate': 2.1666465183752418e-05, 'epoch': 1.1333413926499034, 'step': 9375}\n",
      "{'loss': 0.6546875, 'learning_rate': 2.1590909090909093e-05, 'epoch': 1.1363636363636362, 'step': 9400}\n",
      "{'loss': 0.56759765625, 'learning_rate': 2.1515352998065765e-05, 'epoch': 1.1393858800773695, 'step': 9425}\n",
      "{'loss': 0.75861328125, 'learning_rate': 2.1439796905222437e-05, 'epoch': 1.1424081237911026, 'step': 9450}\n",
      "{'loss': 0.6982421875, 'learning_rate': 2.136424081237911e-05, 'epoch': 1.1454303675048356, 'step': 9475}\n",
      "{'loss': 0.74009765625, 'learning_rate': 2.1288684719535784e-05, 'epoch': 1.1484526112185687, 'step': 9500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84f55fd03694a378da812a532b1e04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7868766331108556, 'eval_acc': 0.6616807179766113, 'eval_f1': 0.5724232150402617, 'eval_acc_and_f1': 0.6170519665084365, 'eval_mcc': 0.39169368156664947, 'epoch': 1.1484526112185687, 'step': 9500}\n",
      "{'loss': 0.6980859375, 'learning_rate': 2.121312862669246e-05, 'epoch': 1.1514748549323017, 'step': 9525}\n",
      "{'loss': 0.6417578125, 'learning_rate': 2.113757253384913e-05, 'epoch': 1.1544970986460348, 'step': 9550}\n",
      "{'loss': 0.668125, 'learning_rate': 2.1062016441005803e-05, 'epoch': 1.1575193423597678, 'step': 9575}\n",
      "{'loss': 0.70837890625, 'learning_rate': 2.0986460348162475e-05, 'epoch': 1.1605415860735009, 'step': 9600}\n",
      "{'loss': 0.65365234375, 'learning_rate': 2.091090425531915e-05, 'epoch': 1.163563829787234, 'step': 9625}\n",
      "{'loss': 0.58607421875, 'learning_rate': 2.0835348162475822e-05, 'epoch': 1.1665860735009672, 'step': 9650}\n",
      "{'loss': 0.67033203125, 'learning_rate': 2.0759792069632497e-05, 'epoch': 1.1696083172147003, 'step': 9675}\n",
      "{'loss': 0.68240234375, 'learning_rate': 2.068423597678917e-05, 'epoch': 1.1726305609284333, 'step': 9700}\n",
      "{'loss': 0.734375, 'learning_rate': 2.060867988394584e-05, 'epoch': 1.1756528046421664, 'step': 9725}\n",
      "{'loss': 0.66259765625, 'learning_rate': 2.0533123791102516e-05, 'epoch': 1.1786750483558994, 'step': 9750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cf44a5d05e4f27ad29ad7189dc644f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.816417784495687, 'eval_acc': 0.6711993472939897, 'eval_f1': 0.599929136036787, 'eval_acc_and_f1': 0.6355642416653884, 'eval_mcc': 0.41668459704343175, 'epoch': 1.1786750483558994, 'step': 9750}\n",
      "{'loss': 0.65052734375, 'learning_rate': 2.0457567698259188e-05, 'epoch': 1.1816972920696325, 'step': 9775}\n",
      "{'loss': 0.79912109375, 'learning_rate': 2.0382011605415863e-05, 'epoch': 1.1847195357833655, 'step': 9800}\n",
      "{'loss': 0.6712890625, 'learning_rate': 2.0306455512572535e-05, 'epoch': 1.1877417794970986, 'step': 9825}\n",
      "{'loss': 0.682734375, 'learning_rate': 2.0230899419729207e-05, 'epoch': 1.1907640232108316, 'step': 9850}\n",
      "{'loss': 0.83587890625, 'learning_rate': 2.0155343326885882e-05, 'epoch': 1.193786266924565, 'step': 9875}\n",
      "{'loss': 0.56580078125, 'learning_rate': 2.0079787234042554e-05, 'epoch': 1.196808510638298, 'step': 9900}\n",
      "{'loss': 0.7169921875, 'learning_rate': 2.000423114119923e-05, 'epoch': 1.199830754352031, 'step': 9925}\n",
      "{'loss': 0.4326171875, 'learning_rate': 1.99286750483559e-05, 'epoch': 1.202852998065764, 'step': 9950}\n",
      "{'loss': 0.70666015625, 'learning_rate': 1.9853118955512573e-05, 'epoch': 1.2058752417794971, 'step': 9975}\n",
      "{'loss': 0.63107421875, 'learning_rate': 1.9777562862669248e-05, 'epoch': 1.2088974854932302, 'step': 10000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbcf58ec70c438eb665b6b53db7efe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.9046157435259483, 'eval_acc': 0.667119934729399, 'eval_f1': 0.5205912437696, 'eval_acc_and_f1': 0.5938555892494994, 'eval_mcc': 0.38557900813341667, 'epoch': 1.2088974854932302, 'step': 10000}\n",
      "{'loss': 0.66501953125, 'learning_rate': 1.970200676982592e-05, 'epoch': 1.2119197292069632, 'step': 10025}\n",
      "{'loss': 0.83875, 'learning_rate': 1.9626450676982595e-05, 'epoch': 1.2149419729206963, 'step': 10050}\n",
      "{'loss': 0.7583984375, 'learning_rate': 1.9550894584139263e-05, 'epoch': 1.2179642166344293, 'step': 10075}\n",
      "{'loss': 0.52103515625, 'learning_rate': 1.947533849129594e-05, 'epoch': 1.2209864603481624, 'step': 10100}\n",
      "{'loss': 0.7928515625, 'learning_rate': 1.9399782398452614e-05, 'epoch': 1.2240087040618954, 'step': 10125}\n",
      "{'loss': 0.734921875, 'learning_rate': 1.9324226305609286e-05, 'epoch': 1.2270309477756287, 'step': 10150}\n",
      "{'loss': 0.67482421875, 'learning_rate': 1.924867021276596e-05, 'epoch': 1.2300531914893618, 'step': 10175}\n",
      "{'loss': 0.6480078125, 'learning_rate': 1.917311411992263e-05, 'epoch': 1.2330754352030948, 'step': 10200}\n",
      "{'loss': 0.5196875, 'learning_rate': 1.9097558027079305e-05, 'epoch': 1.2360976789168279, 'step': 10225}\n",
      "{'loss': 0.605703125, 'learning_rate': 1.9022001934235976e-05, 'epoch': 1.239119922630561, 'step': 10250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ad4a6a170f4d8799557f6dee901926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.9427729231655712, 'eval_acc': 0.680717976611368, 'eval_f1': 0.5649844271892828, 'eval_acc_and_f1': 0.6228512019003254, 'eval_mcc': 0.417250220653935, 'epoch': 1.239119922630561, 'step': 10250}\n",
      "{'loss': 0.8746484375, 'learning_rate': 1.894644584139265e-05, 'epoch': 1.242142166344294, 'step': 10275}\n",
      "{'loss': 0.72515625, 'learning_rate': 1.8870889748549327e-05, 'epoch': 1.245164410058027, 'step': 10300}\n",
      "{'loss': 0.79201171875, 'learning_rate': 1.8795333655705995e-05, 'epoch': 1.24818665377176, 'step': 10325}\n",
      "{'loss': 0.8663671875, 'learning_rate': 1.871977756286267e-05, 'epoch': 1.2512088974854931, 'step': 10350}\n",
      "{'loss': 0.68826171875, 'learning_rate': 1.8644221470019342e-05, 'epoch': 1.2542311411992264, 'step': 10375}\n",
      "{'loss': 0.68689453125, 'learning_rate': 1.8568665377176018e-05, 'epoch': 1.2572533849129595, 'step': 10400}\n",
      "{'loss': 0.64318359375, 'learning_rate': 1.849310928433269e-05, 'epoch': 1.2602756286266925, 'step': 10425}\n",
      "{'loss': 0.693828125, 'learning_rate': 1.841755319148936e-05, 'epoch': 1.2632978723404256, 'step': 10450}\n",
      "{'loss': 0.7645703125, 'learning_rate': 1.8341997098646036e-05, 'epoch': 1.2663201160541586, 'step': 10475}\n",
      "{'loss': 0.666015625, 'learning_rate': 1.8266441005802708e-05, 'epoch': 1.2693423597678917, 'step': 10500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457248e7c9bc4e968503d008db380173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8103556940663856, 'eval_acc': 0.6586891487625782, 'eval_f1': 0.6151102988288492, 'eval_acc_and_f1': 0.6368997237957137, 'eval_mcc': 0.4164374029247952, 'epoch': 1.2693423597678917, 'step': 10500}\n",
      "{'loss': 0.606640625, 'learning_rate': 1.8190884912959383e-05, 'epoch': 1.2723646034816247, 'step': 10525}\n",
      "{'loss': 0.6429296875, 'learning_rate': 1.8115328820116055e-05, 'epoch': 1.2753868471953578, 'step': 10550}\n",
      "{'loss': 0.7062890625, 'learning_rate': 1.8039772727272727e-05, 'epoch': 1.2784090909090908, 'step': 10575}\n",
      "{'loss': 0.545234375, 'learning_rate': 1.7964216634429402e-05, 'epoch': 1.281431334622824, 'step': 10600}\n",
      "{'loss': 0.6631640625, 'learning_rate': 1.7888660541586074e-05, 'epoch': 1.284453578336557, 'step': 10625}\n",
      "{'loss': 0.773125, 'learning_rate': 1.781310444874275e-05, 'epoch': 1.2874758220502902, 'step': 10650}\n",
      "{'loss': 0.6158203125, 'learning_rate': 1.7737548355899418e-05, 'epoch': 1.2904980657640233, 'step': 10675}\n",
      "{'loss': 0.7470703125, 'learning_rate': 1.7661992263056093e-05, 'epoch': 1.2935203094777563, 'step': 10700}\n",
      "{'loss': 0.6934765625, 'learning_rate': 1.758643617021277e-05, 'epoch': 1.2965425531914894, 'step': 10725}\n",
      "{'loss': 0.7871484375, 'learning_rate': 1.751088007736944e-05, 'epoch': 1.2995647969052224, 'step': 10750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f3752df6d54c12b4244f5904d13eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8073113518206037, 'eval_acc': 0.6760946423714985, 'eval_f1': 0.5391247326725016, 'eval_acc_and_f1': 0.6076096875220001, 'eval_mcc': 0.40874558453387155, 'epoch': 1.2995647969052224, 'step': 10750}\n",
      "{'loss': 0.6044921875, 'learning_rate': 1.7435323984526115e-05, 'epoch': 1.3025870406189555, 'step': 10775}\n",
      "{'loss': 0.9712109375, 'learning_rate': 1.7359767891682784e-05, 'epoch': 1.3056092843326885, 'step': 10800}\n",
      "{'loss': 0.7278515625, 'learning_rate': 1.728421179883946e-05, 'epoch': 1.3086315280464218, 'step': 10825}\n",
      "{'loss': 0.7337109375, 'learning_rate': 1.720865570599613e-05, 'epoch': 1.3116537717601546, 'step': 10850}\n",
      "{'loss': 0.787734375, 'learning_rate': 1.7133099613152806e-05, 'epoch': 1.314676015473888, 'step': 10875}\n",
      "{'loss': 0.706171875, 'learning_rate': 1.705754352030948e-05, 'epoch': 1.317698259187621, 'step': 10900}\n",
      "{'loss': 0.71890625, 'learning_rate': 1.698198742746615e-05, 'epoch': 1.320720502901354, 'step': 10925}\n",
      "{'loss': 0.6488671875, 'learning_rate': 1.6906431334622825e-05, 'epoch': 1.323742746615087, 'step': 10950}\n",
      "{'loss': 0.55140625, 'learning_rate': 1.6830875241779497e-05, 'epoch': 1.3267649903288201, 'step': 10975}\n",
      "{'loss': 0.6089453125, 'learning_rate': 1.6755319148936172e-05, 'epoch': 1.3297872340425532, 'step': 11000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ce48c9139749bcae6d840bff3735aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7754791646442045, 'eval_acc': 0.6796301332608105, 'eval_f1': 0.5367557159757678, 'eval_acc_and_f1': 0.6081929246182891, 'eval_mcc': 0.4110362497003527, 'epoch': 1.3297872340425532, 'step': 11000}\n",
      "{'loss': 0.8075390625, 'learning_rate': 1.6679763056092844e-05, 'epoch': 1.3328094777562862, 'step': 11025}\n",
      "{'loss': 0.90578125, 'learning_rate': 1.6604206963249516e-05, 'epoch': 1.3358317214700193, 'step': 11050}\n",
      "{'loss': 0.5821875, 'learning_rate': 1.652865087040619e-05, 'epoch': 1.3388539651837523, 'step': 11075}\n",
      "{'loss': 0.7258203125, 'learning_rate': 1.6453094777562863e-05, 'epoch': 1.3418762088974856, 'step': 11100}\n",
      "{'loss': 0.601171875, 'learning_rate': 1.6377538684719538e-05, 'epoch': 1.3448984526112184, 'step': 11125}\n",
      "{'loss': 0.9306640625, 'learning_rate': 1.630198259187621e-05, 'epoch': 1.3479206963249517, 'step': 11150}\n",
      "{'loss': 0.5467578125, 'learning_rate': 1.622642649903288e-05, 'epoch': 1.3509429400386848, 'step': 11175}\n",
      "{'loss': 0.693671875, 'learning_rate': 1.6150870406189557e-05, 'epoch': 1.3539651837524178, 'step': 11200}\n",
      "{'loss': 0.6371875, 'learning_rate': 1.607531431334623e-05, 'epoch': 1.3569874274661509, 'step': 11225}\n",
      "{'loss': 0.6602734375, 'learning_rate': 1.5999758220502904e-05, 'epoch': 1.360009671179884, 'step': 11250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6897692d3f41a19e09ec91c1412a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8311727668138701, 'eval_acc': 0.6782703290726135, 'eval_f1': 0.5622190300253888, 'eval_acc_and_f1': 0.6202446795490011, 'eval_mcc': 0.41565922148085493, 'epoch': 1.360009671179884, 'step': 11250}\n",
      "{'loss': 0.64875, 'learning_rate': 1.5924202127659576e-05, 'epoch': 1.363031914893617, 'step': 11275}\n",
      "{'loss': 0.658046875, 'learning_rate': 1.5848646034816248e-05, 'epoch': 1.36605415860735, 'step': 11300}\n",
      "{'loss': 0.7108984375, 'learning_rate': 1.577308994197292e-05, 'epoch': 1.3690764023210833, 'step': 11325}\n",
      "{'loss': 0.5069921875, 'learning_rate': 1.5697533849129595e-05, 'epoch': 1.3720986460348161, 'step': 11350}\n",
      "{'loss': 0.700625, 'learning_rate': 1.562197775628627e-05, 'epoch': 1.3751208897485494, 'step': 11375}\n",
      "{'loss': 0.605546875, 'learning_rate': 1.5546421663442942e-05, 'epoch': 1.3781431334622825, 'step': 11400}\n",
      "{'loss': 0.6319140625, 'learning_rate': 1.5470865570599614e-05, 'epoch': 1.3811653771760155, 'step': 11425}\n",
      "{'loss': 0.6493359375, 'learning_rate': 1.5395309477756285e-05, 'epoch': 1.3841876208897486, 'step': 11450}\n",
      "{'loss': 0.6788671875, 'learning_rate': 1.531975338491296e-05, 'epoch': 1.3872098646034816, 'step': 11475}\n",
      "{'loss': 0.6384375, 'learning_rate': 1.5244197292069634e-05, 'epoch': 1.3902321083172147, 'step': 11500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb09fee5cb4c4fee9c7984b15a9d1aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8152965742639786, 'eval_acc': 0.6823497416372042, 'eval_f1': 0.5495669800732506, 'eval_acc_and_f1': 0.6159583608552274, 'eval_mcc': 0.4163350972047007, 'epoch': 1.3902321083172147, 'step': 11500}\n",
      "{'loss': 0.5877734375, 'learning_rate': 1.5168641199226304e-05, 'epoch': 1.3932543520309477, 'step': 11525}\n",
      "{'loss': 0.6640625, 'learning_rate': 1.5093085106382978e-05, 'epoch': 1.3962765957446808, 'step': 11550}\n",
      "{'loss': 0.7695703125, 'learning_rate': 1.5017529013539653e-05, 'epoch': 1.3992988394584138, 'step': 11575}\n",
      "{'loss': 0.59875, 'learning_rate': 1.4941972920696327e-05, 'epoch': 1.402321083172147, 'step': 11600}\n",
      "{'loss': 0.7454296875, 'learning_rate': 1.4866416827853e-05, 'epoch': 1.4053433268858802, 'step': 11625}\n",
      "{'loss': 0.572890625, 'learning_rate': 1.479086073500967e-05, 'epoch': 1.4083655705996132, 'step': 11650}\n",
      "{'loss': 0.760078125, 'learning_rate': 1.4715304642166344e-05, 'epoch': 1.4113878143133463, 'step': 11675}\n",
      "{'loss': 0.5198046875, 'learning_rate': 1.4639748549323017e-05, 'epoch': 1.4144100580270793, 'step': 11700}\n",
      "{'loss': 0.6778515625, 'learning_rate': 1.456419245647969e-05, 'epoch': 1.4174323017408124, 'step': 11725}\n",
      "{'loss': 0.7112890625, 'learning_rate': 1.4488636363636366e-05, 'epoch': 1.4204545454545454, 'step': 11750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9be0d7e18d7402c9b60bc6c3a54dfa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8532948053528311, 'eval_acc': 0.6747348381833016, 'eval_f1': 0.604198952239836, 'eval_acc_and_f1': 0.6394668952115687, 'eval_mcc': 0.4215524953277641, 'epoch': 1.4204545454545454, 'step': 11750}\n",
      "{'loss': 0.53953125, 'learning_rate': 1.4413080270793036e-05, 'epoch': 1.4234767891682785, 'step': 11775}\n",
      "{'loss': 0.73484375, 'learning_rate': 1.433752417794971e-05, 'epoch': 1.4264990328820115, 'step': 11800}\n",
      "{'loss': 0.816171875, 'learning_rate': 1.4261968085106383e-05, 'epoch': 1.4295212765957448, 'step': 11825}\n",
      "{'loss': 0.5478125, 'learning_rate': 1.4186411992263057e-05, 'epoch': 1.4325435203094776, 'step': 11850}\n",
      "{'loss': 0.6599609375, 'learning_rate': 1.411085589941973e-05, 'epoch': 1.435565764023211, 'step': 11875}\n",
      "{'loss': 0.5933203125, 'learning_rate': 1.4035299806576402e-05, 'epoch': 1.438588007736944, 'step': 11900}\n",
      "{'loss': 0.7298046875, 'learning_rate': 1.3959743713733076e-05, 'epoch': 1.441610251450677, 'step': 11925}\n",
      "{'loss': 0.6496484375, 'learning_rate': 1.388418762088975e-05, 'epoch': 1.44463249516441, 'step': 11950}\n",
      "{'loss': 0.5290234375, 'learning_rate': 1.3808631528046423e-05, 'epoch': 1.447654738878143, 'step': 11975}\n",
      "{'loss': 0.579609375, 'learning_rate': 1.3733075435203096e-05, 'epoch': 1.4506769825918762, 'step': 12000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d976bd6d2dd4a919f165eaad055fa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.872068438025509, 'eval_acc': 0.6818058199619255, 'eval_f1': 0.5445719661506591, 'eval_acc_and_f1': 0.6131888930562923, 'eval_mcc': 0.41642314021078247, 'epoch': 1.4506769825918762, 'step': 12000}\n",
      "{'loss': 0.7625390625, 'learning_rate': 1.3657519342359768e-05, 'epoch': 1.4536992263056092, 'step': 12025}\n",
      "{'loss': 0.752734375, 'learning_rate': 1.3581963249516442e-05, 'epoch': 1.4567214700193425, 'step': 12050}\n",
      "{'loss': 0.7381640625, 'learning_rate': 1.3506407156673115e-05, 'epoch': 1.4597437137330753, 'step': 12075}\n",
      "{'loss': 0.6978515625, 'learning_rate': 1.3430851063829789e-05, 'epoch': 1.4627659574468086, 'step': 12100}\n",
      "{'loss': 0.629296875, 'learning_rate': 1.3355294970986462e-05, 'epoch': 1.4657882011605416, 'step': 12125}\n",
      "{'loss': 0.7349609375, 'learning_rate': 1.3279738878143132e-05, 'epoch': 1.4688104448742747, 'step': 12150}\n",
      "{'loss': 0.758984375, 'learning_rate': 1.3204182785299808e-05, 'epoch': 1.4718326885880078, 'step': 12175}\n",
      "{'loss': 0.721953125, 'learning_rate': 1.3128626692456481e-05, 'epoch': 1.4748549323017408, 'step': 12200}\n",
      "{'loss': 0.6853515625, 'learning_rate': 1.3053070599613155e-05, 'epoch': 1.4778771760154739, 'step': 12225}\n",
      "{'loss': 0.71015625, 'learning_rate': 1.2977514506769828e-05, 'epoch': 1.480899419729207, 'step': 12250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd8426dbe40401c96d416e56873b5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8321950249870348, 'eval_acc': 0.6619526788142508, 'eval_f1': 0.5680975318327456, 'eval_acc_and_f1': 0.6150251053234982, 'eval_mcc': 0.4029838179626449, 'epoch': 1.480899419729207, 'step': 12250}\n",
      "{'loss': 0.6734765625, 'learning_rate': 1.2901958413926498e-05, 'epoch': 1.48392166344294, 'step': 12275}\n",
      "{'loss': 0.6538671875, 'learning_rate': 1.2826402321083172e-05, 'epoch': 1.486943907156673, 'step': 12300}\n",
      "{'loss': 0.668359375, 'learning_rate': 1.2750846228239845e-05, 'epoch': 1.4899661508704063, 'step': 12325}\n",
      "{'loss': 0.695625, 'learning_rate': 1.267529013539652e-05, 'epoch': 1.4929883945841393, 'step': 12350}\n",
      "{'loss': 0.5827734375, 'learning_rate': 1.2599734042553194e-05, 'epoch': 1.4960106382978724, 'step': 12375}\n",
      "{'loss': 0.7866796875, 'learning_rate': 1.2524177949709864e-05, 'epoch': 1.4990328820116054, 'step': 12400}\n",
      "{'loss': 0.546171875, 'learning_rate': 1.2448621856866538e-05, 'epoch': 1.5020551257253385, 'step': 12425}\n",
      "{'loss': 0.7602734375, 'learning_rate': 1.2373065764023211e-05, 'epoch': 1.5050773694390716, 'step': 12450}\n",
      "{'loss': 0.504375, 'learning_rate': 1.2297509671179885e-05, 'epoch': 1.5080996131528046, 'step': 12475}\n",
      "{'loss': 0.667578125, 'learning_rate': 1.2221953578336558e-05, 'epoch': 1.5111218568665379, 'step': 12500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5591e18d3e47a194933ad2df32fb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8303578276494161, 'eval_acc': 0.680717976611368, 'eval_f1': 0.6022584774838359, 'eval_acc_and_f1': 0.6414882270476019, 'eval_mcc': 0.4266930755548204, 'epoch': 1.5111218568665379, 'step': 12500}\n",
      "{'loss': 0.925, 'learning_rate': 1.2146397485493232e-05, 'epoch': 1.5141441005802707, 'step': 12525}\n",
      "{'loss': 0.6590625, 'learning_rate': 1.2070841392649904e-05, 'epoch': 1.517166344294004, 'step': 12550}\n",
      "{'loss': 0.6948828125, 'learning_rate': 1.1995285299806577e-05, 'epoch': 1.5201885880077368, 'step': 12575}\n",
      "{'loss': 0.5644921875, 'learning_rate': 1.1919729206963249e-05, 'epoch': 1.52321083172147, 'step': 12600}\n",
      "{'loss': 0.675703125, 'learning_rate': 1.1844173114119923e-05, 'epoch': 1.5262330754352031, 'step': 12625}\n",
      "{'loss': 0.69546875, 'learning_rate': 1.1768617021276596e-05, 'epoch': 1.5292553191489362, 'step': 12650}\n",
      "{'loss': 0.5032421875, 'learning_rate': 1.169306092843327e-05, 'epoch': 1.5322775628626693, 'step': 12675}\n",
      "{'loss': 0.6504296875, 'learning_rate': 1.1617504835589943e-05, 'epoch': 1.5352998065764023, 'step': 12700}\n",
      "{'loss': 0.5705078125, 'learning_rate': 1.1541948742746615e-05, 'epoch': 1.5383220502901354, 'step': 12725}\n",
      "{'loss': 0.56828125, 'learning_rate': 1.1466392649903289e-05, 'epoch': 1.5413442940038684, 'step': 12750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6948950e1fa44564bdd91fad8cc8c32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8321558526102408, 'eval_acc': 0.6774544465596954, 'eval_f1': 0.5597588962355579, 'eval_acc_and_f1': 0.6186066713976266, 'eval_mcc': 0.4141750446005201, 'epoch': 1.5413442940038684, 'step': 12750}\n",
      "{'loss': 0.632265625, 'learning_rate': 1.139083655705996e-05, 'epoch': 1.5443665377176017, 'step': 12775}\n",
      "{'loss': 0.517578125, 'learning_rate': 1.1315280464216636e-05, 'epoch': 1.5473887814313345, 'step': 12800}\n",
      "{'loss': 0.8140625, 'learning_rate': 1.123972437137331e-05, 'epoch': 1.5504110251450678, 'step': 12825}\n",
      "{'loss': 0.7364453125, 'learning_rate': 1.1164168278529981e-05, 'epoch': 1.5534332688588006, 'step': 12850}\n",
      "{'loss': 0.618984375, 'learning_rate': 1.1088612185686655e-05, 'epoch': 1.556455512572534, 'step': 12875}\n",
      "{'loss': 0.6384765625, 'learning_rate': 1.1013056092843326e-05, 'epoch': 1.559477756286267, 'step': 12900}\n",
      "{'loss': 0.7055078125, 'learning_rate': 1.09375e-05, 'epoch': 1.5625, 'step': 12925}\n",
      "{'loss': 0.7535546875, 'learning_rate': 1.0861943907156673e-05, 'epoch': 1.565522243713733, 'step': 12950}\n",
      "{'loss': 0.645859375, 'learning_rate': 1.0786387814313347e-05, 'epoch': 1.568544487427466, 'step': 12975}\n",
      "{'loss': 0.769140625, 'learning_rate': 1.071083172147002e-05, 'epoch': 1.5715667311411994, 'step': 13000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3d1ba0724e45ad8c13be49a940f9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7967352283075513, 'eval_acc': 0.682893663312483, 'eval_f1': 0.5891651193166075, 'eval_acc_and_f1': 0.6360293913145453, 'eval_mcc': 0.4212862133729652, 'epoch': 1.5715667311411994, 'step': 13000}\n",
      "{'loss': 0.695703125, 'learning_rate': 1.0635275628626692e-05, 'epoch': 1.5745889748549322, 'step': 13025}\n",
      "{'loss': 0.7419921875, 'learning_rate': 1.0559719535783366e-05, 'epoch': 1.5776112185686655, 'step': 13050}\n",
      "{'loss': 0.6768359375, 'learning_rate': 1.048416344294004e-05, 'epoch': 1.5806334622823983, 'step': 13075}\n",
      "{'loss': 0.733046875, 'learning_rate': 1.0408607350096713e-05, 'epoch': 1.5836557059961316, 'step': 13100}\n",
      "{'loss': 0.7565625, 'learning_rate': 1.0333051257253386e-05, 'epoch': 1.5866779497098646, 'step': 13125}\n",
      "{'loss': 0.7214453125, 'learning_rate': 1.0257495164410058e-05, 'epoch': 1.5897001934235977, 'step': 13150}\n",
      "{'loss': 0.6215234375, 'learning_rate': 1.0181939071566732e-05, 'epoch': 1.5927224371373307, 'step': 13175}\n",
      "{'loss': 0.57578125, 'learning_rate': 1.0106382978723404e-05, 'epoch': 1.5957446808510638, 'step': 13200}\n",
      "{'loss': 0.7844140625, 'learning_rate': 1.0030826885880077e-05, 'epoch': 1.5987669245647969, 'step': 13225}\n",
      "{'loss': 0.7103515625, 'learning_rate': 9.95527079303675e-06, 'epoch': 1.60178916827853, 'step': 13250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1601160aa76945e9869029c2f661a2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7817253343495526, 'eval_acc': 0.6847973891759587, 'eval_f1': 0.5883903380714738, 'eval_acc_and_f1': 0.6365938636237163, 'eval_mcc': 0.42859533705360664, 'epoch': 1.60178916827853, 'step': 13250}\n",
      "{'loss': 0.7472265625, 'learning_rate': 9.879714700193424e-06, 'epoch': 1.6048114119922632, 'step': 13275}\n",
      "{'loss': 0.509140625, 'learning_rate': 9.804158607350098e-06, 'epoch': 1.607833655705996, 'step': 13300}\n",
      "{'loss': 0.577578125, 'learning_rate': 9.72860251450677e-06, 'epoch': 1.6108558994197293, 'step': 13325}\n",
      "{'loss': 0.6192578125, 'learning_rate': 9.653046421663443e-06, 'epoch': 1.6138781431334621, 'step': 13350}\n",
      "{'loss': 0.71625, 'learning_rate': 9.577490328820117e-06, 'epoch': 1.6169003868471954, 'step': 13375}\n",
      "{'loss': 0.713203125, 'learning_rate': 9.50193423597679e-06, 'epoch': 1.6199226305609284, 'step': 13400}\n",
      "{'loss': 0.615625, 'learning_rate': 9.426378143133464e-06, 'epoch': 1.6229448742746615, 'step': 13425}\n",
      "{'loss': 0.709453125, 'learning_rate': 9.350822050290136e-06, 'epoch': 1.6259671179883946, 'step': 13450}\n",
      "{'loss': 0.796796875, 'learning_rate': 9.275265957446809e-06, 'epoch': 1.6289893617021276, 'step': 13475}\n",
      "{'loss': 0.6339453125, 'learning_rate': 9.199709864603483e-06, 'epoch': 1.6320116054158609, 'step': 13500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a7862c6c114161a1368f9433e50541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7755250398931797, 'eval_acc': 0.6880609192276312, 'eval_f1': 0.5965093184794813, 'eval_acc_and_f1': 0.6422851188535563, 'eval_mcc': 0.43230678977818754, 'epoch': 1.6320116054158609, 'step': 13500}\n",
      "{'loss': 0.694921875, 'learning_rate': 9.124153771760154e-06, 'epoch': 1.6350338491295937, 'step': 13525}\n",
      "{'loss': 0.6614453125, 'learning_rate': 9.048597678916828e-06, 'epoch': 1.638056092843327, 'step': 13550}\n",
      "{'loss': 0.5816796875, 'learning_rate': 8.973041586073501e-06, 'epoch': 1.6410783365570598, 'step': 13575}\n",
      "{'loss': 0.6897265625, 'learning_rate': 8.897485493230175e-06, 'epoch': 1.644100580270793, 'step': 13600}\n",
      "{'loss': 0.6283984375, 'learning_rate': 8.821929400386849e-06, 'epoch': 1.6471228239845261, 'step': 13625}\n",
      "{'loss': 0.7302734375, 'learning_rate': 8.74637330754352e-06, 'epoch': 1.6501450676982592, 'step': 13650}\n",
      "{'loss': 0.706640625, 'learning_rate': 8.670817214700194e-06, 'epoch': 1.6531673114119922, 'step': 13675}\n",
      "{'loss': 0.5562109375, 'learning_rate': 8.595261121856866e-06, 'epoch': 1.6561895551257253, 'step': 13700}\n",
      "{'loss': 0.5355859375, 'learning_rate': 8.519705029013541e-06, 'epoch': 1.6592117988394586, 'step': 13725}\n",
      "{'loss': 0.4793359375, 'learning_rate': 8.444148936170213e-06, 'epoch': 1.6622340425531914, 'step': 13750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1204d81962425880916d497140617a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8093735677151372, 'eval_acc': 0.6899646450911069, 'eval_f1': 0.6213922217898126, 'eval_acc_and_f1': 0.6556784334404597, 'eval_mcc': 0.4455804678813514, 'epoch': 1.6622340425531914, 'step': 13750}\n",
      "{'loss': 0.6541796875, 'learning_rate': 8.368592843326886e-06, 'epoch': 1.6652562862669247, 'step': 13775}\n",
      "{'loss': 0.6628515625, 'learning_rate': 8.29303675048356e-06, 'epoch': 1.6682785299806575, 'step': 13800}\n",
      "{'loss': 0.9248828125, 'learning_rate': 8.217480657640232e-06, 'epoch': 1.6713007736943908, 'step': 13825}\n",
      "{'loss': 0.7953515625, 'learning_rate': 8.141924564796905e-06, 'epoch': 1.6743230174081238, 'step': 13850}\n",
      "{'loss': 0.586875, 'learning_rate': 8.066368471953579e-06, 'epoch': 1.677345261121857, 'step': 13875}\n",
      "{'loss': 0.7148828125, 'learning_rate': 7.990812379110252e-06, 'epoch': 1.68036750483559, 'step': 13900}\n",
      "{'loss': 0.6301171875, 'learning_rate': 7.915256286266926e-06, 'epoch': 1.683389748549323, 'step': 13925}\n",
      "{'loss': 0.654296875, 'learning_rate': 7.839700193423598e-06, 'epoch': 1.686411992263056, 'step': 13950}\n",
      "{'loss': 0.589296875, 'learning_rate': 7.764144100580271e-06, 'epoch': 1.689434235976789, 'step': 13975}\n",
      "{'loss': 0.5573046875, 'learning_rate': 7.688588007736943e-06, 'epoch': 1.6924564796905224, 'step': 14000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb8fc1e68da443ca2a6673d8160c8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.841125795609088, 'eval_acc': 0.6799020940984498, 'eval_f1': 0.5790097952223014, 'eval_acc_and_f1': 0.6294559446603756, 'eval_mcc': 0.4230339029008958, 'epoch': 1.6924564796905224, 'step': 14000}\n",
      "{'loss': 0.7533203125, 'learning_rate': 7.613031914893617e-06, 'epoch': 1.6954787234042552, 'step': 14025}\n",
      "{'loss': 0.492265625, 'learning_rate': 7.537475822050291e-06, 'epoch': 1.6985009671179885, 'step': 14050}\n",
      "{'loss': 0.7846484375, 'learning_rate': 7.4619197292069636e-06, 'epoch': 1.7015232108317213, 'step': 14075}\n",
      "{'loss': 0.63984375, 'learning_rate': 7.386363636363637e-06, 'epoch': 1.7045454545454546, 'step': 14100}\n",
      "{'loss': 0.6621875, 'learning_rate': 7.31080754352031e-06, 'epoch': 1.7075676982591876, 'step': 14125}\n",
      "{'loss': 0.7330078125, 'learning_rate': 7.235251450676983e-06, 'epoch': 1.7105899419729207, 'step': 14150}\n",
      "{'loss': 0.5211328125, 'learning_rate': 7.159695357833655e-06, 'epoch': 1.7136121856866537, 'step': 14175}\n",
      "{'loss': 0.7233203125, 'learning_rate': 7.084139264990329e-06, 'epoch': 1.7166344294003868, 'step': 14200}\n",
      "{'loss': 0.8192578125, 'learning_rate': 7.008583172147003e-06, 'epoch': 1.71965667311412, 'step': 14225}\n",
      "{'loss': 0.585078125, 'learning_rate': 6.933027079303675e-06, 'epoch': 1.722678916827853, 'step': 14250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db447b7647554f15aa10b0eb35704d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8293210192157225, 'eval_acc': 0.6834375849877617, 'eval_f1': 0.5733535901818673, 'eval_acc_and_f1': 0.6283955875848145, 'eval_mcc': 0.425720086661124, 'epoch': 1.722678916827853, 'step': 14250}\n",
      "{'loss': 0.7759375, 'learning_rate': 6.857470986460348e-06, 'epoch': 1.7257011605415862, 'step': 14275}\n",
      "{'loss': 0.608984375, 'learning_rate': 6.781914893617021e-06, 'epoch': 1.728723404255319, 'step': 14300}\n",
      "{'loss': 0.7168359375, 'learning_rate': 6.706358800773695e-06, 'epoch': 1.7317456479690523, 'step': 14325}\n",
      "{'loss': 0.5714453125, 'learning_rate': 6.630802707930368e-06, 'epoch': 1.7347678916827853, 'step': 14350}\n",
      "{'loss': 0.6267578125, 'learning_rate': 6.555246615087041e-06, 'epoch': 1.7377901353965184, 'step': 14375}\n",
      "{'loss': 0.6390625, 'learning_rate': 6.479690522243714e-06, 'epoch': 1.7408123791102514, 'step': 14400}\n",
      "{'loss': 0.577265625, 'learning_rate': 6.404134429400386e-06, 'epoch': 1.7438346228239845, 'step': 14425}\n",
      "{'loss': 0.6109375, 'learning_rate': 6.3285783365570606e-06, 'epoch': 1.7468568665377178, 'step': 14450}\n",
      "{'loss': 0.4794140625, 'learning_rate': 6.253022243713734e-06, 'epoch': 1.7498791102514506, 'step': 14475}\n",
      "{'loss': 0.613359375, 'learning_rate': 6.177466150870406e-06, 'epoch': 1.7529013539651839, 'step': 14500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0ec946332e4879b0089489faeed042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8396475095446745, 'eval_acc': 0.6834375849877617, 'eval_f1': 0.5903478439418794, 'eval_acc_and_f1': 0.6368927144648207, 'eval_mcc': 0.4269129136907057, 'epoch': 1.7529013539651839, 'step': 14500}\n",
      "{'loss': 0.6132421875, 'learning_rate': 6.10191005802708e-06, 'epoch': 1.7559235976789167, 'step': 14525}\n",
      "{'loss': 0.6459375, 'learning_rate': 6.026353965183753e-06, 'epoch': 1.75894584139265, 'step': 14550}\n",
      "{'loss': 0.636015625, 'learning_rate': 5.950797872340426e-06, 'epoch': 1.761968085106383, 'step': 14575}\n",
      "{'loss': 0.66375, 'learning_rate': 5.875241779497099e-06, 'epoch': 1.764990328820116, 'step': 14600}\n",
      "{'loss': 0.700078125, 'learning_rate': 5.799685686653772e-06, 'epoch': 1.7680125725338491, 'step': 14625}\n",
      "{'loss': 0.709609375, 'learning_rate': 5.7241295938104446e-06, 'epoch': 1.7710348162475822, 'step': 14650}\n",
      "{'loss': 0.8049609375, 'learning_rate': 5.648573500967119e-06, 'epoch': 1.7740570599613152, 'step': 14675}\n",
      "{'loss': 0.787109375, 'learning_rate': 5.573017408123792e-06, 'epoch': 1.7770793036750483, 'step': 14700}\n",
      "{'loss': 0.6276171875, 'learning_rate': 5.497461315280464e-06, 'epoch': 1.7801015473887816, 'step': 14725}\n",
      "{'loss': 0.5299609375, 'learning_rate': 5.421905222437138e-06, 'epoch': 1.7831237911025144, 'step': 14750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea6ac0086794a3eb2ea4474cf3efb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7997300616418145, 'eval_acc': 0.6831656241501224, 'eval_f1': 0.6126120846837978, 'eval_acc_and_f1': 0.6478888544169601, 'eval_mcc': 0.43536099666650685, 'epoch': 1.7831237911025144, 'step': 14750}\n",
      "{'loss': 0.798515625, 'learning_rate': 5.3463491295938105e-06, 'epoch': 1.7861460348162477, 'step': 14775}\n",
      "{'loss': 0.507734375, 'learning_rate': 5.270793036750483e-06, 'epoch': 1.7891682785299805, 'step': 14800}\n",
      "{'loss': 0.6697265625, 'learning_rate': 5.195236943907157e-06, 'epoch': 1.7921905222437138, 'step': 14825}\n",
      "{'loss': 0.82984375, 'learning_rate': 5.11968085106383e-06, 'epoch': 1.7952127659574468, 'step': 14850}\n",
      "{'loss': 0.7106640625, 'learning_rate': 5.044124758220503e-06, 'epoch': 1.7982350096711799, 'step': 14875}\n",
      "{'loss': 0.502265625, 'learning_rate': 4.9685686653771765e-06, 'epoch': 1.801257253384913, 'step': 14900}\n",
      "{'loss': 0.709375, 'learning_rate': 4.893012572533849e-06, 'epoch': 1.804279497098646, 'step': 14925}\n",
      "{'loss': 0.6493359375, 'learning_rate': 4.817456479690523e-06, 'epoch': 1.8073017408123793, 'step': 14950}\n",
      "{'loss': 0.5358984375, 'learning_rate': 4.741900386847195e-06, 'epoch': 1.810323984526112, 'step': 14975}\n",
      "{'loss': 0.63140625, 'learning_rate': 4.666344294003869e-06, 'epoch': 1.8133462282398454, 'step': 15000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32070490b9e94aca85141bd2c87711ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.7986846135172923, 'eval_acc': 0.6896926842534675, 'eval_f1': 0.6156901280177278, 'eval_acc_and_f1': 0.6526914061355977, 'eval_mcc': 0.4431497778396136, 'epoch': 1.8133462282398454, 'step': 15000}\n",
      "{'loss': 0.5160546875, 'learning_rate': 4.5907882011605416e-06, 'epoch': 1.8163684719535782, 'step': 15025}\n",
      "{'loss': 0.67734375, 'learning_rate': 4.515232108317215e-06, 'epoch': 1.8193907156673115, 'step': 15050}\n",
      "{'loss': 0.6253515625, 'learning_rate': 4.439676015473888e-06, 'epoch': 1.8224129593810445, 'step': 15075}\n",
      "{'loss': 0.707265625, 'learning_rate': 4.364119922630561e-06, 'epoch': 1.8254352030947776, 'step': 15100}\n",
      "{'loss': 0.804609375, 'learning_rate': 4.288563829787234e-06, 'epoch': 1.8284574468085106, 'step': 15125}\n",
      "{'loss': 0.6090625, 'learning_rate': 4.2130077369439075e-06, 'epoch': 1.8314796905222437, 'step': 15150}\n",
      "{'loss': 0.6454296875, 'learning_rate': 4.13745164410058e-06, 'epoch': 1.8345019342359767, 'step': 15175}\n",
      "{'loss': 0.5914453125, 'learning_rate': 4.061895551257254e-06, 'epoch': 1.8375241779497098, 'step': 15200}\n",
      "{'loss': 0.6589453125, 'learning_rate': 3.986339458413927e-06, 'epoch': 1.840546421663443, 'step': 15225}\n",
      "{'loss': 0.62640625, 'learning_rate': 3.9107833655706e-06, 'epoch': 1.843568665377176, 'step': 15250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b330630da824a74aa4b61012fe0c1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.839164436625371, 'eval_acc': 0.6777264073973348, 'eval_f1': 0.5621200002424802, 'eval_acc_and_f1': 0.6199232038199075, 'eval_mcc': 0.4180163817094177, 'epoch': 1.843568665377176, 'step': 15250}\n",
      "{'loss': 0.72140625, 'learning_rate': 3.835227272727273e-06, 'epoch': 1.8465909090909092, 'step': 15275}\n",
      "{'loss': 0.6748046875, 'learning_rate': 3.759671179883946e-06, 'epoch': 1.849613152804642, 'step': 15300}\n",
      "{'loss': 0.7210546875, 'learning_rate': 3.684115087040619e-06, 'epoch': 1.8526353965183753, 'step': 15325}\n",
      "{'loss': 0.6316015625, 'learning_rate': 3.608558994197292e-06, 'epoch': 1.8556576402321083, 'step': 15350}\n",
      "{'loss': 0.732734375, 'learning_rate': 3.5330029013539655e-06, 'epoch': 1.8586798839458414, 'step': 15375}\n",
      "{'loss': 0.57734375, 'learning_rate': 3.4574468085106386e-06, 'epoch': 1.8617021276595744, 'step': 15400}\n",
      "{'loss': 0.55796875, 'learning_rate': 3.3818907156673117e-06, 'epoch': 1.8647243713733075, 'step': 15425}\n",
      "{'loss': 0.518828125, 'learning_rate': 3.3063346228239844e-06, 'epoch': 1.8677466150870408, 'step': 15450}\n",
      "{'loss': 0.4711328125, 'learning_rate': 3.2307785299806575e-06, 'epoch': 1.8707688588007736, 'step': 15475}\n",
      "{'loss': 0.704140625, 'learning_rate': 3.1552224371373314e-06, 'epoch': 1.8737911025145069, 'step': 15500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457be5caee434120adbda2f4702aa1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8250352314771892, 'eval_acc': 0.6837095458254011, 'eval_f1': 0.5982038625025291, 'eval_acc_and_f1': 0.6409567041639651, 'eval_mcc': 0.431163334794761, 'epoch': 1.8737911025145069, 'step': 15500}\n",
      "{'loss': 0.679609375, 'learning_rate': 3.0796663442940037e-06, 'epoch': 1.8768133462282397, 'step': 15525}\n",
      "{'loss': 0.598515625, 'learning_rate': 3.004110251450677e-06, 'epoch': 1.879835589941973, 'step': 15550}\n",
      "{'loss': 0.6331640625, 'learning_rate': 2.9285541586073503e-06, 'epoch': 1.882857833655706, 'step': 15575}\n",
      "{'loss': 0.4980859375, 'learning_rate': 2.852998065764023e-06, 'epoch': 1.885880077369439, 'step': 15600}\n",
      "{'loss': 0.9093359375, 'learning_rate': 2.7774419729206965e-06, 'epoch': 1.8889023210831721, 'step': 15625}\n",
      "{'loss': 0.5820703125, 'learning_rate': 2.7018858800773696e-06, 'epoch': 1.8919245647969052, 'step': 15650}\n",
      "{'loss': 0.5544921875, 'learning_rate': 2.6263297872340427e-06, 'epoch': 1.8949468085106385, 'step': 15675}\n",
      "{'loss': 0.8506640625, 'learning_rate': 2.550773694390716e-06, 'epoch': 1.8979690522243713, 'step': 15700}\n",
      "{'loss': 0.779921875, 'learning_rate': 2.475217601547389e-06, 'epoch': 1.9009912959381046, 'step': 15725}\n",
      "{'loss': 0.675703125, 'learning_rate': 2.399661508704062e-06, 'epoch': 1.9040135396518374, 'step': 15750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86de923417a5420c9d526a2e5613dcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8360795564939382, 'eval_acc': 0.6834375849877617, 'eval_f1': 0.5978043972841962, 'eval_acc_and_f1': 0.640620991135979, 'eval_mcc': 0.43220080059785443, 'epoch': 1.9040135396518374, 'step': 15750}\n",
      "{'loss': 0.6886328125, 'learning_rate': 2.324105415860735e-06, 'epoch': 1.9070357833655707, 'step': 15775}\n",
      "{'loss': 0.6604296875, 'learning_rate': 2.2485493230174083e-06, 'epoch': 1.9100580270793037, 'step': 15800}\n",
      "{'loss': 0.6039453125, 'learning_rate': 2.1729932301740814e-06, 'epoch': 1.9130802707930368, 'step': 15825}\n",
      "{'loss': 0.525390625, 'learning_rate': 2.0974371373307545e-06, 'epoch': 1.9161025145067698, 'step': 15850}\n",
      "{'loss': 0.64125, 'learning_rate': 2.0218810444874276e-06, 'epoch': 1.9191247582205029, 'step': 15875}\n",
      "{'loss': 0.653671875, 'learning_rate': 1.9463249516441007e-06, 'epoch': 1.922147001934236, 'step': 15900}\n",
      "{'loss': 0.59, 'learning_rate': 1.8707688588007738e-06, 'epoch': 1.925169245647969, 'step': 15925}\n",
      "{'loss': 0.7293359375, 'learning_rate': 1.795212765957447e-06, 'epoch': 1.9281914893617023, 'step': 15950}\n",
      "{'loss': 0.812578125, 'learning_rate': 1.71965667311412e-06, 'epoch': 1.931213733075435, 'step': 15975}\n",
      "{'loss': 0.4530859375, 'learning_rate': 1.644100580270793e-06, 'epoch': 1.9342359767891684, 'step': 16000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acb872164e648da90d0d0cb0e5e5860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8487063521417484, 'eval_acc': 0.6839815066630405, 'eval_f1': 0.5956696218360604, 'eval_acc_and_f1': 0.6398255642495505, 'eval_mcc': 0.4319220445692527, 'epoch': 1.9342359767891684, 'step': 16000}\n",
      "{'loss': 0.5973828125, 'learning_rate': 1.5685444874274664e-06, 'epoch': 1.9372582205029012, 'step': 16025}\n",
      "{'loss': 0.515390625, 'learning_rate': 1.4929883945841393e-06, 'epoch': 1.9402804642166345, 'step': 16050}\n",
      "{'loss': 0.786796875, 'learning_rate': 1.4174323017408124e-06, 'epoch': 1.9433027079303675, 'step': 16075}\n",
      "{'loss': 0.7966796875, 'learning_rate': 1.3418762088974855e-06, 'epoch': 1.9463249516441006, 'step': 16100}\n",
      "{'loss': 0.4010546875, 'learning_rate': 1.2663201160541586e-06, 'epoch': 1.9493471953578336, 'step': 16125}\n",
      "{'loss': 0.661640625, 'learning_rate': 1.1907640232108317e-06, 'epoch': 1.9523694390715667, 'step': 16150}\n",
      "{'loss': 0.7969921875, 'learning_rate': 1.115207930367505e-06, 'epoch': 1.9553916827853, 'step': 16175}\n",
      "{'loss': 0.6602734375, 'learning_rate': 1.039651837524178e-06, 'epoch': 1.9584139264990328, 'step': 16200}\n",
      "{'loss': 0.5310546875, 'learning_rate': 9.64095744680851e-07, 'epoch': 1.961436170212766, 'step': 16225}\n",
      "{'loss': 0.707734375, 'learning_rate': 8.885396518375243e-07, 'epoch': 1.964458413926499, 'step': 16250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95a7b6112e042c3b7fe931a56297e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8610601885295414, 'eval_acc': 0.6837095458254011, 'eval_f1': 0.58046690231236, 'eval_acc_and_f1': 0.6320882240688805, 'eval_mcc': 0.4277400656099433, 'epoch': 1.964458413926499, 'step': 16250}\n",
      "{'loss': 0.8483984375, 'learning_rate': 8.129835589941973e-07, 'epoch': 1.9674806576402322, 'step': 16275}\n",
      "{'loss': 0.73546875, 'learning_rate': 7.374274661508705e-07, 'epoch': 1.9705029013539652, 'step': 16300}\n",
      "{'loss': 0.5472265625, 'learning_rate': 6.618713733075436e-07, 'epoch': 1.9735251450676983, 'step': 16325}\n",
      "{'loss': 0.6375390625, 'learning_rate': 5.863152804642167e-07, 'epoch': 1.9765473887814313, 'step': 16350}\n",
      "{'loss': 0.8223046875, 'learning_rate': 5.107591876208898e-07, 'epoch': 1.9795696324951644, 'step': 16375}\n",
      "{'loss': 0.6972265625, 'learning_rate': 4.352030947775629e-07, 'epoch': 1.9825918762088974, 'step': 16400}\n",
      "{'loss': 0.686484375, 'learning_rate': 3.59647001934236e-07, 'epoch': 1.9856141199226305, 'step': 16425}\n",
      "{'loss': 0.5369140625, 'learning_rate': 2.840909090909091e-07, 'epoch': 1.9886363636363638, 'step': 16450}\n",
      "{'loss': 0.631328125, 'learning_rate': 2.0853481624758223e-07, 'epoch': 1.9916586073500966, 'step': 16475}\n",
      "{'loss': 0.670390625, 'learning_rate': 1.3297872340425533e-07, 'epoch': 1.9946808510638299, 'step': 16500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20774be194b844768a7485ef08895ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=460.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.8466229469824136, 'eval_acc': 0.6847973891759587, 'eval_f1': 0.5888329394147269, 'eval_acc_and_f1': 0.6368151642953428, 'eval_mcc': 0.4312307853069023, 'epoch': 1.9946808510638299, 'step': 16500}\n",
      "{'loss': 0.696484375, 'learning_rate': 5.742263056092844e-08, 'epoch': 1.997703094777563, 'step': 16525}\n",
      "\n",
      "\n",
      "Wall time: 3h 55min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16544, training_loss=0.7405628669192759)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-daabd6490d04ffc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-daabd6490d04ffc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/runs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla BERT model (Older model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# %% create bert tokenizer + mode\n",
    "print('Loading BERT tokenizer..')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case= True)\n",
    "model  = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 3)\n",
    "desc = model.cuda()\n",
    "batch_size = 3\n",
    "learning_rate = 1e-5\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36760</th>\n",
       "      <td>For many people they don't like only asking on...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36761</th>\n",
       "      <td>also people have different views and opinions ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36762</th>\n",
       "      <td>Advice is something that can impact a persons ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36763</th>\n",
       "      <td>someone can use everything that many people sa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36764</th>\n",
       "      <td>In conclusion asking for an opinion can be ben...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36765 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          discourse_text  \\\n",
       "0      Hi, i'm Isaac, i'm going to be writing about h...   \n",
       "1      On my perspective, I think that the face is a ...   \n",
       "2      I think that the face is a natural landform be...   \n",
       "3      If life was on Mars, we would know by now. The...   \n",
       "4      People thought that the face was formed by ali...   \n",
       "...                                                  ...   \n",
       "36760  For many people they don't like only asking on...   \n",
       "36761  also people have different views and opinions ...   \n",
       "36762  Advice is something that can impact a persons ...   \n",
       "36763  someone can use everything that many people sa...   \n",
       "36764  In conclusion asking for an opinion can be ben...   \n",
       "\n",
       "             discourse_type  discourse_effectiveness  \n",
       "0                      Lead                        2  \n",
       "1                  Position                        2  \n",
       "2                     Claim                        2  \n",
       "3                  Evidence                        2  \n",
       "4              Counterclaim                        2  \n",
       "...                     ...                      ...  \n",
       "36760                 Claim                        2  \n",
       "36761                 Claim                        2  \n",
       "36762              Position                        2  \n",
       "36763              Evidence                        0  \n",
       "36764  Concluding Statement                        0  \n",
       "\n",
       "[36765 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #load the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = []\n",
    "# attention_masks = []\n",
    "# for i in range(len(df)):\n",
    "#     input_ids.append(tokenizer.encode_plus(df['discourse_text'][i], \n",
    "#                     df['discourse_type'][i],\n",
    "#                     truncation = True,\n",
    "#                     return_attention_mask = True,\n",
    "#                     return_tensors = 'pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "for i in range(len(df)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(df['discourse_text'][i],\n",
    "                        df['discourse_type'][i],# Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,    # Pad & truncate all sentences.\n",
    "                        truncation = True,\n",
    "                        padding = 'max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(df['discourse_effectiveness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = X_train.index.array\n",
    "train_idx = X_train.index.values.tolist()\n",
    "test_idx = X_test.index.values.tolist()\n",
    "train_data = TensorDataset(input_ids[train_idx],attention_masks[train_idx],labels[train_idx])\n",
    "test_data = TensorDataset(input_ids[test_idx], attention_masks[test_idx],labels[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 29409, 29410, 29411])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeces = np.arange(0, len(df))\n",
    "train_idx = indeces[0:int(0.8 * len(df))]\n",
    "# x = np.asarray(train_idx).astype('float32')\n",
    "x= np.asarray(train_idx)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35113,  8422, 31495, ...,  3297, 28658,  9680], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = X_train.index\n",
    "# x = np.asarray(idx).astype('float32')\n",
    "x= np.asarray(idx)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "                    train_data,\n",
    "                    sampler = RandomSampler(train_data),\n",
    "                    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "                    test_data,\n",
    "                    sampler = RandomSampler(test_data),\n",
    "                    batch_size = batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate, \n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples!)\n",
    "total_steps = len(train_data) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  9,804.    Elapsed: 0:00:14.\n",
      "  Batch    80  of  9,804.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  9,804.    Elapsed: 0:00:47.\n",
      "  Batch   160  of  9,804.    Elapsed: 0:01:03.\n",
      "  Batch   200  of  9,804.    Elapsed: 0:01:20.\n",
      "  Batch   240  of  9,804.    Elapsed: 0:01:37.\n",
      "  Batch   280  of  9,804.    Elapsed: 0:01:54.\n",
      "  Batch   320  of  9,804.    Elapsed: 0:02:12.\n",
      "  Batch   360  of  9,804.    Elapsed: 0:02:29.\n",
      "  Batch   400  of  9,804.    Elapsed: 0:02:46.\n",
      "  Batch   440  of  9,804.    Elapsed: 0:03:02.\n",
      "  Batch   480  of  9,804.    Elapsed: 0:03:19.\n",
      "  Batch   520  of  9,804.    Elapsed: 0:03:36.\n",
      "  Batch   560  of  9,804.    Elapsed: 0:03:52.\n",
      "  Batch   600  of  9,804.    Elapsed: 0:04:09.\n",
      "  Batch   640  of  9,804.    Elapsed: 0:04:26.\n",
      "  Batch   680  of  9,804.    Elapsed: 0:04:43.\n",
      "  Batch   720  of  9,804.    Elapsed: 0:04:59.\n",
      "  Batch   760  of  9,804.    Elapsed: 0:05:16.\n",
      "  Batch   800  of  9,804.    Elapsed: 0:05:33.\n",
      "  Batch   840  of  9,804.    Elapsed: 0:05:49.\n",
      "  Batch   880  of  9,804.    Elapsed: 0:06:06.\n",
      "  Batch   920  of  9,804.    Elapsed: 0:06:22.\n",
      "  Batch   960  of  9,804.    Elapsed: 0:06:39.\n",
      "  Batch 1,000  of  9,804.    Elapsed: 0:06:56.\n",
      "  Batch 1,040  of  9,804.    Elapsed: 0:07:12.\n",
      "  Batch 1,080  of  9,804.    Elapsed: 0:07:29.\n",
      "  Batch 1,120  of  9,804.    Elapsed: 0:07:46.\n",
      "  Batch 1,160  of  9,804.    Elapsed: 0:08:02.\n",
      "  Batch 1,200  of  9,804.    Elapsed: 0:08:19.\n",
      "  Batch 1,240  of  9,804.    Elapsed: 0:08:36.\n",
      "  Batch 1,280  of  9,804.    Elapsed: 0:08:53.\n",
      "  Batch 1,320  of  9,804.    Elapsed: 0:09:10.\n",
      "  Batch 1,360  of  9,804.    Elapsed: 0:09:26.\n",
      "  Batch 1,400  of  9,804.    Elapsed: 0:09:44.\n",
      "  Batch 1,440  of  9,804.    Elapsed: 0:10:01.\n",
      "  Batch 1,480  of  9,804.    Elapsed: 0:10:19.\n",
      "  Batch 1,520  of  9,804.    Elapsed: 0:10:37.\n",
      "  Batch 1,560  of  9,804.    Elapsed: 0:10:55.\n",
      "  Batch 1,600  of  9,804.    Elapsed: 0:11:12.\n",
      "  Batch 1,640  of  9,804.    Elapsed: 0:11:29.\n",
      "  Batch 1,680  of  9,804.    Elapsed: 0:11:46.\n",
      "  Batch 1,720  of  9,804.    Elapsed: 0:12:02.\n",
      "  Batch 1,760  of  9,804.    Elapsed: 0:12:19.\n",
      "  Batch 1,800  of  9,804.    Elapsed: 0:12:36.\n",
      "  Batch 1,840  of  9,804.    Elapsed: 0:12:52.\n",
      "  Batch 1,880  of  9,804.    Elapsed: 0:13:09.\n",
      "  Batch 1,920  of  9,804.    Elapsed: 0:13:26.\n",
      "  Batch 1,960  of  9,804.    Elapsed: 0:13:43.\n",
      "  Batch 2,000  of  9,804.    Elapsed: 0:13:59.\n",
      "  Batch 2,040  of  9,804.    Elapsed: 0:14:16.\n",
      "  Batch 2,080  of  9,804.    Elapsed: 0:14:33.\n",
      "  Batch 2,120  of  9,804.    Elapsed: 0:14:50.\n",
      "  Batch 2,160  of  9,804.    Elapsed: 0:15:07.\n",
      "  Batch 2,200  of  9,804.    Elapsed: 0:15:24.\n",
      "  Batch 2,240  of  9,804.    Elapsed: 0:15:41.\n",
      "  Batch 2,280  of  9,804.    Elapsed: 0:15:58.\n",
      "  Batch 2,320  of  9,804.    Elapsed: 0:16:16.\n",
      "  Batch 2,360  of  9,804.    Elapsed: 0:16:34.\n",
      "  Batch 2,400  of  9,804.    Elapsed: 0:16:51.\n",
      "  Batch 2,440  of  9,804.    Elapsed: 0:17:09.\n",
      "  Batch 2,480  of  9,804.    Elapsed: 0:17:26.\n",
      "  Batch 2,520  of  9,804.    Elapsed: 0:17:43.\n",
      "  Batch 2,560  of  9,804.    Elapsed: 0:17:59.\n",
      "  Batch 2,600  of  9,804.    Elapsed: 0:18:16.\n",
      "  Batch 2,640  of  9,804.    Elapsed: 0:18:33.\n",
      "  Batch 2,680  of  9,804.    Elapsed: 0:18:50.\n",
      "  Batch 2,720  of  9,804.    Elapsed: 0:19:06.\n",
      "  Batch 2,760  of  9,804.    Elapsed: 0:19:23.\n",
      "  Batch 2,800  of  9,804.    Elapsed: 0:19:39.\n",
      "  Batch 2,840  of  9,804.    Elapsed: 0:19:56.\n",
      "  Batch 2,880  of  9,804.    Elapsed: 0:20:13.\n",
      "  Batch 2,920  of  9,804.    Elapsed: 0:20:30.\n",
      "  Batch 2,960  of  9,804.    Elapsed: 0:20:46.\n",
      "  Batch 3,000  of  9,804.    Elapsed: 0:21:03.\n",
      "  Batch 3,040  of  9,804.    Elapsed: 0:21:19.\n",
      "  Batch 3,080  of  9,804.    Elapsed: 0:21:36.\n",
      "  Batch 3,120  of  9,804.    Elapsed: 0:21:53.\n",
      "  Batch 3,160  of  9,804.    Elapsed: 0:22:09.\n",
      "  Batch 3,200  of  9,804.    Elapsed: 0:22:26.\n",
      "  Batch 3,240  of  9,804.    Elapsed: 0:22:43.\n",
      "  Batch 3,280  of  9,804.    Elapsed: 0:22:59.\n",
      "  Batch 3,320  of  9,804.    Elapsed: 0:23:16.\n",
      "  Batch 3,360  of  9,804.    Elapsed: 0:23:33.\n",
      "  Batch 3,400  of  9,804.    Elapsed: 0:23:49.\n",
      "  Batch 3,440  of  9,804.    Elapsed: 0:24:06.\n",
      "  Batch 3,480  of  9,804.    Elapsed: 0:24:23.\n",
      "  Batch 3,520  of  9,804.    Elapsed: 0:24:39.\n",
      "  Batch 3,560  of  9,804.    Elapsed: 0:24:56.\n",
      "  Batch 3,600  of  9,804.    Elapsed: 0:25:13.\n",
      "  Batch 3,640  of  9,804.    Elapsed: 0:25:29.\n",
      "  Batch 3,680  of  9,804.    Elapsed: 0:25:46.\n",
      "  Batch 3,720  of  9,804.    Elapsed: 0:26:03.\n",
      "  Batch 3,760  of  9,804.    Elapsed: 0:26:19.\n",
      "  Batch 3,800  of  9,804.    Elapsed: 0:26:36.\n",
      "  Batch 3,840  of  9,804.    Elapsed: 0:26:53.\n",
      "  Batch 3,880  of  9,804.    Elapsed: 0:27:09.\n",
      "  Batch 3,920  of  9,804.    Elapsed: 0:27:26.\n",
      "  Batch 3,960  of  9,804.    Elapsed: 0:27:43.\n",
      "  Batch 4,000  of  9,804.    Elapsed: 0:27:59.\n",
      "  Batch 4,040  of  9,804.    Elapsed: 0:28:16.\n",
      "  Batch 4,080  of  9,804.    Elapsed: 0:28:33.\n",
      "  Batch 4,120  of  9,804.    Elapsed: 0:28:49.\n",
      "  Batch 4,160  of  9,804.    Elapsed: 0:29:06.\n",
      "  Batch 4,200  of  9,804.    Elapsed: 0:29:23.\n",
      "  Batch 4,240  of  9,804.    Elapsed: 0:29:39.\n",
      "  Batch 4,280  of  9,804.    Elapsed: 0:29:56.\n",
      "  Batch 4,320  of  9,804.    Elapsed: 0:30:13.\n",
      "  Batch 4,360  of  9,804.    Elapsed: 0:30:29.\n",
      "  Batch 4,400  of  9,804.    Elapsed: 0:30:46.\n",
      "  Batch 4,440  of  9,804.    Elapsed: 0:31:03.\n",
      "  Batch 4,480  of  9,804.    Elapsed: 0:31:19.\n",
      "  Batch 4,520  of  9,804.    Elapsed: 0:31:36.\n",
      "  Batch 4,560  of  9,804.    Elapsed: 0:31:53.\n",
      "  Batch 4,600  of  9,804.    Elapsed: 0:32:09.\n",
      "  Batch 4,640  of  9,804.    Elapsed: 0:32:26.\n",
      "  Batch 4,680  of  9,804.    Elapsed: 0:32:43.\n",
      "  Batch 4,720  of  9,804.    Elapsed: 0:32:59.\n",
      "  Batch 4,760  of  9,804.    Elapsed: 0:33:16.\n",
      "  Batch 4,800  of  9,804.    Elapsed: 0:33:33.\n",
      "  Batch 4,840  of  9,804.    Elapsed: 0:33:49.\n",
      "  Batch 4,880  of  9,804.    Elapsed: 0:34:06.\n",
      "  Batch 4,920  of  9,804.    Elapsed: 0:34:23.\n",
      "  Batch 4,960  of  9,804.    Elapsed: 0:34:39.\n",
      "  Batch 5,000  of  9,804.    Elapsed: 0:34:56.\n",
      "  Batch 5,040  of  9,804.    Elapsed: 0:35:13.\n",
      "  Batch 5,080  of  9,804.    Elapsed: 0:35:29.\n",
      "  Batch 5,120  of  9,804.    Elapsed: 0:35:46.\n",
      "  Batch 5,160  of  9,804.    Elapsed: 0:36:03.\n",
      "  Batch 5,200  of  9,804.    Elapsed: 0:36:19.\n",
      "  Batch 5,240  of  9,804.    Elapsed: 0:36:36.\n",
      "  Batch 5,280  of  9,804.    Elapsed: 0:36:53.\n",
      "  Batch 5,320  of  9,804.    Elapsed: 0:37:09.\n",
      "  Batch 5,360  of  9,804.    Elapsed: 0:37:26.\n",
      "  Batch 5,400  of  9,804.    Elapsed: 0:37:42.\n",
      "  Batch 5,440  of  9,804.    Elapsed: 0:37:59.\n",
      "  Batch 5,480  of  9,804.    Elapsed: 0:38:16.\n",
      "  Batch 5,520  of  9,804.    Elapsed: 0:38:33.\n",
      "  Batch 5,560  of  9,804.    Elapsed: 0:38:49.\n",
      "  Batch 5,600  of  9,804.    Elapsed: 0:39:06.\n",
      "  Batch 5,640  of  9,804.    Elapsed: 0:39:23.\n",
      "  Batch 5,680  of  9,804.    Elapsed: 0:39:40.\n",
      "  Batch 5,720  of  9,804.    Elapsed: 0:39:57.\n",
      "  Batch 5,760  of  9,804.    Elapsed: 0:40:13.\n",
      "  Batch 5,800  of  9,804.    Elapsed: 0:40:30.\n",
      "  Batch 5,840  of  9,804.    Elapsed: 0:40:47.\n",
      "  Batch 5,880  of  9,804.    Elapsed: 0:41:03.\n",
      "  Batch 5,920  of  9,804.    Elapsed: 0:41:20.\n",
      "  Batch 5,960  of  9,804.    Elapsed: 0:41:37.\n",
      "  Batch 6,000  of  9,804.    Elapsed: 0:41:53.\n",
      "  Batch 6,040  of  9,804.    Elapsed: 0:42:10.\n",
      "  Batch 6,080  of  9,804.    Elapsed: 0:42:27.\n",
      "  Batch 6,120  of  9,804.    Elapsed: 0:42:44.\n",
      "  Batch 6,160  of  9,804.    Elapsed: 0:43:00.\n",
      "  Batch 6,200  of  9,804.    Elapsed: 0:43:17.\n",
      "  Batch 6,240  of  9,804.    Elapsed: 0:43:34.\n",
      "  Batch 6,280  of  9,804.    Elapsed: 0:43:50.\n",
      "  Batch 6,320  of  9,804.    Elapsed: 0:44:07.\n",
      "  Batch 6,360  of  9,804.    Elapsed: 0:44:24.\n",
      "  Batch 6,400  of  9,804.    Elapsed: 0:44:41.\n",
      "  Batch 6,440  of  9,804.    Elapsed: 0:44:57.\n",
      "  Batch 6,480  of  9,804.    Elapsed: 0:45:14.\n",
      "  Batch 6,520  of  9,804.    Elapsed: 0:45:31.\n",
      "  Batch 6,560  of  9,804.    Elapsed: 0:45:48.\n",
      "  Batch 6,600  of  9,804.    Elapsed: 0:46:04.\n",
      "  Batch 6,640  of  9,804.    Elapsed: 0:46:21.\n",
      "  Batch 6,680  of  9,804.    Elapsed: 0:46:38.\n",
      "  Batch 6,720  of  9,804.    Elapsed: 0:46:54.\n",
      "  Batch 6,760  of  9,804.    Elapsed: 0:47:11.\n",
      "  Batch 6,800  of  9,804.    Elapsed: 0:47:28.\n",
      "  Batch 6,840  of  9,804.    Elapsed: 0:47:44.\n",
      "  Batch 6,880  of  9,804.    Elapsed: 0:48:01.\n",
      "  Batch 6,920  of  9,804.    Elapsed: 0:48:18.\n",
      "  Batch 6,960  of  9,804.    Elapsed: 0:48:35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 7,000  of  9,804.    Elapsed: 0:48:51.\n",
      "  Batch 7,040  of  9,804.    Elapsed: 0:49:08.\n",
      "  Batch 7,080  of  9,804.    Elapsed: 0:49:25.\n",
      "  Batch 7,120  of  9,804.    Elapsed: 0:49:42.\n",
      "  Batch 7,160  of  9,804.    Elapsed: 0:49:58.\n",
      "  Batch 7,200  of  9,804.    Elapsed: 0:50:15.\n",
      "  Batch 7,240  of  9,804.    Elapsed: 0:50:32.\n",
      "  Batch 7,280  of  9,804.    Elapsed: 0:50:48.\n",
      "  Batch 7,320  of  9,804.    Elapsed: 0:51:05.\n",
      "  Batch 7,360  of  9,804.    Elapsed: 0:51:22.\n",
      "  Batch 7,400  of  9,804.    Elapsed: 0:51:39.\n",
      "  Batch 7,440  of  9,804.    Elapsed: 0:51:55.\n",
      "  Batch 7,480  of  9,804.    Elapsed: 0:52:12.\n",
      "  Batch 7,520  of  9,804.    Elapsed: 0:52:29.\n",
      "  Batch 7,560  of  9,804.    Elapsed: 0:52:45.\n",
      "  Batch 7,600  of  9,804.    Elapsed: 0:53:02.\n",
      "  Batch 7,640  of  9,804.    Elapsed: 0:53:19.\n",
      "  Batch 7,680  of  9,804.    Elapsed: 0:53:35.\n",
      "  Batch 7,720  of  9,804.    Elapsed: 0:53:52.\n",
      "  Batch 7,760  of  9,804.    Elapsed: 0:54:09.\n",
      "  Batch 7,800  of  9,804.    Elapsed: 0:54:25.\n",
      "  Batch 7,840  of  9,804.    Elapsed: 0:54:42.\n",
      "  Batch 7,880  of  9,804.    Elapsed: 0:54:59.\n",
      "  Batch 7,920  of  9,804.    Elapsed: 0:55:16.\n",
      "  Batch 7,960  of  9,804.    Elapsed: 0:55:32.\n",
      "  Batch 8,000  of  9,804.    Elapsed: 0:55:49.\n",
      "  Batch 8,040  of  9,804.    Elapsed: 0:56:06.\n",
      "  Batch 8,080  of  9,804.    Elapsed: 0:56:22.\n",
      "  Batch 8,120  of  9,804.    Elapsed: 0:56:39.\n",
      "  Batch 8,160  of  9,804.    Elapsed: 0:56:56.\n",
      "  Batch 8,200  of  9,804.    Elapsed: 0:57:12.\n",
      "  Batch 8,240  of  9,804.    Elapsed: 0:57:29.\n",
      "  Batch 8,280  of  9,804.    Elapsed: 0:57:46.\n",
      "  Batch 8,320  of  9,804.    Elapsed: 0:58:03.\n",
      "  Batch 8,360  of  9,804.    Elapsed: 0:58:19.\n",
      "  Batch 8,400  of  9,804.    Elapsed: 0:58:36.\n",
      "  Batch 8,440  of  9,804.    Elapsed: 0:58:53.\n",
      "  Batch 8,480  of  9,804.    Elapsed: 0:59:09.\n",
      "  Batch 8,520  of  9,804.    Elapsed: 0:59:26.\n",
      "  Batch 8,560  of  9,804.    Elapsed: 0:59:43.\n",
      "  Batch 8,600  of  9,804.    Elapsed: 1:00:00.\n",
      "  Batch 8,640  of  9,804.    Elapsed: 1:00:16.\n",
      "  Batch 8,680  of  9,804.    Elapsed: 1:00:33.\n",
      "  Batch 8,720  of  9,804.    Elapsed: 1:00:50.\n",
      "  Batch 8,760  of  9,804.    Elapsed: 1:01:07.\n",
      "  Batch 8,800  of  9,804.    Elapsed: 1:01:23.\n",
      "  Batch 8,840  of  9,804.    Elapsed: 1:01:40.\n",
      "  Batch 8,880  of  9,804.    Elapsed: 1:01:57.\n",
      "  Batch 8,920  of  9,804.    Elapsed: 1:02:14.\n",
      "  Batch 8,960  of  9,804.    Elapsed: 1:02:30.\n",
      "  Batch 9,000  of  9,804.    Elapsed: 1:02:47.\n",
      "  Batch 9,040  of  9,804.    Elapsed: 1:03:04.\n",
      "  Batch 9,080  of  9,804.    Elapsed: 1:03:20.\n",
      "  Batch 9,120  of  9,804.    Elapsed: 1:03:37.\n",
      "  Batch 9,160  of  9,804.    Elapsed: 1:03:54.\n",
      "  Batch 9,200  of  9,804.    Elapsed: 1:04:10.\n",
      "  Batch 9,240  of  9,804.    Elapsed: 1:04:27.\n",
      "  Batch 9,280  of  9,804.    Elapsed: 1:04:44.\n",
      "  Batch 9,320  of  9,804.    Elapsed: 1:05:00.\n",
      "  Batch 9,360  of  9,804.    Elapsed: 1:05:17.\n",
      "  Batch 9,400  of  9,804.    Elapsed: 1:05:34.\n",
      "  Batch 9,440  of  9,804.    Elapsed: 1:05:51.\n",
      "  Batch 9,480  of  9,804.    Elapsed: 1:06:08.\n",
      "  Batch 9,520  of  9,804.    Elapsed: 1:06:24.\n",
      "  Batch 9,560  of  9,804.    Elapsed: 1:06:41.\n",
      "  Batch 9,600  of  9,804.    Elapsed: 1:06:58.\n",
      "  Batch 9,640  of  9,804.    Elapsed: 1:07:14.\n",
      "  Batch 9,680  of  9,804.    Elapsed: 1:07:31.\n",
      "  Batch 9,720  of  9,804.    Elapsed: 1:07:48.\n",
      "  Batch 9,760  of  9,804.    Elapsed: 1:08:05.\n",
      "  Batch 9,800  of  9,804.    Elapsed: 1:08:21.\n",
      "\n",
      "  Average training loss: 0.80\n",
      "  Training epcoh took: 1:08:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Validation Loss: 0.73\n",
      "  Validation took: 0:05:24\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  9,804.    Elapsed: 0:00:17.\n",
      "  Batch    80  of  9,804.    Elapsed: 0:00:33.\n",
      "  Batch   120  of  9,804.    Elapsed: 0:00:50.\n",
      "  Batch   160  of  9,804.    Elapsed: 0:01:07.\n",
      "  Batch   200  of  9,804.    Elapsed: 0:01:25.\n",
      "  Batch   240  of  9,804.    Elapsed: 0:01:42.\n",
      "  Batch   280  of  9,804.    Elapsed: 0:02:00.\n",
      "  Batch   320  of  9,804.    Elapsed: 0:02:17.\n",
      "  Batch   360  of  9,804.    Elapsed: 0:02:35.\n",
      "  Batch   400  of  9,804.    Elapsed: 0:02:52.\n",
      "  Batch   440  of  9,804.    Elapsed: 0:03:10.\n",
      "  Batch   480  of  9,804.    Elapsed: 0:03:28.\n",
      "  Batch   520  of  9,804.    Elapsed: 0:03:45.\n",
      "  Batch   560  of  9,804.    Elapsed: 0:04:03.\n",
      "  Batch   600  of  9,804.    Elapsed: 0:04:20.\n",
      "  Batch   640  of  9,804.    Elapsed: 0:04:38.\n",
      "  Batch   680  of  9,804.    Elapsed: 0:04:56.\n",
      "  Batch   720  of  9,804.    Elapsed: 0:05:13.\n",
      "  Batch   760  of  9,804.    Elapsed: 0:05:31.\n",
      "  Batch   800  of  9,804.    Elapsed: 0:05:48.\n",
      "  Batch   840  of  9,804.    Elapsed: 0:06:06.\n",
      "  Batch   880  of  9,804.    Elapsed: 0:06:23.\n",
      "  Batch   920  of  9,804.    Elapsed: 0:06:41.\n",
      "  Batch   960  of  9,804.    Elapsed: 0:06:58.\n",
      "  Batch 1,000  of  9,804.    Elapsed: 0:07:16.\n",
      "  Batch 1,040  of  9,804.    Elapsed: 0:07:30.\n",
      "  Batch 1,080  of  9,804.    Elapsed: 0:07:44.\n",
      "  Batch 1,120  of  9,804.    Elapsed: 0:07:58.\n",
      "  Batch 1,160  of  9,804.    Elapsed: 0:08:14.\n",
      "  Batch 1,200  of  9,804.    Elapsed: 0:08:27.\n",
      "  Batch 1,240  of  9,804.    Elapsed: 0:08:39.\n",
      "  Batch 1,280  of  9,804.    Elapsed: 0:08:56.\n",
      "  Batch 1,320  of  9,804.    Elapsed: 0:09:13.\n",
      "  Batch 1,360  of  9,804.    Elapsed: 0:09:30.\n",
      "  Batch 1,400  of  9,804.    Elapsed: 0:09:47.\n",
      "  Batch 1,440  of  9,804.    Elapsed: 0:10:04.\n",
      "  Batch 1,480  of  9,804.    Elapsed: 0:10:21.\n",
      "  Batch 1,520  of  9,804.    Elapsed: 0:10:37.\n",
      "  Batch 1,560  of  9,804.    Elapsed: 0:10:54.\n",
      "  Batch 1,600  of  9,804.    Elapsed: 0:11:11.\n",
      "  Batch 1,640  of  9,804.    Elapsed: 0:11:28.\n",
      "  Batch 1,680  of  9,804.    Elapsed: 0:11:44.\n",
      "  Batch 1,720  of  9,804.    Elapsed: 0:12:01.\n",
      "  Batch 1,760  of  9,804.    Elapsed: 0:12:18.\n",
      "  Batch 1,800  of  9,804.    Elapsed: 0:12:34.\n",
      "  Batch 1,840  of  9,804.    Elapsed: 0:12:51.\n",
      "  Batch 1,880  of  9,804.    Elapsed: 0:13:08.\n",
      "  Batch 1,920  of  9,804.    Elapsed: 0:13:25.\n",
      "  Batch 1,960  of  9,804.    Elapsed: 0:13:41.\n",
      "  Batch 2,000  of  9,804.    Elapsed: 0:13:58.\n",
      "  Batch 2,040  of  9,804.    Elapsed: 0:14:15.\n",
      "  Batch 2,080  of  9,804.    Elapsed: 0:14:32.\n",
      "  Batch 2,120  of  9,804.    Elapsed: 0:14:48.\n",
      "  Batch 2,160  of  9,804.    Elapsed: 0:15:05.\n",
      "  Batch 2,200  of  9,804.    Elapsed: 0:15:22.\n",
      "  Batch 2,240  of  9,804.    Elapsed: 0:15:39.\n",
      "  Batch 2,280  of  9,804.    Elapsed: 0:15:55.\n",
      "  Batch 2,320  of  9,804.    Elapsed: 0:16:12.\n",
      "  Batch 2,360  of  9,804.    Elapsed: 0:16:29.\n",
      "  Batch 2,400  of  9,804.    Elapsed: 0:16:45.\n",
      "  Batch 2,440  of  9,804.    Elapsed: 0:17:02.\n",
      "  Batch 2,480  of  9,804.    Elapsed: 0:17:19.\n",
      "  Batch 2,520  of  9,804.    Elapsed: 0:17:35.\n",
      "  Batch 2,560  of  9,804.    Elapsed: 0:17:52.\n",
      "  Batch 2,600  of  9,804.    Elapsed: 0:18:09.\n",
      "  Batch 2,640  of  9,804.    Elapsed: 0:18:26.\n",
      "  Batch 2,680  of  9,804.    Elapsed: 0:18:42.\n",
      "  Batch 2,720  of  9,804.    Elapsed: 0:18:59.\n",
      "  Batch 2,760  of  9,804.    Elapsed: 0:19:16.\n",
      "  Batch 2,800  of  9,804.    Elapsed: 0:19:33.\n",
      "  Batch 2,840  of  9,804.    Elapsed: 0:19:51.\n",
      "  Batch 2,880  of  9,804.    Elapsed: 0:20:07.\n",
      "  Batch 2,920  of  9,804.    Elapsed: 0:20:24.\n",
      "  Batch 2,960  of  9,804.    Elapsed: 0:20:41.\n",
      "  Batch 3,000  of  9,804.    Elapsed: 0:20:57.\n",
      "  Batch 3,040  of  9,804.    Elapsed: 0:21:14.\n",
      "  Batch 3,080  of  9,804.    Elapsed: 0:21:31.\n",
      "  Batch 3,120  of  9,804.    Elapsed: 0:21:47.\n",
      "  Batch 3,160  of  9,804.    Elapsed: 0:22:04.\n",
      "  Batch 3,200  of  9,804.    Elapsed: 0:22:21.\n",
      "  Batch 3,240  of  9,804.    Elapsed: 0:22:37.\n",
      "  Batch 3,280  of  9,804.    Elapsed: 0:22:54.\n",
      "  Batch 3,320  of  9,804.    Elapsed: 0:23:11.\n",
      "  Batch 3,360  of  9,804.    Elapsed: 0:23:27.\n",
      "  Batch 3,400  of  9,804.    Elapsed: 0:23:44.\n",
      "  Batch 3,440  of  9,804.    Elapsed: 0:24:01.\n",
      "  Batch 3,480  of  9,804.    Elapsed: 0:24:17.\n",
      "  Batch 3,520  of  9,804.    Elapsed: 0:24:34.\n",
      "  Batch 3,560  of  9,804.    Elapsed: 0:24:51.\n",
      "  Batch 3,600  of  9,804.    Elapsed: 0:25:07.\n",
      "  Batch 3,640  of  9,804.    Elapsed: 0:25:24.\n",
      "  Batch 3,680  of  9,804.    Elapsed: 0:25:41.\n",
      "  Batch 3,720  of  9,804.    Elapsed: 0:25:57.\n",
      "  Batch 3,760  of  9,804.    Elapsed: 0:26:14.\n",
      "  Batch 3,800  of  9,804.    Elapsed: 0:26:31.\n",
      "  Batch 3,840  of  9,804.    Elapsed: 0:26:47.\n",
      "  Batch 3,880  of  9,804.    Elapsed: 0:27:04.\n",
      "  Batch 3,920  of  9,804.    Elapsed: 0:27:21.\n",
      "  Batch 3,960  of  9,804.    Elapsed: 0:27:37.\n",
      "  Batch 4,000  of  9,804.    Elapsed: 0:27:54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 4,040  of  9,804.    Elapsed: 0:28:11.\n",
      "  Batch 4,080  of  9,804.    Elapsed: 0:28:27.\n",
      "  Batch 4,120  of  9,804.    Elapsed: 0:28:44.\n",
      "  Batch 4,160  of  9,804.    Elapsed: 0:29:01.\n",
      "  Batch 4,200  of  9,804.    Elapsed: 0:29:17.\n",
      "  Batch 4,240  of  9,804.    Elapsed: 0:29:34.\n",
      "  Batch 4,280  of  9,804.    Elapsed: 0:29:51.\n",
      "  Batch 4,320  of  9,804.    Elapsed: 0:30:07.\n",
      "  Batch 4,360  of  9,804.    Elapsed: 0:30:24.\n",
      "  Batch 4,400  of  9,804.    Elapsed: 0:30:41.\n",
      "  Batch 4,440  of  9,804.    Elapsed: 0:30:57.\n",
      "  Batch 4,480  of  9,804.    Elapsed: 0:31:14.\n",
      "  Batch 4,520  of  9,804.    Elapsed: 0:31:31.\n",
      "  Batch 4,560  of  9,804.    Elapsed: 0:31:47.\n",
      "  Batch 4,600  of  9,804.    Elapsed: 0:32:04.\n",
      "  Batch 4,640  of  9,804.    Elapsed: 0:32:21.\n",
      "  Batch 4,680  of  9,804.    Elapsed: 0:32:37.\n",
      "  Batch 4,720  of  9,804.    Elapsed: 0:32:54.\n",
      "  Batch 4,760  of  9,804.    Elapsed: 0:33:10.\n",
      "  Batch 4,800  of  9,804.    Elapsed: 0:33:27.\n",
      "  Batch 4,840  of  9,804.    Elapsed: 0:33:44.\n",
      "  Batch 4,880  of  9,804.    Elapsed: 0:34:00.\n",
      "  Batch 4,920  of  9,804.    Elapsed: 0:34:17.\n",
      "  Batch 4,960  of  9,804.    Elapsed: 0:34:34.\n",
      "  Batch 5,000  of  9,804.    Elapsed: 0:34:50.\n",
      "  Batch 5,040  of  9,804.    Elapsed: 0:35:07.\n",
      "  Batch 5,080  of  9,804.    Elapsed: 0:35:24.\n",
      "  Batch 5,120  of  9,804.    Elapsed: 0:35:40.\n",
      "  Batch 5,160  of  9,804.    Elapsed: 0:35:57.\n",
      "  Batch 5,200  of  9,804.    Elapsed: 0:36:14.\n",
      "  Batch 5,240  of  9,804.    Elapsed: 0:36:31.\n",
      "  Batch 5,280  of  9,804.    Elapsed: 0:36:47.\n",
      "  Batch 5,320  of  9,804.    Elapsed: 0:37:04.\n",
      "  Batch 5,360  of  9,804.    Elapsed: 0:37:20.\n",
      "  Batch 5,400  of  9,804.    Elapsed: 0:37:37.\n",
      "  Batch 5,440  of  9,804.    Elapsed: 0:37:54.\n",
      "  Batch 5,480  of  9,804.    Elapsed: 0:38:10.\n",
      "  Batch 5,520  of  9,804.    Elapsed: 0:38:27.\n",
      "  Batch 5,560  of  9,804.    Elapsed: 0:38:44.\n",
      "  Batch 5,600  of  9,804.    Elapsed: 0:39:00.\n",
      "  Batch 5,640  of  9,804.    Elapsed: 0:39:17.\n",
      "  Batch 5,680  of  9,804.    Elapsed: 0:39:34.\n",
      "  Batch 5,720  of  9,804.    Elapsed: 0:39:51.\n",
      "  Batch 5,760  of  9,804.    Elapsed: 0:40:07.\n",
      "  Batch 5,800  of  9,804.    Elapsed: 0:40:24.\n",
      "  Batch 5,840  of  9,804.    Elapsed: 0:40:41.\n",
      "  Batch 5,880  of  9,804.    Elapsed: 0:40:57.\n",
      "  Batch 5,920  of  9,804.    Elapsed: 0:41:14.\n",
      "  Batch 5,960  of  9,804.    Elapsed: 0:41:31.\n",
      "  Batch 6,000  of  9,804.    Elapsed: 0:41:47.\n",
      "  Batch 6,040  of  9,804.    Elapsed: 0:42:04.\n",
      "  Batch 6,080  of  9,804.    Elapsed: 0:42:21.\n",
      "  Batch 6,120  of  9,804.    Elapsed: 0:42:38.\n",
      "  Batch 6,160  of  9,804.    Elapsed: 0:42:54.\n",
      "  Batch 6,200  of  9,804.    Elapsed: 0:43:11.\n",
      "  Batch 6,240  of  9,804.    Elapsed: 0:43:28.\n",
      "  Batch 6,280  of  9,804.    Elapsed: 0:43:44.\n",
      "  Batch 6,320  of  9,804.    Elapsed: 0:44:01.\n",
      "  Batch 6,360  of  9,804.    Elapsed: 0:44:18.\n",
      "  Batch 6,400  of  9,804.    Elapsed: 0:44:35.\n",
      "  Batch 6,440  of  9,804.    Elapsed: 0:44:51.\n",
      "  Batch 6,480  of  9,804.    Elapsed: 0:45:08.\n",
      "  Batch 6,520  of  9,804.    Elapsed: 0:45:25.\n",
      "  Batch 6,560  of  9,804.    Elapsed: 0:45:42.\n",
      "  Batch 6,600  of  9,804.    Elapsed: 0:45:58.\n",
      "  Batch 6,640  of  9,804.    Elapsed: 0:46:15.\n",
      "  Batch 6,680  of  9,804.    Elapsed: 0:46:32.\n",
      "  Batch 6,720  of  9,804.    Elapsed: 0:46:49.\n",
      "  Batch 6,760  of  9,804.    Elapsed: 0:47:06.\n",
      "  Batch 6,800  of  9,804.    Elapsed: 0:47:23.\n",
      "  Batch 6,840  of  9,804.    Elapsed: 0:47:39.\n",
      "  Batch 6,880  of  9,804.    Elapsed: 0:47:56.\n",
      "  Batch 6,920  of  9,804.    Elapsed: 0:48:13.\n",
      "  Batch 6,960  of  9,804.    Elapsed: 0:48:29.\n",
      "  Batch 7,000  of  9,804.    Elapsed: 0:48:46.\n",
      "  Batch 7,040  of  9,804.    Elapsed: 0:49:03.\n",
      "  Batch 7,080  of  9,804.    Elapsed: 0:49:19.\n",
      "  Batch 7,120  of  9,804.    Elapsed: 0:49:36.\n",
      "  Batch 7,160  of  9,804.    Elapsed: 0:49:53.\n",
      "  Batch 7,200  of  9,804.    Elapsed: 0:50:09.\n",
      "  Batch 7,240  of  9,804.    Elapsed: 0:50:26.\n",
      "  Batch 7,280  of  9,804.    Elapsed: 0:50:43.\n",
      "  Batch 7,320  of  9,804.    Elapsed: 0:50:59.\n",
      "  Batch 7,360  of  9,804.    Elapsed: 0:51:16.\n",
      "  Batch 7,400  of  9,804.    Elapsed: 0:51:33.\n",
      "  Batch 7,440  of  9,804.    Elapsed: 0:51:50.\n",
      "  Batch 7,480  of  9,804.    Elapsed: 0:52:06.\n",
      "  Batch 7,520  of  9,804.    Elapsed: 0:52:23.\n",
      "  Batch 7,560  of  9,804.    Elapsed: 0:52:40.\n",
      "  Batch 7,600  of  9,804.    Elapsed: 0:52:56.\n",
      "  Batch 7,640  of  9,804.    Elapsed: 0:53:13.\n",
      "  Batch 7,680  of  9,804.    Elapsed: 0:53:30.\n",
      "  Batch 7,720  of  9,804.    Elapsed: 0:53:46.\n",
      "  Batch 7,760  of  9,804.    Elapsed: 0:54:03.\n",
      "  Batch 7,800  of  9,804.    Elapsed: 0:54:20.\n",
      "  Batch 7,840  of  9,804.    Elapsed: 0:54:37.\n",
      "  Batch 7,880  of  9,804.    Elapsed: 0:54:53.\n",
      "  Batch 7,920  of  9,804.    Elapsed: 0:55:10.\n",
      "  Batch 7,960  of  9,804.    Elapsed: 0:55:27.\n",
      "  Batch 8,000  of  9,804.    Elapsed: 0:55:44.\n",
      "  Batch 8,040  of  9,804.    Elapsed: 0:56:01.\n",
      "  Batch 8,080  of  9,804.    Elapsed: 0:56:18.\n",
      "  Batch 8,120  of  9,804.    Elapsed: 0:56:34.\n",
      "  Batch 8,160  of  9,804.    Elapsed: 0:56:51.\n",
      "  Batch 8,200  of  9,804.    Elapsed: 0:57:08.\n",
      "  Batch 8,240  of  9,804.    Elapsed: 0:57:25.\n",
      "  Batch 8,280  of  9,804.    Elapsed: 0:57:42.\n",
      "  Batch 8,320  of  9,804.    Elapsed: 0:57:59.\n",
      "  Batch 8,360  of  9,804.    Elapsed: 0:58:15.\n",
      "  Batch 8,400  of  9,804.    Elapsed: 0:58:32.\n",
      "  Batch 8,440  of  9,804.    Elapsed: 0:58:49.\n",
      "  Batch 8,480  of  9,804.    Elapsed: 0:59:06.\n",
      "  Batch 8,520  of  9,804.    Elapsed: 0:59:22.\n",
      "  Batch 8,560  of  9,804.    Elapsed: 0:59:39.\n",
      "  Batch 8,600  of  9,804.    Elapsed: 0:59:56.\n",
      "  Batch 8,640  of  9,804.    Elapsed: 1:00:13.\n",
      "  Batch 8,680  of  9,804.    Elapsed: 1:00:29.\n",
      "  Batch 8,720  of  9,804.    Elapsed: 1:00:46.\n",
      "  Batch 8,760  of  9,804.    Elapsed: 1:01:03.\n",
      "  Batch 8,800  of  9,804.    Elapsed: 1:01:20.\n",
      "  Batch 8,840  of  9,804.    Elapsed: 1:01:36.\n",
      "  Batch 8,880  of  9,804.    Elapsed: 1:01:53.\n",
      "  Batch 8,920  of  9,804.    Elapsed: 1:02:10.\n",
      "  Batch 8,960  of  9,804.    Elapsed: 1:02:26.\n",
      "  Batch 9,000  of  9,804.    Elapsed: 1:02:43.\n",
      "  Batch 9,040  of  9,804.    Elapsed: 1:03:00.\n",
      "  Batch 9,080  of  9,804.    Elapsed: 1:03:17.\n",
      "  Batch 9,120  of  9,804.    Elapsed: 1:03:34.\n",
      "  Batch 9,160  of  9,804.    Elapsed: 1:03:51.\n",
      "  Batch 9,200  of  9,804.    Elapsed: 1:04:08.\n",
      "  Batch 9,240  of  9,804.    Elapsed: 1:04:24.\n",
      "  Batch 9,280  of  9,804.    Elapsed: 1:04:41.\n",
      "  Batch 9,320  of  9,804.    Elapsed: 1:04:58.\n",
      "  Batch 9,360  of  9,804.    Elapsed: 1:05:15.\n",
      "  Batch 9,400  of  9,804.    Elapsed: 1:05:32.\n",
      "  Batch 9,440  of  9,804.    Elapsed: 1:05:48.\n",
      "  Batch 9,480  of  9,804.    Elapsed: 1:06:05.\n",
      "  Batch 9,520  of  9,804.    Elapsed: 1:06:22.\n",
      "  Batch 9,560  of  9,804.    Elapsed: 1:06:39.\n",
      "  Batch 9,600  of  9,804.    Elapsed: 1:06:55.\n",
      "  Batch 9,640  of  9,804.    Elapsed: 1:07:12.\n",
      "  Batch 9,680  of  9,804.    Elapsed: 1:07:29.\n",
      "  Batch 9,720  of  9,804.    Elapsed: 1:07:45.\n",
      "  Batch 9,760  of  9,804.    Elapsed: 1:08:02.\n",
      "  Batch 9,800  of  9,804.    Elapsed: 1:08:19.\n",
      "\n",
      "  Average training loss: 0.76\n",
      "  Training epcoh took: 1:08:21\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Validation Loss: 0.98\n",
      "  Validation took: 0:05:25\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  9,804.    Elapsed: 0:00:17.\n",
      "  Batch    80  of  9,804.    Elapsed: 0:00:33.\n",
      "  Batch   120  of  9,804.    Elapsed: 0:00:50.\n",
      "  Batch   160  of  9,804.    Elapsed: 0:01:07.\n",
      "  Batch   200  of  9,804.    Elapsed: 0:01:24.\n",
      "  Batch   240  of  9,804.    Elapsed: 0:01:40.\n",
      "  Batch   280  of  9,804.    Elapsed: 0:01:57.\n",
      "  Batch   320  of  9,804.    Elapsed: 0:02:14.\n",
      "  Batch   360  of  9,804.    Elapsed: 0:02:31.\n",
      "  Batch   400  of  9,804.    Elapsed: 0:02:47.\n",
      "  Batch   440  of  9,804.    Elapsed: 0:03:04.\n",
      "  Batch   480  of  9,804.    Elapsed: 0:03:21.\n",
      "  Batch   520  of  9,804.    Elapsed: 0:03:37.\n",
      "  Batch   560  of  9,804.    Elapsed: 0:03:54.\n",
      "  Batch   600  of  9,804.    Elapsed: 0:04:11.\n",
      "  Batch   640  of  9,804.    Elapsed: 0:04:27.\n",
      "  Batch   680  of  9,804.    Elapsed: 0:04:44.\n",
      "  Batch   720  of  9,804.    Elapsed: 0:05:01.\n",
      "  Batch   760  of  9,804.    Elapsed: 0:05:17.\n",
      "  Batch   800  of  9,804.    Elapsed: 0:05:34.\n",
      "  Batch   840  of  9,804.    Elapsed: 0:05:51.\n",
      "  Batch   880  of  9,804.    Elapsed: 0:06:08.\n",
      "  Batch   920  of  9,804.    Elapsed: 0:06:24.\n",
      "  Batch   960  of  9,804.    Elapsed: 0:06:41.\n",
      "  Batch 1,000  of  9,804.    Elapsed: 0:06:58.\n",
      "  Batch 1,040  of  9,804.    Elapsed: 0:07:14.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,080  of  9,804.    Elapsed: 0:07:31.\n",
      "  Batch 1,120  of  9,804.    Elapsed: 0:07:48.\n",
      "  Batch 1,160  of  9,804.    Elapsed: 0:08:04.\n",
      "  Batch 1,200  of  9,804.    Elapsed: 0:08:21.\n",
      "  Batch 1,240  of  9,804.    Elapsed: 0:08:38.\n",
      "  Batch 1,280  of  9,804.    Elapsed: 0:08:55.\n",
      "  Batch 1,320  of  9,804.    Elapsed: 0:09:12.\n",
      "  Batch 1,360  of  9,804.    Elapsed: 0:09:28.\n",
      "  Batch 1,400  of  9,804.    Elapsed: 0:09:45.\n",
      "  Batch 1,440  of  9,804.    Elapsed: 0:10:02.\n",
      "  Batch 1,480  of  9,804.    Elapsed: 0:10:19.\n",
      "  Batch 1,520  of  9,804.    Elapsed: 0:10:35.\n",
      "  Batch 1,560  of  9,804.    Elapsed: 0:10:52.\n",
      "  Batch 1,600  of  9,804.    Elapsed: 0:11:09.\n",
      "  Batch 1,640  of  9,804.    Elapsed: 0:11:26.\n",
      "  Batch 1,680  of  9,804.    Elapsed: 0:11:42.\n",
      "  Batch 1,720  of  9,804.    Elapsed: 0:11:59.\n",
      "  Batch 1,760  of  9,804.    Elapsed: 0:12:16.\n",
      "  Batch 1,800  of  9,804.    Elapsed: 0:12:32.\n",
      "  Batch 1,840  of  9,804.    Elapsed: 0:12:49.\n",
      "  Batch 1,880  of  9,804.    Elapsed: 0:13:06.\n",
      "  Batch 1,920  of  9,804.    Elapsed: 0:13:22.\n",
      "  Batch 1,960  of  9,804.    Elapsed: 0:13:39.\n",
      "  Batch 2,000  of  9,804.    Elapsed: 0:13:56.\n",
      "  Batch 2,040  of  9,804.    Elapsed: 0:14:12.\n",
      "  Batch 2,080  of  9,804.    Elapsed: 0:14:29.\n",
      "  Batch 2,120  of  9,804.    Elapsed: 0:14:46.\n",
      "  Batch 2,160  of  9,804.    Elapsed: 0:15:02.\n",
      "  Batch 2,200  of  9,804.    Elapsed: 0:15:19.\n",
      "  Batch 2,240  of  9,804.    Elapsed: 0:15:36.\n",
      "  Batch 2,280  of  9,804.    Elapsed: 0:15:53.\n",
      "  Batch 2,320  of  9,804.    Elapsed: 0:16:09.\n",
      "  Batch 2,360  of  9,804.    Elapsed: 0:16:26.\n",
      "  Batch 2,400  of  9,804.    Elapsed: 0:16:43.\n",
      "  Batch 2,440  of  9,804.    Elapsed: 0:16:59.\n",
      "  Batch 2,480  of  9,804.    Elapsed: 0:17:16.\n",
      "  Batch 2,520  of  9,804.    Elapsed: 0:17:33.\n",
      "  Batch 2,560  of  9,804.    Elapsed: 0:17:50.\n",
      "  Batch 2,600  of  9,804.    Elapsed: 0:18:06.\n",
      "  Batch 2,640  of  9,804.    Elapsed: 0:18:23.\n",
      "  Batch 2,680  of  9,804.    Elapsed: 0:18:40.\n",
      "  Batch 2,720  of  9,804.    Elapsed: 0:18:56.\n",
      "  Batch 2,760  of  9,804.    Elapsed: 0:19:13.\n",
      "  Batch 2,800  of  9,804.    Elapsed: 0:19:30.\n",
      "  Batch 2,840  of  9,804.    Elapsed: 0:19:46.\n",
      "  Batch 2,880  of  9,804.    Elapsed: 0:20:03.\n",
      "  Batch 2,920  of  9,804.    Elapsed: 0:20:20.\n",
      "  Batch 2,960  of  9,804.    Elapsed: 0:20:36.\n",
      "  Batch 3,000  of  9,804.    Elapsed: 0:20:53.\n",
      "  Batch 3,040  of  9,804.    Elapsed: 0:21:10.\n",
      "  Batch 3,080  of  9,804.    Elapsed: 0:21:26.\n",
      "  Batch 3,120  of  9,804.    Elapsed: 0:21:43.\n",
      "  Batch 3,160  of  9,804.    Elapsed: 0:22:00.\n",
      "  Batch 3,200  of  9,804.    Elapsed: 0:22:16.\n",
      "  Batch 3,240  of  9,804.    Elapsed: 0:22:33.\n",
      "  Batch 3,280  of  9,804.    Elapsed: 0:22:50.\n",
      "  Batch 3,320  of  9,804.    Elapsed: 0:23:06.\n",
      "  Batch 3,360  of  9,804.    Elapsed: 0:23:23.\n",
      "  Batch 3,400  of  9,804.    Elapsed: 0:23:40.\n",
      "  Batch 3,440  of  9,804.    Elapsed: 0:23:57.\n",
      "  Batch 3,480  of  9,804.    Elapsed: 0:24:13.\n",
      "  Batch 3,520  of  9,804.    Elapsed: 0:24:30.\n",
      "  Batch 3,560  of  9,804.    Elapsed: 0:24:47.\n",
      "  Batch 3,600  of  9,804.    Elapsed: 0:25:03.\n",
      "  Batch 3,640  of  9,804.    Elapsed: 0:25:20.\n",
      "  Batch 3,680  of  9,804.    Elapsed: 0:25:37.\n",
      "  Batch 3,720  of  9,804.    Elapsed: 0:25:53.\n",
      "  Batch 3,760  of  9,804.    Elapsed: 0:26:10.\n",
      "  Batch 3,800  of  9,804.    Elapsed: 0:26:27.\n",
      "  Batch 3,840  of  9,804.    Elapsed: 0:26:43.\n",
      "  Batch 3,880  of  9,804.    Elapsed: 0:27:00.\n",
      "  Batch 3,920  of  9,804.    Elapsed: 0:27:17.\n",
      "  Batch 3,960  of  9,804.    Elapsed: 0:27:33.\n",
      "  Batch 4,000  of  9,804.    Elapsed: 0:27:50.\n",
      "  Batch 4,040  of  9,804.    Elapsed: 0:28:07.\n",
      "  Batch 4,080  of  9,804.    Elapsed: 0:28:24.\n",
      "  Batch 4,120  of  9,804.    Elapsed: 0:28:40.\n",
      "  Batch 4,160  of  9,804.    Elapsed: 0:28:57.\n",
      "  Batch 4,200  of  9,804.    Elapsed: 0:29:14.\n",
      "  Batch 4,240  of  9,804.    Elapsed: 0:29:30.\n",
      "  Batch 4,280  of  9,804.    Elapsed: 0:29:47.\n",
      "  Batch 4,320  of  9,804.    Elapsed: 0:30:04.\n",
      "  Batch 4,360  of  9,804.    Elapsed: 0:30:21.\n",
      "  Batch 4,400  of  9,804.    Elapsed: 0:30:37.\n",
      "  Batch 4,440  of  9,804.    Elapsed: 0:30:54.\n",
      "  Batch 4,480  of  9,804.    Elapsed: 0:31:11.\n",
      "  Batch 4,520  of  9,804.    Elapsed: 0:31:28.\n",
      "  Batch 4,560  of  9,804.    Elapsed: 0:31:45.\n",
      "  Batch 4,600  of  9,804.    Elapsed: 0:32:01.\n",
      "  Batch 4,640  of  9,804.    Elapsed: 0:32:18.\n",
      "  Batch 4,680  of  9,804.    Elapsed: 0:32:35.\n",
      "  Batch 4,720  of  9,804.    Elapsed: 0:32:52.\n",
      "  Batch 4,760  of  9,804.    Elapsed: 0:33:08.\n",
      "  Batch 4,800  of  9,804.    Elapsed: 0:33:25.\n",
      "  Batch 4,840  of  9,804.    Elapsed: 0:33:42.\n",
      "  Batch 4,880  of  9,804.    Elapsed: 0:33:59.\n",
      "  Batch 4,920  of  9,804.    Elapsed: 0:34:15.\n",
      "  Batch 4,960  of  9,804.    Elapsed: 0:34:32.\n",
      "  Batch 5,000  of  9,804.    Elapsed: 0:34:49.\n",
      "  Batch 5,040  of  9,804.    Elapsed: 0:35:06.\n",
      "  Batch 5,080  of  9,804.    Elapsed: 0:35:23.\n",
      "  Batch 5,120  of  9,804.    Elapsed: 0:35:39.\n",
      "  Batch 5,160  of  9,804.    Elapsed: 0:35:56.\n",
      "  Batch 5,200  of  9,804.    Elapsed: 0:36:13.\n",
      "  Batch 5,240  of  9,804.    Elapsed: 0:36:30.\n",
      "  Batch 5,280  of  9,804.    Elapsed: 0:36:46.\n",
      "  Batch 5,320  of  9,804.    Elapsed: 0:37:03.\n",
      "  Batch 5,360  of  9,804.    Elapsed: 0:37:20.\n",
      "  Batch 5,400  of  9,804.    Elapsed: 0:37:37.\n",
      "  Batch 5,440  of  9,804.    Elapsed: 0:37:53.\n",
      "  Batch 5,480  of  9,804.    Elapsed: 0:38:10.\n",
      "  Batch 5,520  of  9,804.    Elapsed: 0:38:27.\n",
      "  Batch 5,560  of  9,804.    Elapsed: 0:38:44.\n",
      "  Batch 5,600  of  9,804.    Elapsed: 0:39:01.\n",
      "  Batch 5,640  of  9,804.    Elapsed: 0:39:17.\n",
      "  Batch 5,680  of  9,804.    Elapsed: 0:39:34.\n",
      "  Batch 5,720  of  9,804.    Elapsed: 0:39:51.\n",
      "  Batch 5,760  of  9,804.    Elapsed: 0:40:08.\n",
      "  Batch 5,800  of  9,804.    Elapsed: 0:40:24.\n",
      "  Batch 5,840  of  9,804.    Elapsed: 0:40:41.\n",
      "  Batch 5,880  of  9,804.    Elapsed: 0:40:58.\n",
      "  Batch 5,920  of  9,804.    Elapsed: 0:41:15.\n",
      "  Batch 5,960  of  9,804.    Elapsed: 0:41:32.\n",
      "  Batch 6,000  of  9,804.    Elapsed: 0:41:48.\n",
      "  Batch 6,040  of  9,804.    Elapsed: 0:42:05.\n",
      "  Batch 6,080  of  9,804.    Elapsed: 0:42:22.\n",
      "  Batch 6,120  of  9,804.    Elapsed: 0:42:39.\n",
      "  Batch 6,160  of  9,804.    Elapsed: 0:42:55.\n",
      "  Batch 6,200  of  9,804.    Elapsed: 0:43:12.\n",
      "  Batch 6,240  of  9,804.    Elapsed: 0:43:29.\n",
      "  Batch 6,280  of  9,804.    Elapsed: 0:43:46.\n",
      "  Batch 6,320  of  9,804.    Elapsed: 0:44:02.\n",
      "  Batch 6,360  of  9,804.    Elapsed: 0:44:19.\n",
      "  Batch 6,400  of  9,804.    Elapsed: 0:44:36.\n",
      "  Batch 6,440  of  9,804.    Elapsed: 0:44:53.\n",
      "  Batch 6,480  of  9,804.    Elapsed: 0:45:10.\n",
      "  Batch 6,520  of  9,804.    Elapsed: 0:45:26.\n",
      "  Batch 6,560  of  9,804.    Elapsed: 0:45:43.\n",
      "  Batch 6,600  of  9,804.    Elapsed: 0:46:00.\n",
      "  Batch 6,640  of  9,804.    Elapsed: 0:46:17.\n",
      "  Batch 6,680  of  9,804.    Elapsed: 0:46:33.\n",
      "  Batch 6,720  of  9,804.    Elapsed: 0:46:50.\n",
      "  Batch 6,760  of  9,804.    Elapsed: 0:47:07.\n",
      "  Batch 6,800  of  9,804.    Elapsed: 0:47:24.\n",
      "  Batch 6,840  of  9,804.    Elapsed: 0:47:41.\n",
      "  Batch 6,880  of  9,804.    Elapsed: 0:47:57.\n",
      "  Batch 6,920  of  9,804.    Elapsed: 0:48:14.\n",
      "  Batch 6,960  of  9,804.    Elapsed: 0:48:31.\n",
      "  Batch 7,000  of  9,804.    Elapsed: 0:48:48.\n",
      "  Batch 7,040  of  9,804.    Elapsed: 0:49:05.\n",
      "  Batch 7,080  of  9,804.    Elapsed: 0:49:21.\n",
      "  Batch 7,120  of  9,804.    Elapsed: 0:49:38.\n",
      "  Batch 7,160  of  9,804.    Elapsed: 0:49:55.\n",
      "  Batch 7,200  of  9,804.    Elapsed: 0:50:12.\n",
      "  Batch 7,240  of  9,804.    Elapsed: 0:50:28.\n",
      "  Batch 7,280  of  9,804.    Elapsed: 0:50:45.\n",
      "  Batch 7,320  of  9,804.    Elapsed: 0:51:02.\n",
      "  Batch 7,360  of  9,804.    Elapsed: 0:51:19.\n",
      "  Batch 7,400  of  9,804.    Elapsed: 0:51:36.\n",
      "  Batch 7,440  of  9,804.    Elapsed: 0:51:52.\n",
      "  Batch 7,480  of  9,804.    Elapsed: 0:52:09.\n",
      "  Batch 7,520  of  9,804.    Elapsed: 0:52:26.\n",
      "  Batch 7,560  of  9,804.    Elapsed: 0:52:43.\n",
      "  Batch 7,600  of  9,804.    Elapsed: 0:52:59.\n",
      "  Batch 7,640  of  9,804.    Elapsed: 0:53:16.\n",
      "  Batch 7,680  of  9,804.    Elapsed: 0:53:33.\n",
      "  Batch 7,720  of  9,804.    Elapsed: 0:53:50.\n",
      "  Batch 7,760  of  9,804.    Elapsed: 0:54:07.\n",
      "  Batch 7,800  of  9,804.    Elapsed: 0:54:23.\n",
      "  Batch 7,840  of  9,804.    Elapsed: 0:54:40.\n",
      "  Batch 7,880  of  9,804.    Elapsed: 0:54:57.\n",
      "  Batch 7,920  of  9,804.    Elapsed: 0:55:14.\n",
      "  Batch 7,960  of  9,804.    Elapsed: 0:55:30.\n",
      "  Batch 8,000  of  9,804.    Elapsed: 0:55:47.\n",
      "  Batch 8,040  of  9,804.    Elapsed: 0:56:04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 8,080  of  9,804.    Elapsed: 0:56:21.\n",
      "  Batch 8,120  of  9,804.    Elapsed: 0:56:37.\n",
      "  Batch 8,160  of  9,804.    Elapsed: 0:56:54.\n",
      "  Batch 8,200  of  9,804.    Elapsed: 0:57:11.\n",
      "  Batch 8,240  of  9,804.    Elapsed: 0:57:28.\n",
      "  Batch 8,280  of  9,804.    Elapsed: 0:57:45.\n",
      "  Batch 8,320  of  9,804.    Elapsed: 0:58:01.\n",
      "  Batch 8,360  of  9,804.    Elapsed: 0:58:18.\n",
      "  Batch 8,400  of  9,804.    Elapsed: 0:58:35.\n",
      "  Batch 8,440  of  9,804.    Elapsed: 0:58:52.\n",
      "  Batch 8,480  of  9,804.    Elapsed: 0:59:08.\n",
      "  Batch 8,520  of  9,804.    Elapsed: 0:59:25.\n",
      "  Batch 8,560  of  9,804.    Elapsed: 0:59:42.\n",
      "  Batch 8,600  of  9,804.    Elapsed: 0:59:59.\n",
      "  Batch 8,640  of  9,804.    Elapsed: 1:00:15.\n",
      "  Batch 8,680  of  9,804.    Elapsed: 1:00:32.\n",
      "  Batch 8,720  of  9,804.    Elapsed: 1:00:49.\n",
      "  Batch 8,760  of  9,804.    Elapsed: 1:01:06.\n",
      "  Batch 8,800  of  9,804.    Elapsed: 1:01:23.\n",
      "  Batch 8,840  of  9,804.    Elapsed: 1:01:39.\n",
      "  Batch 8,880  of  9,804.    Elapsed: 1:01:56.\n",
      "  Batch 8,920  of  9,804.    Elapsed: 1:02:13.\n",
      "  Batch 8,960  of  9,804.    Elapsed: 1:02:30.\n",
      "  Batch 9,000  of  9,804.    Elapsed: 1:02:46.\n",
      "  Batch 9,040  of  9,804.    Elapsed: 1:03:03.\n",
      "  Batch 9,080  of  9,804.    Elapsed: 1:03:20.\n",
      "  Batch 9,120  of  9,804.    Elapsed: 1:03:37.\n",
      "  Batch 9,160  of  9,804.    Elapsed: 1:03:54.\n",
      "  Batch 9,200  of  9,804.    Elapsed: 1:04:10.\n",
      "  Batch 9,240  of  9,804.    Elapsed: 1:04:27.\n",
      "  Batch 9,280  of  9,804.    Elapsed: 1:04:44.\n",
      "  Batch 9,320  of  9,804.    Elapsed: 1:05:01.\n",
      "  Batch 9,360  of  9,804.    Elapsed: 1:05:17.\n",
      "  Batch 9,400  of  9,804.    Elapsed: 1:05:34.\n",
      "  Batch 9,440  of  9,804.    Elapsed: 1:05:51.\n",
      "  Batch 9,480  of  9,804.    Elapsed: 1:06:08.\n",
      "  Batch 9,520  of  9,804.    Elapsed: 1:06:24.\n",
      "  Batch 9,560  of  9,804.    Elapsed: 1:06:41.\n",
      "  Batch 9,600  of  9,804.    Elapsed: 1:06:58.\n",
      "  Batch 9,640  of  9,804.    Elapsed: 1:07:15.\n",
      "  Batch 9,680  of  9,804.    Elapsed: 1:07:31.\n",
      "  Batch 9,720  of  9,804.    Elapsed: 1:07:48.\n",
      "  Batch 9,760  of  9,804.    Elapsed: 1:08:05.\n",
      "  Batch 9,800  of  9,804.    Elapsed: 1:08:22.\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 1:08:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Validation Loss: 1.23\n",
      "  Validation took: 0:05:26\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  9,804.    Elapsed: 0:00:17.\n",
      "  Batch    80  of  9,804.    Elapsed: 0:00:33.\n",
      "  Batch   120  of  9,804.    Elapsed: 0:00:50.\n",
      "  Batch   160  of  9,804.    Elapsed: 0:01:07.\n",
      "  Batch   200  of  9,804.    Elapsed: 0:01:24.\n",
      "  Batch   240  of  9,804.    Elapsed: 0:01:40.\n",
      "  Batch   280  of  9,804.    Elapsed: 0:01:57.\n",
      "  Batch   320  of  9,804.    Elapsed: 0:02:14.\n",
      "  Batch   360  of  9,804.    Elapsed: 0:02:31.\n",
      "  Batch   400  of  9,804.    Elapsed: 0:02:47.\n",
      "  Batch   440  of  9,804.    Elapsed: 0:03:04.\n",
      "  Batch   480  of  9,804.    Elapsed: 0:03:21.\n",
      "  Batch   520  of  9,804.    Elapsed: 0:03:37.\n",
      "  Batch   560  of  9,804.    Elapsed: 0:03:54.\n",
      "  Batch   600  of  9,804.    Elapsed: 0:04:11.\n",
      "  Batch   640  of  9,804.    Elapsed: 0:04:28.\n",
      "  Batch   680  of  9,804.    Elapsed: 0:04:44.\n",
      "  Batch   720  of  9,804.    Elapsed: 0:05:01.\n",
      "  Batch   760  of  9,804.    Elapsed: 0:05:18.\n",
      "  Batch   800  of  9,804.    Elapsed: 0:05:35.\n",
      "  Batch   840  of  9,804.    Elapsed: 0:05:51.\n",
      "  Batch   880  of  9,804.    Elapsed: 0:06:08.\n",
      "  Batch   920  of  9,804.    Elapsed: 0:06:25.\n",
      "  Batch   960  of  9,804.    Elapsed: 0:06:41.\n",
      "  Batch 1,000  of  9,804.    Elapsed: 0:06:58.\n",
      "  Batch 1,040  of  9,804.    Elapsed: 0:07:15.\n",
      "  Batch 1,080  of  9,804.    Elapsed: 0:07:32.\n",
      "  Batch 1,120  of  9,804.    Elapsed: 0:07:48.\n",
      "  Batch 1,160  of  9,804.    Elapsed: 0:08:05.\n",
      "  Batch 1,200  of  9,804.    Elapsed: 0:08:22.\n",
      "  Batch 1,240  of  9,804.    Elapsed: 0:08:39.\n",
      "  Batch 1,280  of  9,804.    Elapsed: 0:08:55.\n",
      "  Batch 1,320  of  9,804.    Elapsed: 0:09:12.\n",
      "  Batch 1,360  of  9,804.    Elapsed: 0:09:29.\n",
      "  Batch 1,400  of  9,804.    Elapsed: 0:09:45.\n",
      "  Batch 1,440  of  9,804.    Elapsed: 0:10:02.\n",
      "  Batch 1,480  of  9,804.    Elapsed: 0:10:19.\n",
      "  Batch 1,520  of  9,804.    Elapsed: 0:10:36.\n",
      "  Batch 1,560  of  9,804.    Elapsed: 0:10:52.\n",
      "  Batch 1,600  of  9,804.    Elapsed: 0:11:09.\n",
      "  Batch 1,640  of  9,804.    Elapsed: 0:11:26.\n",
      "  Batch 1,680  of  9,804.    Elapsed: 0:11:43.\n",
      "  Batch 1,720  of  9,804.    Elapsed: 0:11:59.\n",
      "  Batch 1,760  of  9,804.    Elapsed: 0:12:16.\n",
      "  Batch 1,800  of  9,804.    Elapsed: 0:12:33.\n",
      "  Batch 1,840  of  9,804.    Elapsed: 0:12:49.\n",
      "  Batch 1,880  of  9,804.    Elapsed: 0:13:06.\n",
      "  Batch 1,920  of  9,804.    Elapsed: 0:13:23.\n",
      "  Batch 1,960  of  9,804.    Elapsed: 0:13:40.\n",
      "  Batch 2,000  of  9,804.    Elapsed: 0:13:56.\n",
      "  Batch 2,040  of  9,804.    Elapsed: 0:14:13.\n",
      "  Batch 2,080  of  9,804.    Elapsed: 0:14:30.\n",
      "  Batch 2,120  of  9,804.    Elapsed: 0:14:47.\n",
      "  Batch 2,160  of  9,804.    Elapsed: 0:15:03.\n",
      "  Batch 2,200  of  9,804.    Elapsed: 0:15:20.\n",
      "  Batch 2,240  of  9,804.    Elapsed: 0:15:37.\n",
      "  Batch 2,280  of  9,804.    Elapsed: 0:15:53.\n",
      "  Batch 2,320  of  9,804.    Elapsed: 0:16:10.\n",
      "  Batch 2,360  of  9,804.    Elapsed: 0:16:27.\n",
      "  Batch 2,400  of  9,804.    Elapsed: 0:16:44.\n",
      "  Batch 2,440  of  9,804.    Elapsed: 0:17:00.\n",
      "  Batch 2,480  of  9,804.    Elapsed: 0:17:17.\n",
      "  Batch 2,520  of  9,804.    Elapsed: 0:17:34.\n",
      "  Batch 2,560  of  9,804.    Elapsed: 0:17:50.\n",
      "  Batch 2,600  of  9,804.    Elapsed: 0:18:07.\n",
      "  Batch 2,640  of  9,804.    Elapsed: 0:18:24.\n",
      "  Batch 2,680  of  9,804.    Elapsed: 0:18:41.\n",
      "  Batch 2,720  of  9,804.    Elapsed: 0:18:57.\n",
      "  Batch 2,760  of  9,804.    Elapsed: 0:19:14.\n",
      "  Batch 2,800  of  9,804.    Elapsed: 0:19:31.\n",
      "  Batch 2,840  of  9,804.    Elapsed: 0:19:48.\n",
      "  Batch 2,880  of  9,804.    Elapsed: 0:20:04.\n",
      "  Batch 2,920  of  9,804.    Elapsed: 0:20:21.\n",
      "  Batch 2,960  of  9,804.    Elapsed: 0:20:38.\n",
      "  Batch 3,000  of  9,804.    Elapsed: 0:20:55.\n",
      "  Batch 3,040  of  9,804.    Elapsed: 0:21:11.\n",
      "  Batch 3,080  of  9,804.    Elapsed: 0:21:28.\n",
      "  Batch 3,120  of  9,804.    Elapsed: 0:21:45.\n",
      "  Batch 3,160  of  9,804.    Elapsed: 0:22:01.\n",
      "  Batch 3,200  of  9,804.    Elapsed: 0:22:18.\n",
      "  Batch 3,240  of  9,804.    Elapsed: 0:22:35.\n",
      "  Batch 3,280  of  9,804.    Elapsed: 0:22:52.\n",
      "  Batch 3,320  of  9,804.    Elapsed: 0:23:08.\n",
      "  Batch 3,360  of  9,804.    Elapsed: 0:23:25.\n",
      "  Batch 3,400  of  9,804.    Elapsed: 0:23:42.\n",
      "  Batch 3,440  of  9,804.    Elapsed: 0:23:58.\n",
      "  Batch 3,480  of  9,804.    Elapsed: 0:24:15.\n",
      "  Batch 3,520  of  9,804.    Elapsed: 0:24:32.\n",
      "  Batch 3,560  of  9,804.    Elapsed: 0:24:49.\n",
      "  Batch 3,600  of  9,804.    Elapsed: 0:25:05.\n",
      "  Batch 3,640  of  9,804.    Elapsed: 0:25:22.\n",
      "  Batch 3,680  of  9,804.    Elapsed: 0:25:39.\n",
      "  Batch 3,720  of  9,804.    Elapsed: 0:25:56.\n",
      "  Batch 3,760  of  9,804.    Elapsed: 0:26:12.\n",
      "  Batch 3,800  of  9,804.    Elapsed: 0:26:29.\n",
      "  Batch 3,840  of  9,804.    Elapsed: 0:26:46.\n",
      "  Batch 3,880  of  9,804.    Elapsed: 0:27:02.\n",
      "  Batch 3,920  of  9,804.    Elapsed: 0:27:19.\n",
      "  Batch 3,960  of  9,804.    Elapsed: 0:27:36.\n",
      "  Batch 4,000  of  9,804.    Elapsed: 0:27:53.\n",
      "  Batch 4,040  of  9,804.    Elapsed: 0:28:09.\n",
      "  Batch 4,080  of  9,804.    Elapsed: 0:28:26.\n",
      "  Batch 4,120  of  9,804.    Elapsed: 0:28:43.\n",
      "  Batch 4,160  of  9,804.    Elapsed: 0:29:00.\n",
      "  Batch 4,200  of  9,804.    Elapsed: 0:29:16.\n",
      "  Batch 4,240  of  9,804.    Elapsed: 0:29:33.\n",
      "  Batch 4,280  of  9,804.    Elapsed: 0:29:50.\n",
      "  Batch 4,320  of  9,804.    Elapsed: 0:30:06.\n",
      "  Batch 4,360  of  9,804.    Elapsed: 0:30:23.\n",
      "  Batch 4,400  of  9,804.    Elapsed: 0:30:40.\n",
      "  Batch 4,440  of  9,804.    Elapsed: 0:30:57.\n",
      "  Batch 4,480  of  9,804.    Elapsed: 0:31:13.\n",
      "  Batch 4,520  of  9,804.    Elapsed: 0:31:30.\n",
      "  Batch 4,560  of  9,804.    Elapsed: 0:31:47.\n",
      "  Batch 4,600  of  9,804.    Elapsed: 0:32:04.\n",
      "  Batch 4,640  of  9,804.    Elapsed: 0:32:20.\n",
      "  Batch 4,680  of  9,804.    Elapsed: 0:32:37.\n",
      "  Batch 4,720  of  9,804.    Elapsed: 0:32:54.\n",
      "  Batch 4,760  of  9,804.    Elapsed: 0:33:11.\n",
      "  Batch 4,800  of  9,804.    Elapsed: 0:33:27.\n",
      "  Batch 4,840  of  9,804.    Elapsed: 0:33:44.\n",
      "  Batch 4,880  of  9,804.    Elapsed: 0:34:01.\n",
      "  Batch 4,920  of  9,804.    Elapsed: 0:34:17.\n",
      "  Batch 4,960  of  9,804.    Elapsed: 0:34:34.\n",
      "  Batch 5,000  of  9,804.    Elapsed: 0:34:51.\n",
      "  Batch 5,040  of  9,804.    Elapsed: 0:35:08.\n",
      "  Batch 5,080  of  9,804.    Elapsed: 0:35:24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 5,120  of  9,804.    Elapsed: 0:35:41.\n",
      "  Batch 5,160  of  9,804.    Elapsed: 0:35:58.\n",
      "  Batch 5,200  of  9,804.    Elapsed: 0:36:15.\n",
      "  Batch 5,240  of  9,804.    Elapsed: 0:36:31.\n",
      "  Batch 5,280  of  9,804.    Elapsed: 0:36:48.\n",
      "  Batch 5,320  of  9,804.    Elapsed: 0:37:05.\n",
      "  Batch 5,360  of  9,804.    Elapsed: 0:37:22.\n",
      "  Batch 5,400  of  9,804.    Elapsed: 0:37:38.\n",
      "  Batch 5,440  of  9,804.    Elapsed: 0:37:55.\n",
      "  Batch 5,480  of  9,804.    Elapsed: 0:38:12.\n",
      "  Batch 5,520  of  9,804.    Elapsed: 0:38:29.\n",
      "  Batch 5,560  of  9,804.    Elapsed: 0:38:45.\n",
      "  Batch 5,600  of  9,804.    Elapsed: 0:39:02.\n",
      "  Batch 5,640  of  9,804.    Elapsed: 0:39:19.\n",
      "  Batch 5,680  of  9,804.    Elapsed: 0:39:35.\n",
      "  Batch 5,720  of  9,804.    Elapsed: 0:39:52.\n",
      "  Batch 5,760  of  9,804.    Elapsed: 0:40:09.\n",
      "  Batch 5,800  of  9,804.    Elapsed: 0:40:26.\n",
      "  Batch 5,840  of  9,804.    Elapsed: 0:40:42.\n",
      "  Batch 5,880  of  9,804.    Elapsed: 0:40:59.\n",
      "  Batch 5,920  of  9,804.    Elapsed: 0:41:16.\n",
      "  Batch 5,960  of  9,804.    Elapsed: 0:41:33.\n",
      "  Batch 6,000  of  9,804.    Elapsed: 0:41:49.\n",
      "  Batch 6,040  of  9,804.    Elapsed: 0:42:06.\n",
      "  Batch 6,080  of  9,804.    Elapsed: 0:42:23.\n",
      "  Batch 6,120  of  9,804.    Elapsed: 0:42:39.\n",
      "  Batch 6,160  of  9,804.    Elapsed: 0:42:56.\n",
      "  Batch 6,200  of  9,804.    Elapsed: 0:43:13.\n",
      "  Batch 6,240  of  9,804.    Elapsed: 0:43:29.\n",
      "  Batch 6,280  of  9,804.    Elapsed: 0:43:46.\n",
      "  Batch 6,320  of  9,804.    Elapsed: 0:44:03.\n",
      "  Batch 6,360  of  9,804.    Elapsed: 0:44:20.\n",
      "  Batch 6,400  of  9,804.    Elapsed: 0:44:36.\n",
      "  Batch 6,440  of  9,804.    Elapsed: 0:44:53.\n",
      "  Batch 6,480  of  9,804.    Elapsed: 0:45:10.\n",
      "  Batch 6,520  of  9,804.    Elapsed: 0:45:27.\n",
      "  Batch 6,560  of  9,804.    Elapsed: 0:45:43.\n",
      "  Batch 6,600  of  9,804.    Elapsed: 0:46:00.\n",
      "  Batch 6,640  of  9,804.    Elapsed: 0:46:17.\n",
      "  Batch 6,680  of  9,804.    Elapsed: 0:46:34.\n",
      "  Batch 6,720  of  9,804.    Elapsed: 0:46:50.\n",
      "  Batch 6,760  of  9,804.    Elapsed: 0:47:07.\n",
      "  Batch 6,800  of  9,804.    Elapsed: 0:47:24.\n",
      "  Batch 6,840  of  9,804.    Elapsed: 0:47:41.\n",
      "  Batch 6,880  of  9,804.    Elapsed: 0:47:57.\n",
      "  Batch 6,920  of  9,804.    Elapsed: 0:48:14.\n",
      "  Batch 6,960  of  9,804.    Elapsed: 0:48:31.\n",
      "  Batch 7,000  of  9,804.    Elapsed: 0:48:47.\n",
      "  Batch 7,040  of  9,804.    Elapsed: 0:49:04.\n",
      "  Batch 7,080  of  9,804.    Elapsed: 0:49:21.\n",
      "  Batch 7,120  of  9,804.    Elapsed: 0:49:38.\n",
      "  Batch 7,160  of  9,804.    Elapsed: 0:49:54.\n",
      "  Batch 7,200  of  9,804.    Elapsed: 0:50:11.\n",
      "  Batch 7,240  of  9,804.    Elapsed: 0:50:28.\n",
      "  Batch 7,280  of  9,804.    Elapsed: 0:50:45.\n",
      "  Batch 7,320  of  9,804.    Elapsed: 0:51:01.\n",
      "  Batch 7,360  of  9,804.    Elapsed: 0:51:18.\n",
      "  Batch 7,400  of  9,804.    Elapsed: 0:51:35.\n",
      "  Batch 7,440  of  9,804.    Elapsed: 0:51:51.\n",
      "  Batch 7,480  of  9,804.    Elapsed: 0:52:08.\n",
      "  Batch 7,520  of  9,804.    Elapsed: 0:52:25.\n",
      "  Batch 7,560  of  9,804.    Elapsed: 0:52:42.\n",
      "  Batch 7,600  of  9,804.    Elapsed: 0:52:58.\n",
      "  Batch 7,640  of  9,804.    Elapsed: 0:53:15.\n",
      "  Batch 7,680  of  9,804.    Elapsed: 0:53:32.\n",
      "  Batch 7,720  of  9,804.    Elapsed: 0:53:49.\n",
      "  Batch 7,760  of  9,804.    Elapsed: 0:54:05.\n",
      "  Batch 7,800  of  9,804.    Elapsed: 0:54:22.\n",
      "  Batch 7,840  of  9,804.    Elapsed: 0:54:39.\n",
      "  Batch 7,880  of  9,804.    Elapsed: 0:54:55.\n",
      "  Batch 7,920  of  9,804.    Elapsed: 0:55:12.\n",
      "  Batch 7,960  of  9,804.    Elapsed: 0:55:29.\n",
      "  Batch 8,000  of  9,804.    Elapsed: 0:55:46.\n",
      "  Batch 8,040  of  9,804.    Elapsed: 0:56:02.\n",
      "  Batch 8,080  of  9,804.    Elapsed: 0:56:19.\n",
      "  Batch 8,120  of  9,804.    Elapsed: 0:56:36.\n",
      "  Batch 8,160  of  9,804.    Elapsed: 0:56:53.\n",
      "  Batch 8,200  of  9,804.    Elapsed: 0:57:09.\n",
      "  Batch 8,240  of  9,804.    Elapsed: 0:57:26.\n",
      "  Batch 8,280  of  9,804.    Elapsed: 0:57:43.\n",
      "  Batch 8,320  of  9,804.    Elapsed: 0:57:59.\n",
      "  Batch 8,360  of  9,804.    Elapsed: 0:58:16.\n",
      "  Batch 8,400  of  9,804.    Elapsed: 0:58:33.\n",
      "  Batch 8,440  of  9,804.    Elapsed: 0:58:50.\n",
      "  Batch 8,480  of  9,804.    Elapsed: 0:59:06.\n",
      "  Batch 8,520  of  9,804.    Elapsed: 0:59:23.\n",
      "  Batch 8,560  of  9,804.    Elapsed: 0:59:40.\n",
      "  Batch 8,600  of  9,804.    Elapsed: 0:59:57.\n",
      "  Batch 8,640  of  9,804.    Elapsed: 1:00:13.\n",
      "  Batch 8,680  of  9,804.    Elapsed: 1:00:30.\n",
      "  Batch 8,720  of  9,804.    Elapsed: 1:00:47.\n",
      "  Batch 8,760  of  9,804.    Elapsed: 1:01:03.\n",
      "  Batch 8,800  of  9,804.    Elapsed: 1:01:20.\n",
      "  Batch 8,840  of  9,804.    Elapsed: 1:01:37.\n",
      "  Batch 8,880  of  9,804.    Elapsed: 1:01:54.\n",
      "  Batch 8,920  of  9,804.    Elapsed: 1:02:10.\n",
      "  Batch 8,960  of  9,804.    Elapsed: 1:02:27.\n",
      "  Batch 9,000  of  9,804.    Elapsed: 1:02:44.\n",
      "  Batch 9,040  of  9,804.    Elapsed: 1:03:01.\n",
      "  Batch 9,080  of  9,804.    Elapsed: 1:03:17.\n",
      "  Batch 9,120  of  9,804.    Elapsed: 1:03:34.\n",
      "  Batch 9,160  of  9,804.    Elapsed: 1:03:51.\n",
      "  Batch 9,200  of  9,804.    Elapsed: 1:04:08.\n",
      "  Batch 9,240  of  9,804.    Elapsed: 1:04:24.\n",
      "  Batch 9,280  of  9,804.    Elapsed: 1:04:41.\n",
      "  Batch 9,320  of  9,804.    Elapsed: 1:04:58.\n",
      "  Batch 9,360  of  9,804.    Elapsed: 1:05:15.\n",
      "  Batch 9,400  of  9,804.    Elapsed: 1:05:31.\n",
      "  Batch 9,440  of  9,804.    Elapsed: 1:05:48.\n",
      "  Batch 9,480  of  9,804.    Elapsed: 1:06:05.\n",
      "  Batch 9,520  of  9,804.    Elapsed: 1:06:22.\n",
      "  Batch 9,560  of  9,804.    Elapsed: 1:06:38.\n",
      "  Batch 9,600  of  9,804.    Elapsed: 1:06:55.\n",
      "  Batch 9,640  of  9,804.    Elapsed: 1:07:12.\n",
      "  Batch 9,680  of  9,804.    Elapsed: 1:07:29.\n",
      "  Batch 9,720  of  9,804.    Elapsed: 1:07:45.\n",
      "  Batch 9,760  of  9,804.    Elapsed: 1:08:02.\n",
      "  Batch 9,800  of  9,804.    Elapsed: 1:08:19.\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 1:08:21\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.67\n",
      "  Validation Loss: 1.70\n",
      "  Validation took: 0:05:26\n",
      "\n",
      "Training complete!\n",
      "Total training took 4:55:09 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch... 4 times\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "        probs = logits.softmax(dim=-1).detach().cpu().flatten().numpy().tolist()\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1:08:23</td>\n",
       "      <td>0:05:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1:08:21</td>\n",
       "      <td>0:05:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.71</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1:08:23</td>\n",
       "      <td>0:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.56</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1:08:21</td>\n",
       "      <td>0:05:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.80         0.73           0.68       1:08:23         0:05:24\n",
       "2               0.76         0.98           0.68       1:08:21         0:05:25\n",
       "3               0.71         1.23           0.68       1:08:23         0:05:26\n",
       "4               0.56         1.70           0.67       1:08:21         0:05:26"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap (doesn't seem to work in Colab).\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why Validation Loss, not Accuracy?\n",
    "# Validation loss is a more precise measure than validation accuracy, because with accuracy we don’t care about the exact output value, but just which side of a threshold it falls on.\n",
    "# If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
